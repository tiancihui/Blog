<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dunwu</title>
  
  <subtitle>大道至简，知易行难</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://dunwu.github.io/blog/"/>
  <updated>2020-07-25T07:46:26.677Z</updated>
  <id>https://dunwu.github.io/blog/</id>
  
  <author>
    <name>Zhang Peng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>design/solution/bigdata-resolve</title>
    <link href="https://dunwu.github.io/blog/design/solution/bigdata-resolve/"/>
    <id>https://dunwu.github.io/blog/design/solution/bigdata-resolve/</id>
    <published>2020-07-25T07:46:26.677Z</published>
    <updated>2020-07-25T07:46:26.677Z</updated>
    
    <content type="html"><![CDATA[<h1 id="海量数据处理"><a class="markdownIt-Anchor" href="#海量数据处理"></a> 海量数据处理</h1><h2 id="如何从海量的-url-中找出相同的-url"><a class="markdownIt-Anchor" href="#如何从海量的-url-中找出相同的-url"></a> 如何从海量的 URL 中找出相同的 URL？</h2><h3 id="问题描述"><a class="markdownIt-Anchor" href="#问题描述"></a> 问题描述</h3><p>给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。</p><h3 id="解决思路"><a class="markdownIt-Anchor" href="#解决思路"></a> 解决思路</h3><p>每个 URL 占 64B，那么 50 亿个 URL 占用的空间大小约为 320GB。</p><blockquote><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>5</mn><mo separator="true">,</mo><mn>000</mn><mo separator="true">,</mo><mn>000</mn><mo separator="true">,</mo><mn>000</mn><mo>∗</mo><mn>64</mn><mi>B</mi><mo>≈</mo><mn>5</mn><mi>G</mi><mi>B</mi><mo>∗</mo><mn>64</mn><mo>=</mo><mn>320</mn><mi>G</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">5,000,000,000 * 64 B ≈ 5 GB * 64 = 320 GB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord mathdefault">G</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">2</span><span class="mord">0</span><span class="mord mathdefault">G</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span></span></p></blockquote><p>由于内存大小只有 4G，因此，我们不可能一次性把所有 URL 加载到内存中处理。对于这种类型的题目，一般采用<strong>分治策略</strong>，即：把一个文件中的 URL 按照某个特征划分为多个小文件，使得每个小文件大小不超过 4G，这样就可以把这个小文件读到内存中进行处理了。</p><p>思路如下：</p><p>首先遍历文件 a，对遍历到的 URL 求 <code>hash(URL) % 1000</code>，根据计算结果把遍历到的 URL 存储到 a0, a1, a2, …, a999，这样每个大小约为 300MB。使用同样的方法遍历文件 b，把文件 b 中的 URL 分别存储到文件 b0, b1, b2, …, b999 中。这样处理过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0, …, a999 对应 b999，不对应的小文件不可能有相同的 URL。那么接下来，我们只需要求出这 1000 对小文件中相同的 URL 就好了。</p><p>接着遍历 ai( <code>i∈[0,999]</code>)，把 URL 存储到一个 HashSet 集合中。然后遍历 bi 中每个 URL，看在 HashSet 集合中是否存在，若存在，说明这就是共同的 URL，可以把这个 URL 保存到一个单独的文件中。</p><h3 id="方案总结"><a class="markdownIt-Anchor" href="#方案总结"></a> 方案总结</h3><ul><li>分而治之，进行哈希取余；</li><li>对每个子文件进行 HashSet 统计。</li></ul><h2 id="如何从海量数据中找出高频词"><a class="markdownIt-Anchor" href="#如何从海量数据中找出高频词"></a> 如何从海量数据中找出高频词？</h2><h3 id="问题描述-2"><a class="markdownIt-Anchor" href="#问题描述-2"></a> 问题描述</h3><p>有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。</p><h3 id="解决思路-2"><a class="markdownIt-Anchor" href="#解决思路-2"></a> 解决思路</h3><p>由于内存限制，无法直接将大文件的所有词一次读到内存中。因此，可以采用<strong>分治策略</strong>，把一个大文件分解成多个小文件，保证每个文件的大小小于 1MB，进而直接将单个小文件读取到内存中进行处理。</p><p><strong>思路如下</strong>：</p><p>首先遍历大文件，对遍历到的每个词 x，执行 <code>hash(x) % 5000</code>，将结果为 i 的词存放到文件 Ai 中。遍历结束后，我们可以得到 5000 个小文件。每个小文件的大小为 200KB 左右。如果有的小文件大小仍然超过 1MB，则采用同样的方式继续进行分解。</p><p>接着统计每个小文件中出现频数最高的 100 个词。最简单的方式是使用 <code>HashMap</code> 来实现。其中 key 为词，value 为该词出现的频率。具体方法是：对于遍历到的词 x，如果在 map 中不存在，则执行 <code>map.put(x, 1)</code> 若存在，则执行 <code>map.put(x, map.get(x)+1)</code>，将该词频数加 1。</p><p>上面我们统计了每个小文件单词出现的频数。接下来，我们可以通过维护一个<strong>小顶堆</strong>来找出所有词中出现频数最高的 100 个。具体方法是：依次遍历每个小文件，构建一个<strong>小顶堆</strong>，堆大小为 100。如果遍历到的词的出现次数大于堆顶词的出现次数，则用新词替换堆顶的词，然后重新调整为<strong>小顶堆</strong>，遍历结束后，小顶堆上的词就是出现频数最高的 100 个词。</p><h3 id="方案总结-2"><a class="markdownIt-Anchor" href="#方案总结-2"></a> 方案总结</h3><ul><li>分而治之，进行哈希取余；</li><li>使用 <code>HashMap</code> 统计频数；</li><li>求解<strong>最大</strong>的 TopN 个，用<strong>小顶堆</strong>；求解<strong>最小</strong>的 TopN 个，用<strong>大顶堆</strong>。</li></ul><h2 id="如何找出某一天访问百度网站最多的-ip"><a class="markdownIt-Anchor" href="#如何找出某一天访问百度网站最多的-ip"></a> 如何找出某一天访问百度网站最多的 IP？</h2><h3 id="问题描述-3"><a class="markdownIt-Anchor" href="#问题描述-3"></a> 问题描述</h3><p>现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。</p><h3 id="解决思路-3"><a class="markdownIt-Anchor" href="#解决思路-3"></a> 解决思路</h3><p>这道题只关心某一天访问百度最多的 IP，因此，可以首先对文件进行一次遍历，把这一天访问百度 IP 的相关信息记录到一个单独的大文件中。接下来采用的方法与上一题一样，大致就是先对 IP 进行哈希映射，接着使用 HashMap 统计重复 IP 的次数，最后计算出重复次数最多的 IP。</p><blockquote><p>注：这里只需要找出出现次数最多的 IP，可以不必使用堆，直接用一个变量 max 即可。</p></blockquote><h3 id="方法总结"><a class="markdownIt-Anchor" href="#方法总结"></a> 方法总结</h3><ul><li>分而治之，进行哈希取余；</li><li>使用 HashMap 统计频数；</li><li>求解<strong>最大</strong>的 TopN 个，用<strong>小顶堆</strong>；求解<strong>最小</strong>的 TopN 个，用<strong>大顶堆</strong>。</li></ul><h2 id="如何在大量的数据中找出不重复的整数"><a class="markdownIt-Anchor" href="#如何在大量的数据中找出不重复的整数"></a> 如何在大量的数据中找出不重复的整数？</h2><h3 id="问题描述-4"><a class="markdownIt-Anchor" href="#问题描述-4"></a> 问题描述</h3><p>在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。</p><h3 id="解决思路-4"><a class="markdownIt-Anchor" href="#解决思路-4"></a> 解决思路</h3><h4 id="方法一分治法"><a class="markdownIt-Anchor" href="#方法一分治法"></a> 方法一：分治法</h4><p>与前面的题目方法类似，先将 2.5 亿个数划分到多个小文件，用 HashSet/HashMap 找出每个小文件中不重复的整数，再合并每个子结果，即为最终结果。</p><h4 id="方法二位图法"><a class="markdownIt-Anchor" href="#方法二位图法"></a> 方法二：位图法</h4><p><strong>位图</strong>，就是用一个或多个 bit 来标记某个元素对应的值，而键就是该元素。采用位作为单位来存储数据，可以大大节省存储空间。</p><p>位图通过使用位数组来表示某些元素是否存在。它可以用于快速查找，判重，排序等。不是很清楚？我先举个小例子。</p><p>假设我们要对 <code>[0,7]</code> 中的 5 个元素 (6, 4, 2, 1, 5) 进行排序，可以采用位图法。0~7 范围总共有 8 个数，只需要 8bit，即 1 个字节。首先将每个位都置 0：</p><figure class="highlight basic"><table><tr><td class="code"><pre><span class="line"><span class="symbol">0 </span><span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p>然后遍历 5 个元素，首先遇到 6，那么将下标为 6 的位的 0 置为 1；接着遇到 4，把下标为 4 的位 的 0 置为 1：</p><figure class="highlight basic"><table><tr><td class="code"><pre><span class="line"><span class="symbol">0 </span><span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p>依次遍历，结束后，位数组是这样的：</p><figure class="highlight basic"><table><tr><td class="code"><pre><span class="line"><span class="symbol">0 </span><span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p>每个为 1 的位，它的下标都表示了一个数：</p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> in range(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">if</span> bits[<span class="built_in">i</span>] == <span class="number">1</span>:</span><br><span class="line">        print(<span class="built_in">i</span>)</span><br></pre></td></tr></table></figure><p>这样我们其实就已经实现了排序。</p><p>对于整数相关的算法的求解，<strong>位图法</strong>是一种非常实用的算法。假设 int 整数占用 4B，即 32bit，那么我们可以表示的整数的个数为 232。</p><p><strong>那么对于这道题</strong>，我们用 2 个 bit 来表示各个数字的状态：</p><ul><li>00 表示这个数字没出现过；</li><li>01 表示这个数字出现过一次（即为题目所找的不重复整数）；</li><li>10 表示这个数字出现了多次。</li></ul><p>那么这 232 个整数，总共所需内存为 232*2b=1GB。因此，当可用内存超过 1GB 时，可以采用位图法。假设内存满足位图法需求，进行下面的操作：</p><p>遍历 2.5 亿个整数，查看位图中对应的位，如果是 00，则变为 01，如果是 01 则变为 10，如果是 10 则保持不变。遍历结束后，查看位图，把对应位是 01 的整数输出即可。</p><h3 id="方法总结-2"><a class="markdownIt-Anchor" href="#方法总结-2"></a> 方法总结</h3><p><strong>判断数字是否重复的问题</strong>，位图法是一种非常高效的方法。</p><h2 id="如何在大量的数据中判断一个数是否存在"><a class="markdownIt-Anchor" href="#如何在大量的数据中判断一个数是否存在"></a> 如何在大量的数据中判断一个数是否存在？</h2><h3 id="题目描述"><a class="markdownIt-Anchor" href="#题目描述"></a> 题目描述</h3><p>给定 40 亿个不重复的没排过序的 unsigned int 型整数，然后再给定一个数，如何快速判断这个数是否在这 40 亿个整数当中？</p><h3 id="解答思路"><a class="markdownIt-Anchor" href="#解答思路"></a> 解答思路</h3><h4 id="方法一分治法-2"><a class="markdownIt-Anchor" href="#方法一分治法-2"></a> 方法一：分治法</h4><p>依然可以用分治法解决，方法与前面类似，就不再次赘述了。</p><h4 id="方法二位图法-2"><a class="markdownIt-Anchor" href="#方法二位图法-2"></a> 方法二：位图法</h4><p>40 亿个不重复整数，我们用 40 亿个 bit 来表示，初始位均为 0，那么总共需要内存：4,000,000,000b≈512M。</p><p>我们读取这 40 亿个整数，将对应的 bit 设置为 1。接着读取要查询的数，查看相应位是否为 1，如果为 1 表示存在，如果为 0 表示不存在。</p><h3 id="方法总结-3"><a class="markdownIt-Anchor" href="#方法总结-3"></a> 方法总结</h3><p><strong>判断数字是否存在、判断数字是否重复的问题</strong>，位图法是一种非常高效的方法。</p><h2 id="如何查询最热门的查询串"><a class="markdownIt-Anchor" href="#如何查询最热门的查询串"></a> 如何查询最热门的查询串？</h2><h3 id="题目描述-2"><a class="markdownIt-Anchor" href="#题目描述-2"></a> 题目描述</h3><p>搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询串的长度不超过 255 字节。</p><p>假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。）</p><h3 id="解答思路-2"><a class="markdownIt-Anchor" href="#解答思路-2"></a> 解答思路</h3><p>每个查询串最长为 255B，1000w 个串需要占用 约 2.55G 内存，因此，我们无法将所有字符串全部读入到内存中处理。</p><h4 id="方法一分治法-3"><a class="markdownIt-Anchor" href="#方法一分治法-3"></a> 方法一：分治法</h4><p>分治法依然是一个非常实用的方法。</p><p>划分为多个小文件，保证单个小文件中的字符串能被直接加载到内存中处理，然后求出每个文件中出现次数最多的 10 个字符串；最后通过一个小顶堆统计出所有文件中出现最多的 10 个字符串。</p><p>方法可行，但不是最好，下面介绍其他方法。</p><h4 id="方法二hashmap-法"><a class="markdownIt-Anchor" href="#方法二hashmap-法"></a> 方法二：HashMap 法</h4><p>虽然字符串总数比较多，但去重后不超过 300w，因此，可以考虑把所有字符串及出现次数保存在一个 HashMap 中，所占用的空间为 300w*(255+4)≈777M（其中，4 表示整数占用的 4 个字节）。由此可见，1G 的内存空间完全够用。</p><p><strong>思路如下</strong>：</p><p>首先，遍历字符串，若不在 map 中，直接存入 map，value 记为 1；若在 map 中，则把对应的 value 加 1，这一步时间复杂度 <code>O(N)</code>。</p><p>接着遍历 map，构建一个 10 个元素的小顶堆，若遍历到的字符串的出现次数大于堆顶字符串的出现次数，则进行替换，并将堆调整为小顶堆。</p><p>遍历结束后，堆中 10 个字符串就是出现次数最多的字符串。这一步时间复杂度 <code>O(Nlog10)</code>。</p><h4 id="方法三前缀树法字典树"><a class="markdownIt-Anchor" href="#方法三前缀树法字典树"></a> 方法三：前缀树法（字典树）</h4><p>方法二使用了 HashMap 来统计次数，当这些字符串有大量相同前缀时，可以考虑使用前缀树来统计字符串出现的次数，树的结点保存字符串出现次数，0 表示没有出现。</p><p><strong>思路如下</strong>：</p><p>在遍历字符串时，在前缀树中查找，如果找到，则把结点中保存的字符串次数加 1，否则为这个字符串构建新结点，构建完成后把叶子结点中字符串的出现次数置为 1。</p><p>最后依然使用小顶堆来对字符串的出现次数进行排序。</p><h3 id="方法总结-4"><a class="markdownIt-Anchor" href="#方法总结-4"></a> 方法总结</h3><p>前缀树经常被用来统计字符串的出现次数。它的另外一个大的用途是字符串查找，判断是否有重复的字符串等。</p><h2 id="如何统计不同电话号码的个数"><a class="markdownIt-Anchor" href="#如何统计不同电话号码的个数"></a> 如何统计不同电话号码的个数？</h2><h3 id="题目描述-3"><a class="markdownIt-Anchor" href="#题目描述-3"></a> 题目描述</h3><p>已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。</p><h3 id="解答思路-3"><a class="markdownIt-Anchor" href="#解答思路-3"></a> 解答思路</h3><p>这道题本质还是求解<strong>数据重复</strong>的问题，对于这类问题，一般首先考虑位图法。</p><p>对于本题，8 位电话号码可以表示的号码个数为 $$10^8$$ 个，即 1 亿个。我们每个号码用一个 bit 来表示，则总共需要 1 亿个 bit，内存占用约 100M。</p><p><strong>思路如下</strong>：</p><p>申请一个位图数组，长度为 1 亿，初始化为 0。然后遍历所有电话号码，把号码对应的位图中的位置置为 1。遍历完成后，如果 bit 为 1，则表示这个电话号码在文件中存在，否则不存在。bit 值为 1 的数量即为 不同电话号码的个数。</p><h3 id="方法总结-5"><a class="markdownIt-Anchor" href="#方法总结-5"></a> 方法总结</h3><p>求解数据重复问题，记得考虑位图法。</p><h2 id="如何从-5-亿个数中找出中位数"><a class="markdownIt-Anchor" href="#如何从-5-亿个数中找出中位数"></a> 如何从 5 亿个数中找出中位数？</h2><h3 id="题目描述-4"><a class="markdownIt-Anchor" href="#题目描述-4"></a> 题目描述</h3><p>从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 <code>(N+1)/2</code> 个数；当样本数为偶数时，中位数为 第 <code>N/2</code> 个数与第 <code>1+N/2</code> 个数的均值。</p><h3 id="解答思路-4"><a class="markdownIt-Anchor" href="#解答思路-4"></a> 解答思路</h3><p>如果这道题没有内存大小限制，则可以把所有数读到内存中排序后找出中位数。但是最好的排序算法的时间复杂度都为 <code>O(NlogN)</code>。这里使用其他方法。</p><h4 id="方法一双堆法"><a class="markdownIt-Anchor" href="#方法一双堆法"></a> 方法一：双堆法</h4><p>维护两个堆，一个大顶堆，一个小顶堆。大顶堆中最大的数<strong>小于等于</strong>小顶堆中最小的数；保证这两个堆中的元素个数的差不超过 1。</p><p>若数据总数为<strong>偶数</strong>，当这两个堆建好之后，<strong>中位数就是这两个堆顶元素的平均值</strong>。当数据总数为<strong>奇数</strong>时，根据两个堆的大小，<strong>中位数一定在数据多的堆的堆顶</strong>。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MedianFinder</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> PriorityQueue&lt;Integer&gt; maxHeap;</span><br><span class="line">    <span class="keyword">private</span> PriorityQueue&lt;Integer&gt; minHeap;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** initialize your data structure here. */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MedianFinder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        maxHeap = <span class="keyword">new</span> PriorityQueue&lt;&gt;(Comparator.reverseOrder());</span><br><span class="line">        minHeap = <span class="keyword">new</span> PriorityQueue&lt;&gt;(Integer::compareTo);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addNum</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (maxHeap.isEmpty() || maxHeap.peek() &gt; num) &#123;</span><br><span class="line">            maxHeap.offer(num);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            minHeap.offer(num);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> size1 = maxHeap.size();</span><br><span class="line">        <span class="keyword">int</span> size2 = minHeap.size();</span><br><span class="line">        <span class="keyword">if</span> (size1 - size2 &gt; <span class="number">1</span>) &#123;</span><br><span class="line">            minHeap.offer(maxHeap.poll());</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (size2 - size1 &gt; <span class="number">1</span>) &#123;</span><br><span class="line">            maxHeap.offer(minHeap.poll());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">findMedian</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size1 = maxHeap.size();</span><br><span class="line">        <span class="keyword">int</span> size2 = minHeap.size();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> size1 == size2</span><br><span class="line">            ? (maxHeap.peek() + minHeap.peek()) * <span class="number">1.0</span> / <span class="number">2</span></span><br><span class="line">            : (size1 &gt; size2 ? maxHeap.peek() : minHeap.peek());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>见 LeetCode No.295：<a href="https://leetcode.com/problems/find-median-from-data-stream/" target="_blank" rel="noopener">https://leetcode.com/problems/find-median-from-data-stream/</a></p></blockquote><p>以上这种方法，需要把所有数据都加载到内存中。当数据量很大时，就不能这样了，因此，这种方法<strong>适用于数据量较小的情况</strong>。5 亿个数，每个数字占用 4B，总共需要 2G 内存。如果可用内存不足 2G，就不能使用这种方法了，下面介绍另一种方法。</p><h4 id="方法二分治法"><a class="markdownIt-Anchor" href="#方法二分治法"></a> 方法二：分治法</h4><p>分治法的思想是把一个大的问题逐渐转换为规模较小的问题来求解。</p><p>对于这道题，顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。</p><p>划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中，且是在 f0 中，从小到大排列的第 1.5 亿个数与它后面的一个数的平均值。</p><blockquote><p><strong>提示</strong>，5 亿数的中位数是第 2.5 亿与右边相邻一个数求平均值。若 f1 有一亿个数，那么中位数就是 f0 中从第 1.5 亿个数开始的两个数求得的平均值。</p></blockquote><p>对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。</p><blockquote><p><strong>注意</strong>，当数据总数为偶数，如果划分后两个文件中的数据有相同个数，那么中位数就是数据较小的文件中的最大值与数据较大的文件中的最小值的平均值。</p></blockquote><h3 id="方法总结-6"><a class="markdownIt-Anchor" href="#方法总结-6"></a> 方法总结</h3><p>分治法，真香！</p><h2 id="如何找出排名前-500-的数"><a class="markdownIt-Anchor" href="#如何找出排名前-500-的数"></a> 如何找出排名前 500 的数？</h2><h3 id="题目描述-5"><a class="markdownIt-Anchor" href="#题目描述-5"></a> 题目描述</h3><p>有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 20*500 个数中找出前 500 的数？</p><h3 id="解答思路-5"><a class="markdownIt-Anchor" href="#解答思路-5"></a> 解答思路</h3><p>对于 TopK 问题，最常用的方法是使用堆排序。对本题而言，假设数组降序排列，可以采用以下方法：</p><p>首先建立大顶堆，堆的大小为数组的个数，即为 20，把每个数组最大的值存到堆中。</p><p>接着删除堆顶元素，保存到另一个大小为 500 的数组中，然后向大顶堆插入删除的元素所在数组的下一个元素。</p><p>重复上面的步骤，直到删除完第 500 个元素，也即找出了最大的前 500 个数。</p><blockquote><p>为了在堆中取出一个数据后，能知道它是从哪个数组中取出的，从而可以从这个数组中取下一个值，可以把数组的指针存放到堆中，对这个指针提供比较大小的方法。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.PriorityQueue;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> https://github.com/yanglbme</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataWithSource</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">DataWithSource</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 数值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> value;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 记录数值来源的数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> source;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 记录数值在数组中的索引</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> index;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DataWithSource</span><span class="params">(<span class="keyword">int</span> value, <span class="keyword">int</span> source, <span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.source = source;</span><br><span class="line">        <span class="keyword">this</span>.index = index;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 由于 PriorityQueue 使用小顶堆来实现，这里通过修改</span></span><br><span class="line"><span class="comment">     * 两个整数的比较逻辑来让 PriorityQueue 变成大顶堆</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(DataWithSource o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Integer.compare(o.getValue(), <span class="keyword">this</span>.value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] getTop(<span class="keyword">int</span>[][] data) &#123;</span><br><span class="line">        <span class="keyword">int</span> rowSize = data.length;</span><br><span class="line">        <span class="keyword">int</span> columnSize = data[<span class="number">0</span>].length;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建一个columnSize大小的数组，存放结果</span></span><br><span class="line">        <span class="keyword">int</span>[] result = <span class="keyword">new</span> <span class="keyword">int</span>[columnSize];</span><br><span class="line"></span><br><span class="line">        PriorityQueue&lt;DataWithSource&gt; maxHeap = <span class="keyword">new</span> PriorityQueue&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; ++i) &#123;</span><br><span class="line">            <span class="comment">// 将每个数组的最大一个元素放入堆中</span></span><br><span class="line">            DataWithSource d = <span class="keyword">new</span> DataWithSource(data[i][<span class="number">0</span>], i, <span class="number">0</span>);</span><br><span class="line">            maxHeap.add(d);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (num &lt; columnSize) &#123;</span><br><span class="line">            <span class="comment">// 删除堆顶元素</span></span><br><span class="line">            DataWithSource d = maxHeap.poll();</span><br><span class="line">            result[num++] = d.getValue();</span><br><span class="line">            <span class="keyword">if</span> (num &gt;= columnSize) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            d.setValue(data[d.getSource()][d.getIndex() + <span class="number">1</span>]);</span><br><span class="line">            d.setIndex(d.getIndex() + <span class="number">1</span>);</span><br><span class="line">            maxHeap.add(d);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] data = &#123;</span><br><span class="line">                &#123;<span class="number">29</span>, <span class="number">17</span>, <span class="number">14</span>, <span class="number">2</span>, <span class="number">1</span>&#125;,</span><br><span class="line">                &#123;<span class="number">19</span>, <span class="number">17</span>, <span class="number">16</span>, <span class="number">15</span>, <span class="number">6</span>&#125;,</span><br><span class="line">                &#123;<span class="number">30</span>, <span class="number">25</span>, <span class="number">20</span>, <span class="number">14</span>, <span class="number">5</span>&#125;,</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] top = getTop(data);</span><br><span class="line">        System.out.println(Arrays.toString(top)); <span class="comment">// [30, 29, 25, 20, 19]</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="方法总结-7"><a class="markdownIt-Anchor" href="#方法总结-7"></a> 方法总结</h3><p>求 TopK，不妨考虑一下堆排序？</p><h2 id="如何按照-query-的频度排序"><a class="markdownIt-Anchor" href="#如何按照-query-的频度排序"></a> 如何按照 query 的频度排序？</h2><h3 id="题目描述-6"><a class="markdownIt-Anchor" href="#题目描述-6"></a> 题目描述</h3><p>有 10 个文件，每个文件大小为 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求按照 query 的频度排序。</p><h3 id="解答思路-6"><a class="markdownIt-Anchor" href="#解答思路-6"></a> 解答思路</h3><p>如果 query 的重复度比较大，可以考虑一次性把所有 query 读入内存中处理；如果 query 的重复率不高，那么可用内存不足以容纳所有的 query，这时候就需要采用分治法或其他的方法来解决。</p><h4 id="方法一hashmap-法"><a class="markdownIt-Anchor" href="#方法一hashmap-法"></a> 方法一：HashMap 法</h4><p>如果 query 重复率高，说明不同 query 总数比较小，可以考虑把所有的 query 都加载到内存中的 HashMap 中。接着就可以按照 query 出现的次数进行排序。</p><h4 id="方法二分治法-2"><a class="markdownIt-Anchor" href="#方法二分治法-2"></a> 方法二：分治法</h4><p>分治法需要根据数据量大小以及可用内存的大小来确定问题划分的规模。对于这道题，可以顺序遍历 10 个文件中的 query，通过 Hash 函数 <code>hash(query) % 10</code> 把这些 query 划分到 10 个小文件中。之后对每个小文件使用 HashMap 统计 query 出现次数，根据次数排序并写入到零外一个单独文件中。</p><p>接着对所有文件按照 query 的次数进行排序，这里可以使用归并排序（由于无法把所有 query 都读入内存，因此需要使用外排序）。</p><h3 id="方法总结-8"><a class="markdownIt-Anchor" href="#方法总结-8"></a> 方法总结</h3><ul><li>内存若够，直接读入进行排序；</li><li>内存不够，先划分为小文件，小文件排好序后，整理使用外排序进行归并。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;海量数据处理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#海量数据处理&quot;&gt;&lt;/a&gt; 海量数据处理&lt;/h1&gt;
&lt;h2 id=&quot;如何从海量的-url-中找出相同的-url&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; hre
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>design/architecture/ddd</title>
    <link href="https://dunwu.github.io/blog/design/architecture/ddd/"/>
    <id>https://dunwu.github.io/blog/design/architecture/ddd/</id>
    <published>2020-07-25T07:46:26.673Z</published>
    <updated>2020-07-25T07:46:26.673Z</updated>
    
    <content type="html"><![CDATA[<h1 id="领域驱动设计"><a class="markdownIt-Anchor" href="#领域驱动设计"></a> 领域驱动设计</h1><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#ddd-%E7%AE%80%E4%BB%8B">DDD 简介</a><ul><li><a href="#%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%BC%94%E8%BF%9B">软件架构模式的演进</a></li><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF-ddd">什么是 DDD</a></li><li><a href="#ddd-%E4%B8%8E%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%85%B3%E7%B3%BB">DDD 与微服务的关系</a></li></ul></li><li><a href="#ddd-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5">DDD 核心概念</a><ul><li><a href="#%E5%9F%9F">域</a></li><li><a href="#%E9%80%9A%E7%94%A8%E8%AF%AD%E8%A8%80%E5%92%8C%E4%B8%8A%E4%B8%8B%E6%96%87%E8%BE%B9%E7%95%8C">通用语言和上下文边界</a></li><li><a href="#%E5%AE%9E%E4%BD%93%E5%92%8C%E5%80%BC%E5%AF%B9%E8%B1%A1">实体和值对象</a></li><li><a href="#%E8%81%9A%E5%90%88%E5%92%8C%E8%81%9A%E5%90%88%E8%B7%9F">聚合和聚合跟</a></li></ul></li><li><a href="#%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B">架构模型</a><ul><li><a href="#ddd-%E6%9E%B6%E6%9E%84">DDD 架构</a></li><li><a href="#%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84">整洁架构</a></li><li><a href="#%E5%85%AD%E8%BE%B9%E5%BD%A2%E6%9E%B6%E6%9E%84">六边形架构</a></li><li><a href="#%E4%B8%89%E7%A7%8D%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94">三种架构对比</a></li></ul></li><li><a href="#%E4%B8%AD%E5%8F%B0%E6%88%98%E7%95%A5">中台战略</a><ul><li><a href="#%E5%B9%B3%E5%8F%B0%E4%B8%8D%E6%98%AF%E4%B8%AD%E5%8F%B0">平台不是中台</a></li><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%AD%E5%8F%B0">什么是中台</a></li><li><a href="#%E6%95%B0%E5%AD%97%E5%8C%96%E8%BD%AC%E5%9E%8B%E4%B8%AD%E5%8F%B0">数字化转型中台</a></li><li><a href="#%E5%89%8D%E4%B8%AD%E5%90%8E%E5%8F%B0%E5%8D%8F%E5%90%8C">前中后台协同</a></li><li><a href="#ddd%E4%B8%AD%E5%8F%B0%E5%92%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%8D%8F%E4%BD%9C">DDD、中台和微服务的协作</a></li><li><a href="#%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E4%B8%AD%E5%8F%B0">如何构建中台</a></li></ul></li><li><a href="#%E8%BE%B9%E7%95%8C">边界</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="ddd-简介"><a class="markdownIt-Anchor" href="#ddd-简介"></a> DDD 简介</h2><h3 id="软件架构模式的演进"><a class="markdownIt-Anchor" href="#软件架构模式的演进"></a> 软件架构模式的演进</h3><p>**第一阶段是单机架构：**采用面向过程的设计方法，系统包括客户端 UI 层和数据库两层，采用 C/S 架构模式，整个系统围绕数据库驱动设计和开发，并且总是从设计数据库和字段开始。</p><p>**第二阶段是集中式架构：**采用面向对象的设计方法，系统包括业务接入层、业务逻辑层和数据库层，采用经典的三层架构，也有部分应用采用传统的 SOA 架构。这种架构容易使系统变得臃肿，可扩展性和弹性伸缩性差。</p><p>**第三阶段是分布式微服务架构：**随着微服务架构理念的提出，集中式架构正向分布式微服务架构演进。微服务架构可以很好地实现应用之间的解耦，解决单体应用扩展性和弹性伸缩能力不足的问题。</p><p>在单机和集中式架构时代，系统分析、设计和开发往往是独立、分阶段割裂进行的。</p><h3 id="什么是-ddd"><a class="markdownIt-Anchor" href="#什么是-ddd"></a> 什么是 DDD</h3><p>DDD 是一种处理高度复杂领域的<strong>设计思想</strong>，它试图分离技术实现的复杂性，并<strong>围绕业务概念构建领域模型来控制业务的复杂性</strong>，以解决软件难以理解，难以演进的问题。DDD 不是架构，而是一种架构设计方法论，它通过边界划分将复杂业务领域简单化，帮我们设计出清晰的领域和应用边界，可以很容易地实现架构演进。DDD 分为两个思维层面：</p><ul><li>战略设计主要从业务视角出发，建立业务领域模型，划分领域边界，建立通用语言的上下文边界，上下文边界可以作为微服务设计的参考边界。</li><li>战术设计则从技术视角出发，侧重于领域模型的技术实现，完成软件开发和落地，包括：聚合根、实体、值对象、领域服务、应用服务和资源库等代码逻辑的设计和实现。</li></ul><h3 id="ddd-与微服务的关系"><a class="markdownIt-Anchor" href="#ddd-与微服务的关系"></a> DDD 与微服务的关系</h3><p><strong>DDD 是一种架构设计方法，微服务是一种架构风格</strong>。两者都是为了拆解业务复杂度：合理划分领域边界，持续调整现有架构，优化现有代码，以保持架构和代码的生命力，也就是我们常说的演进式架构。</p><p>DDD 主要关注：<strong>从业务领域视角划分领域边界</strong>，构建通用语言进行高效沟通，通过业务抽象，建立领域模型，维持业务和代码的逻辑一致性。</p><p>微服务主要关注：<strong>运行时的进程间通信、容错和故障隔离</strong>，实现去中心化数据管理和去中心化服务治理，关注微服务的独立开发、测试、构建和部署。</p><h2 id="ddd-核心概念"><a class="markdownIt-Anchor" href="#ddd-核心概念"></a> DDD 核心概念</h2><p><img src="http://dunwu.test.upcdn.net/snap/20200719231154.png" alt="img" /></p><h3 id="域"><a class="markdownIt-Anchor" href="#域"></a> 域</h3><ul><li><strong>领域</strong>：领域具体指一种特定的<strong>范围</strong>。领域是用来限定业务边界的，那么就会有大小之分，领域越大，业务范围就越大，反之则相反。</li><li><strong>子域</strong>：领域可以进一步划分为子领域。我们把划分出来的多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围。</li><li><strong>核心域</strong>：决定产品和公司核心竞争力的子域是核心域。</li><li><strong>通用域</strong>：同时被多个子域使用的通用功能子域是通用域。</li><li><strong>支撑域</strong>：还有一种功能子域是必需的，但既非核心域也非通用域，它就是支撑域。</li></ul><blockquote><p><strong>领域的核心思想就是将问题域逐级细分，来降低业务理解和系统实现的复杂度</strong>。通过领域细分，逐步缩小微服务需要解决的问题域，构建合适的领域模型，而领域模型映射成系统就是微服务了。</p><p>核心域、支撑域和通用域的主要目标是：通过领域划分，区分不同子域在公司内的不同功能属性和重要性，从而公司可对不同子域采取不同的资源投入和建设策略，其关注度也会不一样。</p></blockquote><h3 id="通用语言和上下文边界"><a class="markdownIt-Anchor" href="#通用语言和上下文边界"></a> 通用语言和上下文边界</h3><p><strong>通用语言</strong>：通过团队交流达成共识性的，能够简单、清晰、准确描述业务涵义和规则的语言。</p><p><strong>上下文边界</strong>：限界就是领域的边界，而上下文则是语义环境。通过领域的上下文边界，我们就可以在统一的领域边界内用统一的语言进行交流。综合一下，上下文边界的定义就是：用来封装通用语言和领域对象，提供上下文环境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。这个边界定义了模型的适用范围，使团队所有成员能够明确地知道什么应该在模型中实现，什么不应该在模型中实现。</p><h3 id="实体和值对象"><a class="markdownIt-Anchor" href="#实体和值对象"></a> 实体和值对象</h3><p>实体是多个属性、操作或行为的载体。在事件风暴中，我们可以根据命令、操作或者事件，找出产生这些行为的业务实体对象，进而按照一定的业务规则将依存度高和业务关联紧密的多个实体对象和值对象进行聚类，形成聚合。你可以这么理解，实体和值对象是组成领域模型的基础单元。</p><p>本质上，实体是看得到、摸得着的实实在在的业务对象，实体具有业务属性、业务行为和业务逻辑。而值对象只是若干个属性的集合，只有数据初始化操作和有限的不涉及修改数据的行为，基本不包含业务逻辑。值对象的属性集虽然在物理上独立出来了，但在逻辑上它仍然是实体属性的一部分，用于描述实体的特征。</p><h3 id="聚合和聚合跟"><a class="markdownIt-Anchor" href="#聚合和聚合跟"></a> 聚合和聚合跟</h3><p>领域模型内的实体和值对象就好比个体，而能让实体和值对象协同工作的组织就是聚合，它用来确保这些领域对象在实现共同的业务逻辑时，能保证数据的一致性。</p><p>聚合就是由业务和逻辑紧密关联的实体和值对象组合而成的，聚合是数据修改和持久化的基本单元，每一个聚合对应一个仓储，实现数据的持久化。聚合有一个聚合根和上下文边界，这个边界根据业务单一职责和高内聚原则，定义了聚合内部应该包含哪些实体和值对象，而聚合之间的边界是松耦合的。</p><p>聚合根的主要目的是为了避免由于复杂数据模型缺少统一的业务规则控制，而导致聚合、实体之间数据不一致性的问题。如果把聚合比作组织，那聚合根就是这个组织的负责人。聚合根也称为根实体，它不仅是实体，还是聚合的管理者。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200719152031.png" alt="img" /></p><h4 id="聚合设计步骤"><a class="markdownIt-Anchor" href="#聚合设计步骤"></a> 聚合设计步骤</h4><ul><li>第 1 步：采用事件风暴，根据业务行为，梳理出所有的实体和值对象。</li><li>第 2 步：从众多实体中选出适合作为对象管理者的根实体，也就是聚合根。判断一个实体<br />是否是聚合根，你可以结合以下场景分析：是否有独立的生命周期？是否有全局唯一 ID？<br />是否可以创建或修改其它对象？是否有专门的模块来管这个实体。</li><li>第 3 步：根据业务单一职责和高内聚原则，找出与聚合根关联的所有紧密依赖的实体和值<br />对象。</li><li>第 4 步：在聚合内根据聚合根、实体和值对象的依赖关系，画出对象的引用和依赖模型。</li><li>第 5 步：多个聚合根据业务语义和上下文一起划分到同一个限界上下文内。</li></ul><h4 id="聚合设计原则"><a class="markdownIt-Anchor" href="#聚合设计原则"></a> 聚合设计原则</h4><ul><li>在一致性边界内建模真正的不变条件。</li><li>设计小聚合。</li><li>通过唯一标识引用其它聚合。</li><li>在边界之外使用最终一致性。</li><li>通过应用层实现跨聚合的服务调用。</li></ul><h2 id="架构模型"><a class="markdownIt-Anchor" href="#架构模型"></a> 架构模型</h2><h3 id="ddd-架构"><a class="markdownIt-Anchor" href="#ddd-架构"></a> DDD 架构</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200719223353.png" alt="img" /></p><p>三层架构向 DDD 分层架构演进，主要发生在业务逻辑层和数据访问层。</p><p>DDD 分层架构包含用户接口层、应用层、领域层和基础层。通过这些层次划分，我们可以明确微服务各层的职能，划定各领域对象的边界，确定各领域对象的协作方式。</p><h3 id="整洁架构"><a class="markdownIt-Anchor" href="#整洁架构"></a> 整洁架构</h3><p>在整洁架构里，同心圆代表应用软件的不同部分，从里到外依次是领域模型、领域服务、应用服务和最外围的容易变化的内容，比如用户界面和基础设施。</p><p>整洁架构最主要的原则是依赖原则，它定义了各层的依赖关系，越往里依赖越低，代码级别越高，越是核心能力。外圆代码依赖只能指向内圆，内圆不需要知道外圆的任何情况。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200719223906.png" alt="img" /></p><h3 id="六边形架构"><a class="markdownIt-Anchor" href="#六边形架构"></a> 六边形架构</h3><p>六边形架构的核心理念是：应用是通过端口与外部进行交互的。我想这也是微服务架构下 API 网关盛行的主要原因吧。</p><p>也就是说，在下图的六边形架构中，红圈内的核心业务逻辑（应用程序和领域模型）与外部资源（包括 APP、Web 应用以及数据库资源等）完全隔离，仅通过适配器进行交互。它解决了业务逻辑与用户界面的代码交错问题，很好地实现了前后端分离。六边形架构各层的依赖关系与整洁架构一样，都是由外向内依赖。</p><p>六边形架构将系统分为内六边形和外六边形两层，这两层的职能划分如下：</p><p>红圈内的六边形实现应用的核心业务逻辑；</p><p>外六边形完成外部应用、驱动和基础资源等的交互和访问，对前端应用以 API 主动适配的方式提供服务，对基础资源以依赖倒置被动适配的方式实现资源访问。</p><h3 id="三种架构对比"><a class="markdownIt-Anchor" href="#三种架构对比"></a> 三种架构对比</h3><p>这三种架构模型的设计思想正是微服务架构高内聚低耦合原则的完美体现。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200719224313.png" alt="img" /></p><h4 id="架构模型和中台-微服务的联系"><a class="markdownIt-Anchor" href="#架构模型和中台-微服务的联系"></a> 架构模型和中台、微服务的联系</h4><p>中台本质上是领域的子域，它可能是核心域，也可能是通用域或支撑域。通常大家认为阿里的中台对应 DDD 的通用域，将通用的公共能力沉淀为中台，对外提供通用共享服务。</p><p>DDD、中台、微服务这三者之间似乎没什么关联，实际上它们的关系是非常紧密的，组合在一起可以作为<br />一个理论体系用于你的中台和微服务设计。</p><h4 id="中台建设要聚焦领域模型"><a class="markdownIt-Anchor" href="#中台建设要聚焦领域模型"></a> 中台建设要聚焦领域模型</h4><p>中台需要站在全企业的高度考虑能力的共享和复用。</p><p>中台设计时，我们需要建立中台内所有限界上下文的领域模型，DDD 建模过程中会考虑架构演进和功能的重新组合。领域模型建立的过程会对业务和应用进行清晰的逻辑和物理边界（微服务）划分。领域模型的结果会影响到后续的系统模型、架构模型和代码模型，最终影响到微服务的拆分和项目落地。</p><h4 id="微服务要有合理的架构分层"><a class="markdownIt-Anchor" href="#微服务要有合理的架构分层"></a> 微服务要有合理的架构分层</h4><p>微服务设计要有分层的设计思想，让各层各司其职，建立松耦合的层间关系。</p><p>不要把与领域无关的逻辑放在领域层实现，保证领域层的纯洁和领域逻辑的稳定，避免污染领域模型。也不要把领域模型的业务逻辑放在应用层，这样会导致应用层过于庞大，最终领域模型会失焦。</p><h4 id="应用和资源的解耦与适配"><a class="markdownIt-Anchor" href="#应用和资源的解耦与适配"></a> 应用和资源的解耦与适配</h4><p>传统以数据为中心的设计模式，应用会对数据库、缓存、文件系统等基础资源产生严重依赖。</p><p>正是由于它们之间的这种强依赖的关系，我们一旦更换基础资源就会对应用产生很大的影响，因此需要为应用和资源解耦。</p><h2 id="中台战略"><a class="markdownIt-Anchor" href="#中台战略"></a> 中台战略</h2><h3 id="平台不是中台"><a class="markdownIt-Anchor" href="#平台不是中台"></a> 平台不是中台</h3><p>中台源于平台，但它的战略高度要比平台高很多。</p><p><strong>平台只是将部分通用的公共能力独立为共享平台</strong>。虽然可以通过 API 或者数据对外提供公共共享服务，解决系统重复建设的问题，但这类平台并没有和企业内的其它平台或应用，实现页面、业务流程和数据从前端到后端的全面融合，并且<strong>没有将核心业务服务链路作为一个整体方案考虑，各平台仍然是分离且独立的</strong>。</p><p>简单的理解就是把传统的前后台体系中的后台进行了细分。阿里巴巴提出了<strong>大中台小前台</strong>的战略。就是强化业务和技术中台，把前端的应用变得更小更灵活。当中台越强大，能力就越强，越能更好的快速响应前台的业务需求。打个比喻，就是土壤越肥沃，越适合生长不同的生物，打造好的生态系统。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200716194609.png" alt="img" /></p><h3 id="什么是中台"><a class="markdownIt-Anchor" href="#什么是中台"></a> 什么是中台</h3><p>中台是一个基础的理念和架构，我们要把所有的基础服务用中台的思路建设，进行联通，共同支持上端的业务。业务中台更多的是支持在线业务，数据中台提供了基础数据处理能力和很多的数据产品给所有业务方去用。业务中台、数据中台、算法中台等等一起提供对上层业务的支撑。</p><p>中台的关键词：<strong>共享、联通、融合和创新</strong>。联通是前台以及中台之间的联通，融合是前台流程和数据的融合，并以共享的方式支持前端一线业务的发展和创新。其中最关键的是快速响应能力和企业级的无缝联通和融合能力，尤其是对于跨业经营的超大型企业来说至关重要。</p><h3 id="数字化转型中台"><a class="markdownIt-Anchor" href="#数字化转型中台"></a> 数字化转型中台</h3><h3 id="前中后台协同"><a class="markdownIt-Anchor" href="#前中后台协同"></a> 前中后台协同</h3><h4 id="前台"><a class="markdownIt-Anchor" href="#前台"></a> 前台</h4><p>在前台设计中我们可以借鉴微前端的设计思想，在企业内不仅实现前端解耦和复用，还可以根据核心链路和业务流程，通过对微前端页面的动态组合和流程编排，实现前台业务的融合。</p><p>前端页面可以很自然地融合到不同的终端和渠道应用核心业务链路中，实现前端页面、流程和功能复用。</p><h4 id="中台"><a class="markdownIt-Anchor" href="#中台"></a> 中台</h4><p>业务中台的建设可采用领域驱动设计方法，通过领域建模，将可复用的公共能力从各个单体剥离，沉淀并组合，采用微服务架构模式，建设成为可共享的通用能力中台。</p><p>同样的，我们可以将核心能力用微服务架构模式，建设成为可面向不同渠道和场景的可复用的核心能力中台。 业务中台向前台、第三方和其它中台提供 API 服务，实现通用能力和核心能力的复用。</p><p>数据中台的主要目标是打通数据孤岛，实现业务融合和创新，包括三大主要职能：</p><ul><li>一是完成企业全域数据的采集与存储，实现各不同业务类别中台数据的汇总和集中管理。</li><li>二是按照标准的数据规范或数据模型，将数据按照不同主题域或场景进行加工和处理，形成面向不同主题和场景的数据应用，比如客户视图、代理人视图、渠道视图、机构视图等不同数据体系。</li><li>三是建立业务需求驱动的数据体系，基于各个维度的数据，深度萃取数据价值，支持业务和商业模式的创新。</li></ul><p>相应的，数据中台的建设就可分为三步走：</p><ul><li>第一步实现各中台业务数据的汇集，解决数据孤岛和初级数据共享问题。</li><li>第二步实现企业级实时或非实时全维度数据的深度融合、加工和共享。</li><li>第三步萃取数据价值，支持业务创新，加速从数据转换为业务价值的过程。</li></ul><h4 id="后台"><a class="markdownIt-Anchor" href="#后台"></a> 后台</h4><p>前台主要面向客户以及终端销售者，实现营销推广以及交易转化；中台主要面向运营人员，完成运营支撑；后台主要面向后台管理人员，实现流程审核、内部管理以及后勤支撑，比如采购、人力、财务和 OA 等系统。</p><h3 id="ddd-中台和微服务的协作"><a class="markdownIt-Anchor" href="#ddd-中台和微服务的协作"></a> DDD、中台和微服务的协作</h3><p>传统企业可以将需要共享的公共能力进行领域建模，建设可共享的通用中台。除此之外，传统企业还会将核心能力进行领域建模，建设面向不同渠道的可复用的核心中台。</p><h3 id="如何构建中台"><a class="markdownIt-Anchor" href="#如何构建中台"></a> 如何构建中台</h3><h4 id="自顶向下策略"><a class="markdownIt-Anchor" href="#自顶向下策略"></a> 自顶向下策略</h4><p>自顶向下的策略适用于全新的应用系统建设，或旧系统推倒重建的情况。这种策略是先做顶层设计，从最高领域逐级分解为中台，分别建立领域模型，根据业务属性分为通用中台或核心中台。领域建模过程主要基于业务现状，暂时不考虑系统现状。</p><h4 id="自顶向下策略-2"><a class="markdownIt-Anchor" href="#自顶向下策略-2"></a> 自顶向下策略</h4><p>自底向上策略适用于遗留系统业务模型的演进式重构。这种策略是基于业务和系统现状完成领域建模。首先分别完成系统所在业务域的领域建模；然后对齐业务域，找出具有同类或相似业务功能的领域模型，对比分析领域模型的差异，重组领域对象，重构领域模型。这个过程会沉淀公共和复用的业务能力，会将分散的业务模型整合。</p><h4 id="构建步骤"><a class="markdownIt-Anchor" href="#构建步骤"></a> 构建步骤</h4><p>第一步：锁定系统所在业务域，构建领域模型。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200720063540.png" alt="img" /></p><p>第二步：对齐业务域，构建中台业务模型。</p><p>第三步：中台归类，根据领域模型设计微服务。</p><h2 id="边界"><a class="markdownIt-Anchor" href="#边界"></a> 边界</h2><p>逻辑边界：微服务内聚合之间的边界是逻辑边界。它是一个虚拟的边界，强调业务的内聚，可根据需要变成物理边界，也就是说聚合也可以独立为微服务。</p><p>物理边界：微服务之间的边界是物理边界。它强调微服务部署和运行的隔离，关注微服务的服务调用、容错和运行等。</p><p>代码边界：不同层或者聚合之间代码目录的边界是代码边界。它强调的是代码之间的隔离，方便架构演进时代码的重组。</p><p>通过以上边界，我们可以让业务能力高内聚、代码松耦合，且清晰的边界，可以快速实现微服务代码的拆分和组合，轻松实现微服务架构演进。但有一点一定要格外注意，边界清晰的微服务，不是大单体向小单体的演进。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://time.geekbang.org/column/intro/100037301" target="_blank" rel="noopener">DDD 实战课</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;领域驱动设计&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#领域驱动设计&quot;&gt;&lt;/a&gt; 领域驱动设计&lt;/h1&gt;
&lt;!-- TOC depthFrom:2 depthTo:3 --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#ddd-%E7%A
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>design/architecture/system-architecture-interview</title>
    <link href="https://dunwu.github.io/blog/design/architecture/system-architecture-interview/"/>
    <id>https://dunwu.github.io/blog/design/architecture/system-architecture-interview/</id>
    <published>2020-07-25T07:46:26.673Z</published>
    <updated>2020-07-25T07:46:26.673Z</updated>
    
    <content type="html"><![CDATA[<h1 id="系统架构面试"><a class="markdownIt-Anchor" href="#系统架构面试"></a> 系统架构面试</h1><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F">如何设计一个秒杀系统？</a><ul><li><a href="#%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%91%E6%88%98">秒杀系统的挑战</a></li><li><a href="#%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF">秒杀系统的解决思路</a></li><li><a href="#%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">秒杀系统的解决方案</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="如何设计一个秒杀系统"><a class="markdownIt-Anchor" href="#如何设计一个秒杀系统"></a> 如何设计一个秒杀系统？</h2><h3 id="秒杀系统的挑战"><a class="markdownIt-Anchor" href="#秒杀系统的挑战"></a> 秒杀系统的挑战</h3><p>秒杀的核心问题就是<strong>极高并发处理</strong>，由于系统要在瞬时承受平时数十倍甚至上百倍的流量，这往往超出系统上限，因此处理秒杀的<strong>核心思路是限流和缓存</strong>。</p><h3 id="秒杀系统的解决思路"><a class="markdownIt-Anchor" href="#秒杀系统的解决思路"></a> 秒杀系统的解决思路</h3><ul><li>系统上有拦截流量：尽可能在上游拦截和限制请求，限制流入后端的量，保证后端系统正常。 因为无论多少人参与秒杀，实际成交往往是有限的，而且远小于参加秒杀的人数，因此可以通过前端系统进行拦截，限制最终流入系统的请求数量，来保证系统正常进行。</li><li>充分利用缓存：这是一个典型的读多写少的应用场景（一趟火车其实只有 2000 张票，200w 个人来买，最多 2000 个人下单成功，其他人都是查询库存，写比例只有 0.1%，读比例占 99.9%），非常适合使用缓存。</li></ul><h3 id="秒杀系统的解决方案"><a class="markdownIt-Anchor" href="#秒杀系统的解决方案"></a> 秒杀系统的解决方案</h3><p>秒杀系统具体方案如下：</p><p><strong>（1）浏览器、客户端拦截重复请求</strong></p><ul><li>用户点击查询或购买按钮后，禁用按钮，避免用户重复提交请求。</li><li>JS 代码中限制用户在限定时间内只允许提交一次请求</li></ul><p>基于此，大部分流量已被拦截。</p><p><strong>（2）应用层拦截请求</strong></p><p>浏览器、客户端拦截重复请求只能应付通过浏览器访问的用户。如果有人通过程序发送 http 请求，则无法拦截。针对这种情况的方案是：</p><p>以页面缓存的方式，针对短时间内的同一个访问源（如同一个 IP、同一个 Session、同一个用户 ID 多次发送 HTTP 请求）或同样的查询请求（如大量请求都是查询某类商品的库存），都返回相同的展示页面。</p><p>如此限流，又有大部分的流量被拦截</p><p>（3）服务层请求拦截与数据缓存</p><p>加入有黑客，控制了 10w 台肉鸡（并且假设买票不需要实名认证），前面的的限制都不起作用了。这时应该怎么办？</p><ul><li><p>读请求（查库存） - 对于读请求，直接使用缓存即可，一般缓存服务器单机处理每秒 10w 个请求应该没什么问题。</p></li><li><p>写请求（下单） - 由于服务层清楚的知道库存数量，所以完全可以根据库存数量进行限流。具体来说，就是把所有下单请求都丢该消息队列中，每次只取有限的写请求去数据层处理。当这些写请求处理完，更新一下缓存中的库存数，再去取下一批写请求，如果库存数不够，则消息队列的写请求全部返回&quot;已售罄&quot;的结果。</p></li></ul><blockquote><p>参考：</p><ul><li><a href="https://www.zhihu.com/question/54895548/answer/146924420" target="_blank" rel="noopener">如何设计秒杀系统？ - 阿里云云栖社区的回答 - 知乎</a></li><li><a href="https://www.zhihu.com/question/54895548/answer/259218876" target="_blank" rel="noopener">如何设计秒杀系统？ - 网易云的回答 - 知乎</a></li></ul></blockquote><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://www.zhihu.com/question/54895548/answer/146924420" target="_blank" rel="noopener">如何设计秒杀系统？ - 阿里云云栖社区的回答 - 知乎</a></li><li><a href="https://www.zhihu.com/question/54895548/answer/259218876" target="_blank" rel="noopener">如何设计秒杀系统？ - 网易云的回答 - 知乎</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;系统架构面试&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#系统架构面试&quot;&gt;&lt;/a&gt; 系统架构面试&lt;/h1&gt;
&lt;!-- TOC depthFrom:2 depthTo:3 --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E5%A6%82
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>微服务理论</title>
    <link href="https://dunwu.github.io/blog/theory/micro-services/"/>
    <id>https://dunwu.github.io/blog/theory/micro-services/</id>
    <published>2020-07-21T07:35:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="微服务理论"><a class="markdownIt-Anchor" href="#微服务理论"></a> 微服务理论</h1><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B">一、微服务简介</a><ul><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84">什么是微服务架构</a></li><li><a href="#%E5%A6%82%E4%BD%95%E6%9D%83%E8%A1%A1%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%88%A9%E5%BC%8A">如何权衡微服务的利弊</a></li><li><a href="#%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B">康威定律</a></li><li><a href="#%E5%A6%82%E4%BD%95%E6%8B%86%E5%88%86%E5%BE%AE%E6%9C%8D%E5%8A%A1">如何拆分微服务</a></li></ul></li><li><a href="#%E4%BA%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84">二、微服务技术架构</a></li><li><a href="#%E4%B8%89%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0">三、服务注册发现</a><ul><li><a href="#%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%BC%8F">注册中心实现模式</a></li><li><a href="#%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98">服务注册发现的问题</a></li><li><a href="#%E8%AF%86%E5%88%AB%E6%9C%8D%E5%8A%A1%E8%8A%82%E7%82%B9%E6%98%AF%E5%90%A6%E5%AD%98%E6%B4%BB">识别服务节点是否存活</a></li></ul></li><li><a href="#%E5%9B%9B%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1">四、服务通信</a></li><li><a href="#%E4%BA%94api-%E7%BD%91%E5%85%B3">五、API 网关</a><ul><li><a href="#zuul">Zuul</a></li></ul></li><li><a href="#%E5%85%AD%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86">六、服务治理</a></li><li><a href="#%E4%B8%83%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">七、负载均衡</a></li><li><a href="#%E5%85%AB%E6%9C%8D%E5%8A%A1%E8%B7%AF%E7%94%B1">八、服务路由</a><ul><li><a href="#%E5%86%85%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8">内部服务调用</a></li><li><a href="#%E5%A4%96%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8">外部服务调用</a></li></ul></li><li><a href="#%E4%B9%9D%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83">九、配置中心</a><ul><li><a href="#apollo">Apollo</a></li><li><a href="#spring-cloud-git">Spring Cloud Git</a></li></ul></li><li><a href="#%E5%8D%81%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7">十、服务监控</a><ul><li><a href="#%E7%9B%91%E6%8E%A7%E5%AF%B9%E8%B1%A1">监控对象</a></li><li><a href="#%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E5%8E%9F%E7%90%86">系统监控原理</a></li><li><a href="#%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF">监控技术</a></li></ul></li><li><a href="#%E5%8D%81%E4%B8%80%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA">十一、链路追踪</a><ul><li><a href="#%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E7%9A%84%E4%BD%9C%E7%94%A8">链路追踪的作用</a></li><li><a href="#%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E7%9A%84%E5%8E%9F%E7%90%86">链路追踪的原理</a></li><li><a href="#%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E7%9A%84%E5%AE%9E%E7%8E%B0">链路追踪的实现</a></li><li><a href="#%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94">链路追踪方案对比</a></li></ul></li><li><a href="#%E5%8D%81%E4%B8%80%E9%99%90%E6%B5%81%E7%86%94%E6%96%AD">十一、限流熔断</a></li><li><a href="#%E5%8D%81%E4%BA%8Cdevops">十二、DEVOPS</a><ul><li><a href="#%E5%AE%B9%E5%99%A8%E5%92%8C%E5%AE%B9%E5%99%A8%E5%B9%B3%E5%8F%B0">容器和容器平台</a></li></ul></li><li><a href="#%E5%8D%81%E4%B8%89rpc-%E9%80%89%E5%9E%8B">十三、RPC 选型</a><ul><li><a href="#%E9%99%90%E5%AE%9A%E8%AF%AD%E8%A8%80-rpc">限定语言 RPC</a></li><li><a href="#%E8%B7%A8%E8%AF%AD%E8%A8%80-rpc">跨语言 RPC</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-微服务简介"><a class="markdownIt-Anchor" href="#一-微服务简介"></a> 一、微服务简介</h2><h3 id="什么是微服务架构"><a class="markdownIt-Anchor" href="#什么是微服务架构"></a> 什么是微服务架构</h3><ul><li><strong>服务拆分粒度更细</strong>：根据业务拆分。</li><li><strong>独立部署</strong>：每个服务部署在物理上隔离，互不影响。</li><li><strong>独立维护</strong>：根据组织架构拆分，分团队维护。</li><li><strong>服务治理</strong>：服务数量变多，需要有统一的服务治理平台。</li></ul><h3 id="如何权衡微服务的利弊"><a class="markdownIt-Anchor" href="#如何权衡微服务的利弊"></a> 如何权衡微服务的利弊</h3><p>优点</p><ul><li>强模块化边界</li><li>可独立部署</li><li>技术多样性</li></ul><p>缺点</p><ul><li>分布式复杂度</li><li>最终一致性</li><li>运维复杂度</li><li>测试复杂度</li></ul><h3 id="康威定律"><a class="markdownIt-Anchor" href="#康威定律"></a> 康威定律</h3><ul><li>第一定律：组织沟通方式会通过系统设计表达出来</li><li>第二定律：时间再多一件事情也不可能做的完美，但总有时间做完一件事情</li><li>第三定律：线型系统和线型组织架构间有潜在的异质同态特性</li><li>第四定律：大的系统组织总是比小系统更倾向于分解</li></ul><h3 id="如何拆分微服务"><a class="markdownIt-Anchor" href="#如何拆分微服务"></a> 如何拆分微服务</h3><p>思考维度：</p><ul><li>根据<strong>业务维度</strong>聚类，业务和数据关系密切的应该放在一起。</li><li>根据<strong>功能维度</strong>聚类，公共功能聚合为一个服务。</li><li>根据<strong>组织架构</strong>聚类，根据实际组织架构，天然分为不同的团队，每个团队独立维护若干微服务。</li></ul><p>前置条件：</p><ul><li>服务如何定</li><li>服务如何发布和订阅</li><li>服务如何监控</li><li>服务如何治理</li><li>故障如何定位</li></ul><h2 id="二-微服务技术架构"><a class="markdownIt-Anchor" href="#二-微服务技术架构"></a> 二、微服务技术架构</h2><p><img src="http://dunwu.test.upcdn.net/snap/20200716195006.png" alt="img" /></p><p><strong>第一层：接入层</strong></p><p>外部设备访问的统一接入层。</p><p><strong>第二层：聚合服务层</strong></p><p>对下层的基础服务做一些聚合，剪裁的工作，适配上层不同设备的数据输出。</p><p><strong>第三层：基础服务层</strong></p><p>比较细粒度的微服务层，提供基础的核心服务，公共服务。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200716195117.png" alt="img" /></p><h2 id="三-服务注册发现"><a class="markdownIt-Anchor" href="#三-服务注册发现"></a> 三、服务注册发现</h2><p>在微服务架构下，主要有三种角色：</p><ul><li>服务提供者（RPC Server / Provider）</li><li>服务消费者（RPC Client / Consumer）</li><li>服务注册中心（Registry）</li></ul><p>注册中心的实现依赖以下机制：</p><ul><li>注册中心 API</li><li>集群部署：如果注册中心是单点，无法保障高可用。</li><li>元数据存储：例如 ZooKeeper 将数据以层次化的目录结构存储。</li><li>服务健康检查：使用长连接或心跳探测方式检查服务健康状态。</li><li>服务状态变更通知：可以基于订阅者模式实现，例如 ZooKeeper 的 Watch 机制。</li><li>白名单机制</li></ul><p>注册中心的服务注册和发现都是基于 API 的。一般需要支持以下功能：</p><ul><li>服务注册</li><li>服务注销</li><li>接口续约（心跳）</li><li>服务订阅</li><li>可用服务同步</li><li>服务查询</li><li>服务修改</li></ul><h3 id="注册中心实现模式"><a class="markdownIt-Anchor" href="#注册中心实现模式"></a> 注册中心实现模式</h3><h4 id="应用内注册和发现"><a class="markdownIt-Anchor" href="#应用内注册和发现"></a> 应用内注册和发现</h4><p>采用应用内注册与发现的方式，最典型的案例要属 Netflix 开源的 Eureka，官方架构图如下。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200720194412.png" alt="img" /></p><p>对着这张图，我来介绍下 Eureka 的架构，它主要由三个重要的组件组成：</p><ul><li>Eureka Server：注册中心的服务端，实现了服务信息注册、存储以及查询等功能。</li><li>服务端的 Eureka Client：集成在服务端的注册中心 SDK，服务提供者通过调用 SDK，实现服务注册、反注册等功能。</li><li>客户端的 Eureka Client：集成在客户端的注册中心 SDK，服务消费者通过调用 SDK，实现服务订阅、服务更新等功能。</li></ul><h4 id="应用外注册和发现"><a class="markdownIt-Anchor" href="#应用外注册和发现"></a> 应用外注册和发现</h4><p><img src="http://dunwu.test.upcdn.net/snap/20200720194519.png" alt="img" /></p><p>通过这张架构图，可以看出来使用 Consul 实现应用外服务注册和发现主要依靠三个重要的组件：</p><ul><li>Consul：注册中心的服务端，实现服务注册信息的存储，并提供注册和发现服务。</li><li><a href="https://github.com/gliderlabs/registrator" target="_blank" rel="noopener">Registrator</a>：一个开源的第三方服务管理器项目，它通过监听服务部署的 Docker 实例是否存活，来负责服务提供者的注册和销毁。</li><li><a href="https://github.com/hashicorp/consul-template" target="_blank" rel="noopener">Consul Template</a>：定时从注册中心服务端获取最新的服务提供者节点列表并刷新 LB 配置（比如 Nginx 的 upstream），这样服务消费者就通过访问 Nginx 就可以获取最新的服务提供者信息。</li></ul><h4 id="注册中心选型"><a class="markdownIt-Anchor" href="#注册中心选型"></a> 注册中心选型</h4><h5 id="高可用性"><a class="markdownIt-Anchor" href="#高可用性"></a> 高可用性</h5><p>集群部署，通过部署多个实例组成集群来保证高可用性。</p><p>多 IDC 部署，即部署在不止一个机房。</p><h5 id="数据一致性"><a class="markdownIt-Anchor" href="#数据一致性"></a> 数据一致性</h5><p>根据 CAP 理论，三者不能同时满足：</p><ul><li>CP 型注册中心，牺牲可用性来保证数据强一致性，最典型的例子就是 ZooKeeper，etcd，Consul 了。ZooKeeper 集群内只有一个 Leader，而且在 Leader 无法使用的时候通过 Paxos 算法选举出一个新的 Leader。这个 Leader 的目的就是保证写信息的时候只向这个 Leader 写入，Leader 会同步信息到 Followers，这个过程就可以保证数据的强一致性。但如果多个 ZooKeeper 之间网络出现问题，造成出现多个 Leader，发生脑裂的话，注册中心就不可用了。而 etcd 和 Consul 集群内都是通过 raft 协议来保证强一致性，如果出现脑裂的话， 注册中心也不可用。</li><li>AP 型注册中心，牺牲一致性来保证可用性，最典型的例子就是 Eureka 了。对比下 Zookeeper，Eureka 不用选举一个 Leader，每个 Eureka 服务器单独保存服务注册地址，因此有可能出现数据信息不一致的情况。但是当网络出现问题的时候，每台服务器都可以完成独立的服务。</li></ul><h3 id="服务注册发现的问题"><a class="markdownIt-Anchor" href="#服务注册发现的问题"></a> 服务注册发现的问题</h3><h4 id="多注册中心"><a class="markdownIt-Anchor" href="#多注册中心"></a> 多注册中心</h4><p>对于服务消费者来说，要能够同时从多个注册中心订阅服务；对于服务提供者来说，要能够同时向多个注册中心注册服务。</p><h4 id="并行订阅服务"><a class="markdownIt-Anchor" href="#并行订阅服务"></a> 并行订阅服务</h4><p>可以每订阅一个服务就单独用一个线程来处理，这样的话即使遇到个别服务节点连接超时，其他服务节点的初始化连接也不受影响，最慢也就是这个服务节点的初始化连接耗费的时间，最终所有服务节点的初始化连接耗时控制在了 30 秒以内。</p><h4 id="批量注销服务"><a class="markdownIt-Anchor" href="#批量注销服务"></a> 批量注销服务</h4><p>需要定时去清理注册中心中的“僵尸节点”，如果支持批量注销服务，就可以一次调用就把该节点上提供的所有服务同时注销掉。</p><h4 id="服务变更信息同步更新"><a class="markdownIt-Anchor" href="#服务变更信息同步更新"></a> 服务变更信息同步更新</h4><p>为了减少服务消费者从注册中心中拉取的服务可用节点信息的数据量，这个时候可以通过增量更新的方式，注册中心只返回变化的那部分节点信息，尤其在只有少数节点信息变更时，此举可以大大减少服务消费者从注册中心拉取的数据量，从而最大程度避免产生网络风暴。</p><h3 id="识别服务节点是否存活"><a class="markdownIt-Anchor" href="#识别服务节点是否存活"></a> 识别服务节点是否存活</h3><h4 id="心跳开关保护机制"><a class="markdownIt-Anchor" href="#心跳开关保护机制"></a> 心跳开关保护机制</h4><p>在网络频繁抖动的情况下，注册中心中可用的节点会不断变化，这时候服务消费者会频繁收到服务提供者节点变更的信息，于是就不断地请求注册中心来拉取最新的可用服务节点信息。当有成百上千个服务消费者，同时请求注册中心获取最新的服务提供者的节点信息时，可能会把注册中心的带宽给占满，尤其是注册中心是百兆网卡的情况下。</p><p>所以针对这种情况，<strong>需要一种保护机制，即使在网络频繁抖动的时候，服务消费者也不至于同时去请求注册中心获取最新的服务节点信息</strong>。</p><p>我曾经就遇到过这种情况，一个可行的解决方案就是给注册中心设置一个开关，当开关打开时，即使网络频繁抖动，注册中心也不会通知所有的服务消费者有服务节点信息变更，比如只给 10% 的服务消费者返回变更，这样的话就能将注册中心的请求量减少到原来的 1/10。</p><p>当然打开这个开关也是有一定代价的，它会导致服务消费者感知最新的服务节点信息延迟，原先可能在 10s 内就能感知到服务提供者节点信息的变更，现在可能会延迟到几分钟，所以在网络正常的情况下，开关并不适合打开；可以作为一个紧急措施，在网络频繁抖动的时候，才打开这个开关。</p><h4 id="服务节点摘除保护机制"><a class="markdownIt-Anchor" href="#服务节点摘除保护机制"></a> 服务节点摘除保护机制</h4><p>服务提供者在进程启动时，会注册服务到注册中心，并每隔一段时间，汇报心跳给注册中心，以标识自己的存活状态。如果隔了一段固定时间后，服务提供者仍然没有汇报心跳给注册中心，注册中心就会认为该节点已经处于“dead”状态，于是从服务的可用节点信息中移除出去。</p><p>如果遇到网络问题，大批服务提供者节点汇报给注册中心的心跳信息都可能会传达失败，注册中心就会把它们都从可用节点列表中移除出去，造成剩下的可用节点难以承受所有的调用，引起“雪崩”。但是这种情况下，可能大部分服务提供者节点是可用的，仅仅因为网络原因无法汇报心跳给注册中心就被“无情”的摘除了。</p><p><strong>这个时候就需要根据实际业务的情况，设定一个阈值比例，即使遇到刚才说的这种情况，注册中心也不能摘除超过这个阈值比例的节点</strong>。</p><p>这个阈值比例可以根据实际业务的冗余度来确定，我通常会把这个比例设定在 20%，就是说注册中心不能摘除超过 20% 的节点。因为大部分情况下，节点的变化不会这么频繁，只有在网络抖动或者业务明确要下线大批量节点的情况下才有可能发生。而业务明确要下线大批量节点的情况是可以预知的，这种情况下可以关闭阈值保护；而正常情况下，应该打开阈值保护，以防止网络抖动时，大批量可用的服务节点被摘除。</p><h2 id="四-服务通信"><a class="markdownIt-Anchor" href="#四-服务通信"></a> 四、服务通信</h2><ul><li><strong>通信方式</strong>。它主要解决客户端和服务端如何建立连接、管理连接以及服务端如何处理请求的问题。例如：Dubbo 基于 TCP 通信；而 Spring Cloud 基于 HTTP REST 通信。TCP 通信方式，传输效率更高；但是 HTTP 方式天然可以提供对外服务。</li><li><strong>通信协议</strong>。它主要解决客户端和服务端采用哪种数据传输协议的问题。</li><li><strong>序列化和反序列化</strong>。它主要解决客户端和服务端采用哪种数据编解码的问题。常见的序列化方式包括：XML、JSON；二进制类如：<a href="https://github.com/apache/thrift" target="_blank" rel="noopener">thrift</a>、<a href="https://github.com/protocolbuffers/protobuf" target="_blank" rel="noopener">protobuf</a>、<a href="http://hessian.caucho.com/doc/hessian-overview.xtp" target="_blank" rel="noopener">hessian</a>、JDK</li></ul><p>序列化方式的选型，一般基于以下考虑：</p><ul><li>支持数据结构类型的丰富度</li><li>跨语言支持</li><li>性能</li></ul><p>RPC vs. REST</p><p><img src="http://dunwu.test.upcdn.net/snap/20200716203602.png" alt="img" /></p><h2 id="五-api-网关"><a class="markdownIt-Anchor" href="#五-api-网关"></a> 五、API 网关</h2><p>API 网关是一个服务器，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API 网关封装了系统内部架构，为每个客户端提供一个定制的 API。它可能还具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。<br />API 网关方式的核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。通常，网关也是提供 REST/HTTP 的访问 API。服务端通过 API-GW 注册和管理服务。</p><h3 id="zuul"><a class="markdownIt-Anchor" href="#zuul"></a> Zuul</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200716201640.png" alt="img" /></p><p>在 zuul 中， 整个请求的过程是这样的，首先将请求给 zuulservlet 处理，zuulservlet 中有一个 zuulRunner 对象，该对象中初始化了 RequestContext：作为存储整个请求的一些数据，并被所有的 zuulfilter 共享。zuulRunner 中还有 FilterProcessor，FilterProcessor 作为执行所有的 zuulfilter 的管理器。FilterProcessor 从 filterloader 中获取 zuulfilter，而 zuulfilter 是被 filterFileManager 所加载，并支持 groovy 热加载，采用了轮询的方式热加载。有了这些 filter 之后，zuulservelet 首先执行的 Pre 类型的过滤器，再执行 route 类型的过滤器，最后执行的是 post 类型的过滤器，如果在执行这些过滤器有错误的时候则会执行 error 类型的过滤器。执行完这些过滤器，最终将请求的结果返回给客户端。</p><h2 id="六-服务治理"><a class="markdownIt-Anchor" href="#六-服务治理"></a> 六、服务治理</h2><p>微服务治理平台就是<strong>与服务打交道的统一入口</strong>，无论是开发人员还是运维人员，都能通过这个平台对服务进行各种操作，比如开发人员可以通过这个平台对服务进行降级操作，运维人员可以通过这个平台对服务进行上下线操作，而不需要关心这个操作背后的具体实现。</p><p>微服务治理平台关键之处就在于它能够封装对微服务架构内的各个基础设施组件的调用，从而对外提供统一的服务操作 API，而且还提供了可视化的界面，以方便开发人员和运维人员操作。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200716203729.png" alt="img" /></p><p>服务治理的常用手段有：</p><ul><li>节点管理<ul><li>注册中心主动摘除机制</li><li>服务消费者摘除机制</li></ul></li><li>负载均衡<ul><li>轮询</li><li>随机</li><li>最近最少连接</li><li>一致性 Hash</li></ul></li><li>服务路由<ul><li>业务存在灰度发布的需求</li><li>多机房就近访问的需求</li></ul></li><li>服务容错<ul><li>FailOver：失败自动切换</li><li>FailBack：失败通知</li><li>FailCache：失败缓存</li><li>FailFast：快速失败</li></ul></li></ul><h2 id="七-负载均衡"><a class="markdownIt-Anchor" href="#七-负载均衡"></a> 七、负载均衡</h2><blockquote><p>参考：<a href="https://github.com/dunwu/blog/blob/master/source/_posts/theory/load-balance.md" target="_blank" rel="noopener">负载均衡基本原理</a></p></blockquote><h2 id="八-服务路由"><a class="markdownIt-Anchor" href="#八-服务路由"></a> 八、服务路由</h2><p><strong>服务路由就是服务消费者在发起服务调用时，必须根据特定的规则来选择服务节点，从而满足某些特定的需求</strong>。</p><h3 id="服务路由的应用场景"><a class="markdownIt-Anchor" href="#服务路由的应用场景"></a> 服务路由的应用场景</h3><ul><li><strong>分组调用</strong>。一般来讲，为了保证服务的高可用性，实现异地多活的需求，一个服务往往不止部署在一个数据中心，而且出于节省成本等考虑，有些业务可能不仅在私有机房部署，还会采用公有云部署，甚至采用多家公有云部署。服务节点也会按照不同的数据中心分成不同的分组，这时对于服务消费者来说，选择哪一个分组调用，就必须有相应的路由规则。</li><li><strong>灰度发布</strong>。在服务上线发布的过程中，一般需要先在一小部分规模的服务节点上先发布服务，然后验证功能是否正常。如果正常的话就继续扩大发布范围；如果不正常的话，就需要排查问题，解决问题后继续发布。这个过程就叫作灰度发布，也叫金丝雀部署。</li><li><strong>流量切换</strong>。在业务线上运行过程中，经常会遇到一些不可抗力因素导致业务故障，比如某个机房的光缆被挖断，或者发生着火等事故导致整个机房的服务都不可用。这个时候就需要按照某个指令，能够把原来调用这个机房服务的流量切换到其他正常的机房。</li><li><strong>读写分离</strong>。对于大多数互联网业务来说都是读多写少，所以在进行服务部署的时候，可以把读写分开部署，所有写接口可以部署在一起，而读接口部署在另外的节点上。</li></ul><h3 id="服务路由的规则"><a class="markdownIt-Anchor" href="#服务路由的规则"></a> 服务路由的规则</h3><p>服务路由主要有两种规则：一种是条件路由，一种是脚本路由。</p><h4 id="条件路由"><a class="markdownIt-Anchor" href="#条件路由"></a> 条件路由</h4><p>条件路由是基于条件表达式的路由规则。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">condition://0.0.0.0/dubbo.test.interfaces.TestService?category=routers&amp;dynamic=true&amp;priority=2&amp;enabled=true&amp;rule="</span> <span class="string">+</span> <span class="string">URL.encode("</span> <span class="string">host</span> <span class="string">=</span> <span class="number">10.20</span><span class="number">.153</span><span class="number">.10</span><span class="string">=&gt;</span> <span class="string">host</span> <span class="string">=</span> <span class="number">10.20</span><span class="number">.153</span><span class="number">.11</span><span class="string">")</span></span><br></pre></td></tr></table></figure><p>这里面 <code>condition://</code> 代表了这是一段用条件表达式编写的路由规则，具体的规则是</p><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">host = <span class="number">10.20</span><span class="number">.153</span><span class="number">.10</span> =&gt; host = <span class="number">10.20</span><span class="number">.153</span><span class="number">.11</span></span><br></pre></td></tr></table></figure><p>分隔符“=&gt;”前面是服务消费者的匹配条件，后面是服务提供者的过滤条件。当服务消费者节点满足匹配条件时，就对该服务消费者执行后面的过滤规则。那么上面这段表达式表达的意义就是 IP 为“10.20.153.10”的服务消费者都调用 IP 为“10.20.153.11”的服务提供者节点。</p><p>如果服务消费者的匹配条件为空，就表示对所有的服务消费者应用，就像下面的表达式一样。</p><figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">=&gt; host ！= <span class="number">10.20</span>.<span class="number">153.11</span></span><br></pre></td></tr></table></figure><p>如果服务提供者的过滤条件为空，就表示禁止服务消费者访问，就像下面的表达式一样。</p><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">host = <span class="number">10.20</span><span class="number">.153</span><span class="number">.10</span>=&gt;</span><br></pre></td></tr></table></figure><p>下面我举一些 Dubbo 框架中的条件路由，来给你讲解下条件路由的具体应用场景。</p><ul><li>排除某个服务节点</li></ul><figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">=&gt; host != <span class="number">172.22</span>.<span class="number">3.91</span></span><br></pre></td></tr></table></figure><p>一旦这条路由规则被应用到线上，所有的服务消费者都不会访问 IP 为 172.22.3.91 的服务节点，这种路由规则一般应用在线上流量排除预发布机以及摘除某个故障节点的场景。</p><ul><li>白名单和黑名单功能</li></ul><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">host != <span class="number">10.20</span><span class="number">.153</span><span class="number">.10</span>,<span class="number">10.20</span><span class="number">.153</span><span class="number">.11</span> =&gt;</span><br></pre></td></tr></table></figure><p>这条路由规则意思是除了 IP 为 10.20.153.10 和 10.20.153.11 的服务消费者可以发起服务调用以外，其他服务消费者都不可以，主要用于白名单访问逻辑，比如某个后台服务只允许特定的几台机器才可以访问，这样的话可以机器控制访问权限。</p><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">host = <span class="number">10.20</span><span class="number">.153</span><span class="number">.10</span>,<span class="number">10.20</span><span class="number">.153</span><span class="number">.11</span> =&gt;</span><br></pre></td></tr></table></figure><p>同理，这条路由规则意思是除了 IP 为 10.20.153.10 和 10.20.153.11 的服务消费者不能发起服务调用以外，其他服务消费者都可以，也就是实现了黑名单功能，比如线上经常会遇到某些调用方不管是出于有意还是无意的不合理调用，影响了服务的稳定性，这时候可以通过黑名单功能暂时予以封杀。</p><ul><li>机房隔离</li></ul><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">host = <span class="number">172.22</span><span class="number">.3</span>.* =&gt; host = <span class="number">172.22</span><span class="number">.3</span>.*</span><br></pre></td></tr></table></figure><p>这条路由规则意思是 IP 网段为 172.22.3.* 的服务消费者，才可以访问同网段的服务节点，这种规则一般应用于服务部署在多个 IDC，理论上同一个 IDC 内的调用性能要比跨 IDC 调用性能要好，应用这个规则是为了实现同 IDC 就近访问。</p><ul><li>读写分离</li></ul><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">method = find*,list*,<span class="keyword">get</span>*,<span class="keyword">is</span>* =&gt; host =<span class="number">172.22</span><span class="number">.3</span><span class="number">.94</span>,<span class="number">172.22</span><span class="number">.3</span><span class="number">.95</span></span><br><span class="line">method != find*,list*,<span class="keyword">get</span>*,<span class="keyword">is</span>* =&gt; host = <span class="number">172.22</span><span class="number">.3</span><span class="number">.97</span>,<span class="number">172.22</span><span class="number">.3</span><span class="number">.98</span></span><br></pre></td></tr></table></figure><p>这条路由规则意思是 find*、get*、is* 等读方法调用 IP 为 172.22.3.94 和 172.22.3.95 的节点，除此以外的写方法调用 IP 为 172.22.3.97 和 172.22.3.98 的节点。对于大部分互联网业务来说，往往读请求要远远大于写请求，而写请求的重要性往往要远远高于读请求，所以需要把读写请求进行分离，以避免读请求异常影响到写请求，这时候就可以应用这种规则。</p><h4 id="脚本路由"><a class="markdownIt-Anchor" href="#脚本路由"></a> 脚本路由</h4><p>脚本路由是基于脚本语言的路由规则，常用的脚本语言比如 JavaScript、Groovy、JRuby 等。</p><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="string">"script://0.0.0.0/com.foo.BarService?category=routers&amp;dynamic=false&amp;rule="</span> + <span class="module-access"><span class="module"><span class="identifier">URL</span>.</span></span>encode(<span class="string">"（function route(invokers) &#123; ... &#125; (invokers)）"</span>)</span><br></pre></td></tr></table></figure><p>这里面“script://”就代表了这是一段脚本语言编写的路由规则，具体规则定义在脚本语言的 route 方法实现里，比如下面这段用 JavaScript 编写的 route() 方法表达的意思是，只有 IP 为 10.20.153.10 的服务消费者可以发起服务调用。</p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">route</span><span class="params">(invokers)</span>&#123;</span></span><br><span class="line">  var result = new java.util.ArrayList(invokers.<span class="built_in">size</span>());</span><br><span class="line">  <span class="keyword">for</span>(<span class="built_in">i</span> =<span class="number">0</span>; <span class="built_in">i</span> &lt; invokers.<span class="built_in">size</span>(); <span class="built_in">i</span> ++)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="string">"10.20.153.10"</span>.equals(invokers.get(<span class="built_in">i</span>).getUrl().getHost()))&#123; </span><br><span class="line">       result.add(invokers.get(<span class="built_in">i</span>));</span><br><span class="line">    &#125; </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result; </span><br><span class="line"> &#125; (invokers)）;</span><br></pre></td></tr></table></figure><h3 id="服务路由的获取方式"><a class="markdownIt-Anchor" href="#服务路由的获取方式"></a> 服务路由的获取方式</h3><p>服务路由的获取方式主要有三种：</p><ul><li>本地配置</li></ul><p>顾名思义就是路由规则存储在服务消费者本地上。服务消费者发起调用时，从本地固定位置读取路由规则，然后按照路由规则选取一个服务节点发起调用。</p><ul><li>配置中心管理</li></ul><p>这种方式下，所有的服务消费者都从配置中心获取路由规则，由配置中心来统一管理。</p><ul><li>动态下发</li></ul><p>这种方式下，一般是运维人员或者开发人员，通过服务治理平台修改路由规则，服务治理平台调用配置中心接口，把修改后的路由规则持久化到配置中心。因为服务消费者订阅了路由规则的变更，于是就会从配置中心获取最新的路由规则，按照最新的路由规则来执行。</p><h3 id="内部服务调用"><a class="markdownIt-Anchor" href="#内部服务调用"></a> 内部服务调用</h3><p>基础服务之间的调用：结合服务注册中心以及专属的具有负载均衡功能的客户端，如 Eureka+（restTemplate+Ribbon）或者 Eureka+Feign<br />聚合服务调用：结合服务注册中心以及专属的具有负载均衡功能的客户端，如 Eureka+（restTemplate+Ribbon）或者 Eureka+Feign</p><p><img src="http://dunwu.test.upcdn.net/snap/20200716202409.png" alt="img" /></p><h3 id="外部服务调用"><a class="markdownIt-Anchor" href="#外部服务调用"></a> 外部服务调用</h3><p>基于 Netflix 的 zuul，做了简单了解，SpringCloud 与 zuul 集成的方式。这里先对核心流程做个简单了解，后续会有深入的应用、分析。</p><p>Spring Cloud 很好的集成了 zuul，并且可以通过注解的形式来进行请求的反向路由以及 API 网关功能<br />Spring Cloud 集成 zuul，对与 url 映射的处理方式与 SpringMVC 对 url 的请求方式类似，都是通过 RequestMapping 来进行请求绑定的。核心类：ZuulHandlerMapping<br />zuul 的核心是 ZuulServlet，一个请求核心流程：HttpServletRequest –&gt;ZuulHandlerMapping –&gt;ZuulController –&gt; ZuulServlet –&gt; ZuulFilter –&gt; HttpServletResponse</p><h2 id="九-配置中心"><a class="markdownIt-Anchor" href="#九-配置中心"></a> 九、配置中心</h2><p>配置中心的思路就是把服务的各种配置，如代码里配置的各种参数、服务降级的开关甚至依赖的资源等都在一个地方统一进行管理。服务启动时，可以自动从配置中心中拉取所需的配置，并且如果有配置变更的情况，同样可以自动从配置中心拉取最新的配置信息，服务无须重新发布。</p><p>配置中心一般包含下面几个功能：</p><ul><li>配置注册功能</li><li>配置反注册功能</li><li>配置查看功能</li><li>配置变更订阅功能</li></ul><h3 id="apollo"><a class="markdownIt-Anchor" href="#apollo"></a> Apollo</h3><p>携程开源的分布式配置中心，支持 Java <a href="http://xn--0tr.Net" target="_blank" rel="noopener">和.Net</a> 语言，客户端和配置中心通过 HTTP 长连接实现实时推送，并且有统一的管理界面来实现配置管理。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/ELH62gpbFmGdnIjxDT7AOQyZgl2KQnz68zZFSDpHfa80ppne7gbP4ROOLJSuZT7E2uEdf1OTR9zthLNFkIZSLQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" /></p><h3 id="spring-cloud-git"><a class="markdownIt-Anchor" href="#spring-cloud-git"></a> Spring Cloud Git</h3><p>Spring Cloud 中使用的配置中心组件，只支持 Java 语言，配置存储在 git 中，变更配置也需要通过 git 操作，如果配置中心有配置变更，需要手动刷新。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200716202911.png" alt="img" /></p><h2 id="十-服务监控"><a class="markdownIt-Anchor" href="#十-服务监控"></a> 十、服务监控</h2><p>在微服务架构下，一次用户调用会因为服务化拆分后，变成多个不同服务之间的相互调用，这也就需要对拆分后的每个服务都监控起来。</p><h3 id="监控对象"><a class="markdownIt-Anchor" href="#监控对象"></a> 监控对象</h3><ul><li>用户端监控：性能、返回码、城市、地区、运营商、版本、系统等。</li><li>业务监控：核心指标、登录、注册、下单、支付等。</li><li>应用层监控：访问接口、访问服务、SQL、内存使用率、响应时间、TPS、QPS 等。</li><li>系统层监控：CPU、内存、网络带宽、磁盘使用率等。</li><li>基础监控监控：网络流量、丢包数、错包数、连接数等。</li></ul><h3 id="系统监控原理"><a class="markdownIt-Anchor" href="#系统监控原理"></a> 系统监控原理</h3><p><strong>监控系统主要包括四个环节：数据采集、数据传输、数据处理和数据展示</strong></p><h4 id="数据采集"><a class="markdownIt-Anchor" href="#数据采集"></a> 数据采集</h4><p>通常有两种数据收集方式：</p><ul><li>服务主动上报，这种处理方式通过在业务代码或者服务框架里加入数据收集代码逻辑，在每一次服务调用完成后，主动上报服务的调用信息。</li><li>代理收集，这种处理方式通过服务调用后把调用的详细信息记录到本地日志文件中，然后再通过代理去解析本地日志文件，然后再上报服务的调用信息。</li></ul><h4 id="数据传输"><a class="markdownIt-Anchor" href="#数据传输"></a> 数据传输</h4><p>数据传输最常用的方式有两种：</p><ul><li>UDP 传输，这种处理方式是数据处理单元提供服务器的请求地址，数据采集后通过 UDP 协议与服务器建立连接，然后把数据发送过去。</li><li>Kafka 传输，这种处理方式是数据采集后发送到指定的 Topic，然后数据处理单元再订阅对应的 Topic，就可以从 Kafka 消息队列中读取到对应的数据。</li></ul><h4 id="数据处理"><a class="markdownIt-Anchor" href="#数据处理"></a> 数据处理</h4><p>数据处理是对收集来的原始数据进行聚合并存储。数据聚合通常有两个维度：</p><ul><li><strong>接口维度聚合</strong>，这个维度是把实时收到的数据按照接口名维度实时聚合在一起，这样就可以得到每个接口的实时请求量、平均耗时等信息。</li><li><strong>机器维度聚合</strong>，这个维度是把实时收到的数据按照调用的节点维度聚合在一起，这样就可以从单机维度去查看每个接口的实时请求量、平均耗时等信息。</li></ul><p>聚合后的数据需要持久化到数据库中存储，所选用的数据库一般分为两种：</p><ul><li><strong>全文检索数据库</strong>，比如 Elasticsearch，以倒排索引的数据结构存储，需要查询的时候，根据索引来查询。</li><li><strong>时序数据库</strong>，比如 OpenTSDB，以时序序列数据的方式存储，查询的时候按照时序如 1min、5min 等维度来查询。</li></ul><h4 id="数据展示"><a class="markdownIt-Anchor" href="#数据展示"></a> 数据展示</h4><p>数据展示是把处理后的数据以 Dashboard 的方式展示给用户。数据展示有多种方式，比如曲线图、饼状图、格子图展示等。</p><h3 id="监控技术"><a class="markdownIt-Anchor" href="#监控技术"></a> 监控技术</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200716204432.png" alt="img" /></p><ul><li>ELK 的技术栈比较成熟，应用范围也比较广，除了可用作监控系统外，还可以用作日志查询和分析。</li><li>Graphite 是基于时间序列数据库存储的监控系统，并且提供了功能强大的各种聚合函数比如 sum、average、top5 等可用于监控分析，而且对外提供了 API 也可以接入其他图形化监控系统如 Grafana。</li><li>TICK 的核心在于其时间序列数据库 InfluxDB 的存储功能强大，且支持类似 SQL 语言的复杂数据处理操作。</li><li>Prometheus 的独特之处在于它采用了拉数据的方式，对业务影响较小，同时也采用了时间序列数据库存储，而且支持独有的 PromQL 查询语言，功能强大而且简洁。</li></ul><h2 id="十一-链路追踪"><a class="markdownIt-Anchor" href="#十一-链路追踪"></a> 十一、链路追踪</h2><h3 id="链路追踪的作用"><a class="markdownIt-Anchor" href="#链路追踪的作用"></a> 链路追踪的作用</h3><ul><li>优化系统瓶颈</li><li>优化链路调用</li><li>生成网络拓扑</li><li>透明传输数据</li></ul><h3 id="链路追踪的原理"><a class="markdownIt-Anchor" href="#链路追踪的原理"></a> 链路追踪的原理</h3><p>理解链路追踪必须先了解以下概念：</p><ul><li><strong>traceId</strong>，用于标识某一次具体的请求 ID。当用户的请求进入系统后，会在 RPC 调用网络的第一层生成一个全局唯一的 traceId，并且会随着每一层的 RPC 调用，不断往后传递，这样的话通过 traceId 就可以把一次用户请求在系统中调用的路径串联起来。</li><li><strong>spanId</strong>，用于标识一次 RPC 调用在分布式请求中的位置。当用户的请求进入系统后，处在 RPC 调用网络的第一层 A 时 spanId 初始值是 0，进入下一层 RPC 调用 B 的时候 spanId 是 0.1，继续进入下一层 RPC 调用 C 时 spanId 是 0.1.1，而与 B 处在同一层的 RPC 调用 E 的 spanId 是 0.2，这样的话通过 spanId 就可以定位某一次 RPC 请求在系统调用中所处的位置，以及它的上下游依赖分别是谁。</li><li><strong>annotation</strong>，用于业务自定义埋点数据，可以是业务感兴趣的想上传到后端的数据，比如一次请求的用户 UID。</li></ul><p><img src="http://dunwu.test.upcdn.net/snap/20200716204658.png" alt="img" /></p><h3 id="链路追踪的实现"><a class="markdownIt-Anchor" href="#链路追踪的实现"></a> 链路追踪的实现</h3><p>一个服务追踪系统一般可以分为三层：</p><ul><li><strong>数据采集</strong>层，负责数据埋点并上报。</li><li><strong>数据处理</strong>层，负责数据的存储与计算。</li><li><strong>数据展示</strong>层，负责数据的图形化展示。</li></ul><h4 id="数据采集层"><a class="markdownIt-Anchor" href="#数据采集层"></a> 数据采集层</h4><p>一次 RPC 请求可以分为四个阶段。</p><ul><li>CS（Client Send）阶段 : 客户端发起请求，并生成调用的上下文。</li><li>SR（Server Recieve）阶段 : 服务端接收请求，并生成上下文。</li><li>SS（Server Send）阶段 : 服务端返回请求，这个阶段会将服务端上下文数据上报，下面这张图可以说明上报的数据有：traceId=123456，spanId=0.1，appKey=B，method=B.method，start=103，duration=38。</li><li>CR（Client Recieve）阶段 : 客户端接收返回结果，这个阶段会将客户端上下文数据上报，上报的数据有：traceid=123456，spanId=0.1，appKey=A，method=B.method，start=103，duration=38。</li></ul><h4 id="数据处理层"><a class="markdownIt-Anchor" href="#数据处理层"></a> 数据处理层</h4><p>数据处理层的作用就是把数据采集层上报的数据按需计算，然后落地存储供查询使用。</p><ul><li>实时数据处理</li></ul><p>针对实时数据处理，一般采用 Storm 或者 Spark Streaming 来对链路数据进行实时聚合加工，存储一般使用 OLTP 数据仓库，比如 HBase，使用 traceId 作为 RowKey，能天然地把一整条调用链聚合在一起，提高查询效率。</p><ul><li>离线数据处理</li></ul><p>针对离线数据处理，一般通过运行 MapReduce 或者 Spark 批处理程序来对链路数据进行离线计算，存储一般使用 Hive。</p><h4 id="数据展示层"><a class="markdownIt-Anchor" href="#数据展示层"></a> 数据展示层</h4><p>数据展示层的作用就是将处理后的链路信息以图形化的方式展示给用户。</p><p>实际项目中主要用到两种图形展示，一种是调用链路图，一种是调用拓扑图。</p><h3 id="链路追踪方案对比"><a class="markdownIt-Anchor" href="#链路追踪方案对比"></a> 链路追踪方案对比</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200716205052.png" alt="img" /></p><h2 id="十一-限流熔断"><a class="markdownIt-Anchor" href="#十一-限流熔断"></a> 十一、限流熔断</h2><p>一般而言，集群故障的产生原因不外乎有两种：</p><p>一种是代码 bug 所导致，比如说某一段 Java 代码不断地分配大对象，但没有及时回收导致 JVM OOM 退出；</p><p>另一种是突发的流量冲击，超出了系统的最大承载能力，比如“双 11”这种购物活动，电商系统会在零点一瞬间涌入大量流量，超出系统的最大承载能力，一下子就把整个系统给压垮了。</p><p>应付集群故障的思路，主要有两种：<strong>限流</strong>和<strong>降级</strong>。</p><h3 id="限流"><a class="markdownIt-Anchor" href="#限流"></a> 限流</h3><p>限流就是限制流量。通常情况下，系统能够承载的流量根据集群规模的大小是固定的，可以称之为系统的最大容量。当真实流量超过了系统的最大容量后，就会导致系统响应变慢，服务调用出现大量超时，反映给用户的感觉就是卡顿、无响应。所以，应该根据系统的最大容量，给系统设置一个阈值，超过这个阈值的请求会被自动抛弃，这样的话可以最大限度地保证系统提供的服务正常。</p><p>除此之外，通常一个微服务系统会同时提供多个服务，每个服务在同一时刻的请求量也是不同的，很可能出现的一种情况就是，系统中某个服务的请求量突增，占用了系统中大部分资源，导致其他服务没有资源可用。因此，还要针对系统中每个服务的请求量也设置一个阈值，超过这个阈值的请求也要被自动抛弃，这样的话不至于因为一个服务影响了其他所有服务。</p><p>在实际项目中，可以用两个指标来衡量服务的请求量，一个是 QPS 即每秒请求量，一个是工作线程数。不过 QPS 因为不同服务的响应快慢不同，所以系统能够承载的 QPS 相差很大，因此一般选择工作线程数来作为限流的指标，给系统设置一个总的最大工作线程数以及单个服务的最大工作线程数，这样的话无论是系统的总请求量过大导致整体工作线程数量达到最大工作线程数，还是某个服务的请求量超过单个服务的最大工作线程数，都会被限流，以起到保护整个系统的作用。</p><h3 id="降级"><a class="markdownIt-Anchor" href="#降级"></a> 降级</h3><p>什么是降级呢？在我看来，降级就是通过停止系统中的某些功能，来保证系统整体的可用性。降级可以说是一种被动防御的措施，为什么这么说呢？因为它一般是系统已经出现故障后所采取的一种止损措施。</p><p>那么降级一般是如何实现的呢？根据我的实践来看， 一种可行的方案是通过开关来实现。</p><p>具体来讲，就是在系统运行的内存中开辟一块区域，专门用于存储开关的状态，也就是开启还是关闭。并且需要监听某个端口，通过这个端口可以向系统下发命令，来改变内存中开关的状态。当开关开启时，业务的某一段逻辑就不再执行，而正常情况下，开关是关闭的状态。</p><p>开关一般用在两种地方，一种是新增的业务逻辑，因为新增的业务逻辑相对来说不成熟，往往具备一定的风险，所以需要加开关来控制新业务逻辑是否执行；另一种是依赖的服务或资源，因为依赖的服务或者资源不总是可靠的，所以最好是有开关能够控制是否对依赖服务或资源发起调用，来保证即使依赖出现问题，也能通过降级来避免影响。</p><p>在实际业务应用的时候，降级要按照对业务的影响程度进行分级，一般分为三级：一级降级是对业务影响最小的降级，在故障的情况下，首先执行一级降级，所以一级降级也可以设置成自动降级，不需要人为干预；二级降级是对业务有一定影响的降级，在故障的情况下，如果一级降级起不到多大作用的时候，可以人为采取措施，执行二级降级；三级降级是对业务有较大影响的降级，这种降级要么是对商业收入有重大影响，要么是对用户体验有重大影响，所以操作起来要非常谨慎，不在最后时刻一般不予采用。</p><h2 id="十二-devops"><a class="markdownIt-Anchor" href="#十二-devops"></a> 十二、DEVOPS</h2><h3 id="容器和容器平台"><a class="markdownIt-Anchor" href="#容器和容器平台"></a> 容器和容器平台</h3><p>Mesos、Marathon、Kubernetes</p><h2 id="十三-rpc-选型"><a class="markdownIt-Anchor" href="#十三-rpc-选型"></a> 十三、RPC 选型</h2><h3 id="限定语言-rpc"><a class="markdownIt-Anchor" href="#限定语言-rpc"></a> 限定语言 RPC</h3><p>跟语言平台绑定的开源 RPC 框架主要有下面几种。</p><ul><li>Dubbo：国内最早开源的 RPC 框架，由阿里巴巴公司开发并于 2011 年末对外开源，仅支持 Java 语言。</li><li>Motan：微博内部使用的 RPC 框架，于 2016 年对外开源，仅支持 Java 语言。</li><li>Tars：腾讯内部使用的 RPC 框架，于 2017 年对外开源，仅支持 C++ 语言。</li><li>Spring Cloud：国外 Pivotal 公司 2014 年对外开源的 RPC 框架，仅支持 Java 语言，最近几年生态发展得比较好，是比较火的 RPC 框架。</li></ul><p>所以很明显，如果你的业务场景仅仅局限于一种语言的话，可以选择跟语言绑定的 RPC 框架中的一种；如果涉及多个语言平台之间的相互调用，就应该选择跨语言平台的 RPC 框架。</p><p>仔细分析，可以看出 Spring Cloud 不仅提供了基本的 RPC 框架功能，还提供了服务注册组件、配置中心组件、负载均衡组件、断路器组件、分布式消息追踪组件等一系列组件，也难怪被技术圈的人称之为“Spring Cloud 全家桶”。如果你不想自己实现以上这些功能，那么 Spring Cloud 基本可以满足你的全部需求。而 Dubbo、Motan 基本上只提供了最基础的 RPC 框架的功能，其他微服务组件都需要自己去实现。不过由于 Spring Cloud 的 RPC 通信采用了 HTTP 协议，相比 Dubbo 和 Motan 所采用的私有协议来说，在高并发的通信场景下，性能相对要差一些，所以对性能有苛刻要求的情况下，可以考虑 Dubbo 和 Motan。</p><h3 id="跨语言-rpc"><a class="markdownIt-Anchor" href="#跨语言-rpc"></a> 跨语言 RPC</h3><p>而跨语言平台的开源 RPC 框架主要有以下几种。</p><ul><li>gRPC：Google 于 2015 年对外开源的跨语言 RPC 框架，支持常用的 C++、Java、Python、Go、Ruby、PHP、Android Java、Objective-C 等多种语言。</li><li>Thrift：最初是由 Facebook 开发的内部系统跨语言的 RPC 框架，2007 年贡献给了 Apache 基金，成为 Apache 开源项目之一，支持常用的 C++、Java、PHP、Python、Ruby、Erlang 等多种语言。</li></ul><p>从成熟度上来讲，Thrift 因为诞生的时间要早于 gRPC，所以使用的范围要高于 gRPC，在 HBase、Hadoop、Scribe、Cassandra 等许多开源组件中都得到了广泛地应用。而且 Thrift 支持多达 25 种语言，这要比 gRPC 支持的语言更多，所以如果遇到 gRPC 不支持的语言场景下，选择 Thrift 更合适。</p><p>但 gRPC 作为后起之秀，因为采用了 HTTP/2 作为通信协议、ProtoBuf 作为数据序列化格式，在移动端设备的应用以及对传输带宽比较敏感的场景下具有很大的优势，而且开发文档丰富，根据 ProtoBuf 文件生成的代码要比 Thrift 更简洁一些，从使用难易程度上更占优势，所以如果使用的语言平台 gRPC 支持的话，建议还是采用 gRPC 比较好。</p><h2 id="十四-service-mesh"><a class="markdownIt-Anchor" href="#十四-service-mesh"></a> 十四、Service Mesh</h2><p><img src="http://dunwu.test.upcdn.net/snap/20200721154106.png" alt="img" /></p><h3 id="service-mesh-的实现原理"><a class="markdownIt-Anchor" href="#service-mesh-的实现原理"></a> Service Mesh 的实现原理</h3><p>Service Mesh 实现的关键就在于两点：</p><p>一个是上面提到的轻量级的网络代理也叫 SideCar，它的作用就是转发服务之间的调用；</p><p>一个是基于 SideCar 的服务治理也被叫作 Control Plane，它的作用是向 SideCar 发送各种指令，以完成各种服务治理功能。下面我就来详细讲解这两点是如何实现的。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://time.geekbang.org/column/intro/100014401" target="_blank" rel="noopener">从 0 开始学微服务</a></li><li><a href="https://time.geekbang.org/column/intro/100046201" target="_blank" rel="noopener">RPC 实战与核心原理</a></li><li><a href="https://time.geekbang.org/course/intro/100003901" target="_blank" rel="noopener">微服务架构核心 20 讲</a></li><li><a href="https://www.cnblogs.com/savorboard/p/api-gateway.html" target="_blank" rel="noopener">谈谈微服务中的 API 网关（API Gateway）</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;微服务理论&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#微服务理论&quot;&gt;&lt;/a&gt; 微服务理论&lt;/h1&gt;
&lt;!-- TOC depthFrom:2 depthTo:3 --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E4%B8%80%E5
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="微服务" scheme="https://dunwu.github.io/blog/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="RPC" scheme="https://dunwu.github.io/blog/tags/RPC/"/>
    
  </entry>
  
  <entry>
    <title>RPC 基本原理</title>
    <link href="https://dunwu.github.io/blog/theory/rpc/"/>
    <id>https://dunwu.github.io/blog/theory/rpc/</id>
    <published>2020-06-10T08:00:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="rpc-基本原理"><a class="markdownIt-Anchor" href="#rpc-基本原理"></a> RPC 基本原理</h1><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80rpc-%E7%AE%80%E4%BB%8B">一、RPC 简介</a><ul><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF-rpc">什么是 RPC</a></li><li><a href="#rpc-%E9%80%9A%E4%BF%A1">RPC 通信</a></li><li><a href="#rpc-%E5%8D%8F%E8%AE%AE">RPC 协议</a></li></ul></li><li><a href="#%E4%BA%8C%E5%BA%8F%E5%88%97%E5%8C%96">二、序列化</a><ul><li><a href="#%E5%B8%B8%E8%A7%81%E5%BA%8F%E5%88%97%E5%8C%96%E6%96%B9%E5%BC%8F">常见序列化方式</a></li><li><a href="#%E5%BA%8F%E5%88%97%E5%8C%96%E9%97%AE%E9%A2%98">序列化问题</a></li></ul></li><li><a href="#%E4%B8%89%E5%8F%8D%E5%B0%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86">三、反射+动态代理</a></li><li><a href="#%E5%9B%9B%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1">四、网络通信</a><ul><li><a href="#io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8">IO 多路复用</a></li><li><a href="#%E9%9B%B6%E6%8B%B7%E8%B4%9D">零拷贝</a></li></ul></li><li><a href="#%E4%BA%94rpc-%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B">五、RPC 架构模型</a></li><li><a href="#%E5%85%AD%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%92%8C%E5%8F%91%E7%8E%B0">六、服务注册和发现</a><ul><li><a href="#%E5%9F%BA%E4%BA%8E-zookeeper-%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0">基于 ZooKeeper 的服务发现</a></li><li><a href="#%E5%9F%BA%E4%BA%8E%E6%B6%88%E6%81%AF%E6%80%BB%E7%BA%BF%E7%9A%84%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83">基于消息总线的最终一致性的注册中心</a></li></ul></li><li><a href="#%E4%B8%83%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5">七、健康检查</a></li><li><a href="#%E5%85%AB%E8%B7%AF%E7%94%B1%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">八、路由和负载均衡</a><ul><li><a href="#%E8%B6%85%E6%97%B6%E9%87%8D%E8%AF%95">超时重试</a></li><li><a href="#%E9%99%90%E6%B5%81%E9%99%8D%E7%BA%A7%E7%86%94%E6%96%AD">限流、降级、熔断</a></li><li><a href="#%E4%BC%98%E9%9B%85%E5%90%AF%E5%8A%A8%E5%85%B3%E9%97%AD">优雅启动关闭</a></li></ul></li><li><a href="#%E4%B9%9D%E5%AE%B9%E9%94%99%E5%A4%84%E7%90%86">九、容错处理</a><ul><li><a href="#%E5%BC%82%E5%B8%B8%E9%87%8D%E8%AF%95">异常重试</a></li><li><a href="#%E9%87%8D%E8%AF%95%E8%B6%85%E6%97%B6%E6%97%B6%E9%97%B4">重试超时时间</a></li><li><a href="#%E4%B8%9A%E5%8A%A1%E5%BC%82%E5%B8%B8">业务异常</a></li></ul></li><li><a href="#%E5%8D%81%E4%BC%98%E9%9B%85%E4%B8%8A%E7%BA%BF%E4%B8%8B%E7%BA%BF">十、优雅上线下线</a></li><li><a href="#%E5%8D%81%E4%B8%80%E9%99%90%E6%B5%81%E7%86%94%E6%96%AD">十一、限流熔断</a></li><li><a href="#%E5%8D%81%E4%BA%8C%E4%B8%9A%E5%8A%A1%E5%88%86%E7%BB%84">十二、业务分组</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-rpc-简介"><a class="markdownIt-Anchor" href="#一-rpc-简介"></a> 一、RPC 简介</h2><h3 id="什么是-rpc"><a class="markdownIt-Anchor" href="#什么是-rpc"></a> 什么是 RPC</h3><p>RPC 的全称是 <strong>Remote Procedure Call</strong>，即<strong>远程过程调用</strong>。</p><p>RPC 的主要作用是：</p><ul><li>屏蔽远程调用跟本地调用的区别。</li><li>隐藏底层网络通信的复杂性。</li></ul><h3 id="rpc-通信"><a class="markdownIt-Anchor" href="#rpc-通信"></a> RPC 通信</h3><p>远程调用说明了，RPC 需要通信，那么 RPC 的通信过程是怎样的呢？</p><p>RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 RPC 一般默认采用 TCP 来传输。</p><p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象，所以必须要将其转换，这个过程叫序列化。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610153311.png" alt="img" /></p><ul><li>RPC 拦截调用方要执行的远程方法，将方法名、参数等序列化为方便在网络中传输的二进制或 JSON 数据，然后将这些请求信息传给服务提供方；</li><li>服务提供方将请求信息反序列化为本地的方法和请求参数，然后执行，最后将执行结果序列化为二进制或 JSON 数据，再回应给调用方。</li><li>调用方将应答数据反序列化。</li></ul><h3 id="rpc-协议"><a class="markdownIt-Anchor" href="#rpc-协议"></a> RPC 协议</h3><p>既然有了现成的 HTTP 协议，还有必要设计 RPC 协议吗？</p><p>有必要。因为 HTTP 这些通信标准协议，数据包中的实际请求数据相对于数据包本身要小很多，有很多无用的内容；并且 HTTP 属于无状态协议，无法将请求和响应关联，每次请求要重新建立连接。这对于高性能的 RPC 来说，HTTP 协议难以满足需求，所以有必要设计一个<strong>紧凑的私有协议</strong>。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610163132.png" alt="img" /></p><h2 id="二-序列化"><a class="markdownIt-Anchor" href="#二-序列化"></a> 二、序列化</h2><blockquote><p><strong>序列化可以将对象的字节序列持久化——保存在内存、文件、数据库中</strong>。</p></blockquote><p>序列化是 RPC 的要点之一。</p><p><img src="http://dunwu.test.upcdn.net/snap/1553224129484.png" alt="img" /></p><h3 id="常见序列化方式"><a class="markdownIt-Anchor" href="#常见序列化方式"></a> 常见序列化方式</h3><h4 id="jdk-序列化"><a class="markdownIt-Anchor" href="#jdk-序列化"></a> JDK 序列化</h4><blockquote><p>有兴趣深入了解 JDK 序列化方式，可以参考：<a href="https://github.com/dunwu/javacore/blob/master/docs/io/java-serialization.md" target="_blank" rel="noopener">深入理解 Java 序列化</a></p></blockquote><h4 id="json"><a class="markdownIt-Anchor" href="#json"></a> JSON</h4><p><a href="https://github.com/FasterXML/jackson" target="_blank" rel="noopener">jackson</a>、<a href="https://github.com/google/gson" target="_blank" rel="noopener">gson</a>、<a href="https://github.com/alibaba/fastjson" target="_blank" rel="noopener">fastjson</a> - 适用于对序列化后的数据要求有良好的可读性（转为 json 、xml 形式）。</p><h4 id="hessian"><a class="markdownIt-Anchor" href="#hessian"></a> Hessian</h4><p><a href="http://hessian.caucho.com/doc/hessian-overview.xtp" target="_blank" rel="noopener">hessian</a> - 适用于对开发体验敏感，性能有要求的内外部系统。</p><p>但 Hessian 本身也有问题，官方版本对 Java 里面一些常见对象的类型不支持，比如：</p><ul><li>Linked 系列，<code>LinkedHashMap</code>、<code>LinkedHashSet</code> 等，但是可以通过扩展 <code>CollectionDeserializer</code> 类修复；</li><li>Locale 类，可以通过扩展 <code>ContextSerializerFactory</code> 类修复；</li><li><code>Byte</code>/<code>Short</code> 反序列化的时候变成 <code>Integer</code>。</li></ul><h4 id="thrift-protobuf"><a class="markdownIt-Anchor" href="#thrift-protobuf"></a> Thrift / Protobuf</h4><p><a href="https://github.com/apache/thrift" target="_blank" rel="noopener">thrift</a>、<a href="https://github.com/protocolbuffers/protobuf" target="_blank" rel="noopener">protobuf</a> - 适用于对性能敏感，对开发体验要求不高的内部系统。</p><p>初次以外，还有很多其他的序列化方案。那么，RPC 的序列化方式如何选择呢？</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610193721.png" alt="img" /></p><p>综合以上，Java RPC 框架中序列化方式，一般首选 Protobuf 和 Hessian，二者在性能、通用性、安全性、兼容性、空间开销上都表现不错。其中，Protobuf 性能、通用性更好；而 Hessian 在开发体验上更为便捷。</p><h3 id="序列化问题"><a class="markdownIt-Anchor" href="#序列化问题"></a> 序列化问题</h3><p>Java 对象序列化，一般要关注以下问题：</p><p>常规性问题：</p><ul><li>当父类继承 <code>Serializable</code> 接口时，所有子类都可以被序列化。</li><li>子类实现了 <code>Serializable</code> 接口，父类没有，则父类的属性不会被序列化（不报错，数据丢失），子类的属性仍可以正确序列化。</li><li>如果序列化的属性是对象，则这个对象也必须实现 <code>Serializable</code> 接口，否则会报错。</li><li>在反序列化时，如果对象的属性有修改或删减，则修改的部分属性会丢失，但不会报错。</li><li>在反序列化时，如果 <code>serialVersionUID</code> 被修改，则反序列化时会失败。</li></ul><p>设计问题：</p><ul><li><strong>对象过于复杂、庞大</strong> - 对象过于复杂、庞大，会降低序列化、反序列化的效率，并增加传输开销，从而导致响应时延增大。</li><li><strong>对象有复杂的继承关系</strong> - 对象关系越复杂，就越浪费性能，同时又很容易出现序列化上的问题。</li><li><strong>使用序列化框架不支持的类作为入参类</strong> - 比如 Hessian 框架，他天然是不支持 LinkHashMap、LinkedHashSet 等，而且大多数情况下最好不要使用第三方集合类，如 Guava 中的集合类，很多开源的序列化框架都是优先支持编程语言原生的对象。因此如果入参是集合类，应尽量选用原生的、最为常用的集合类，如 HashMap、ArrayList。</li></ul><h2 id="三-反射动态代理"><a class="markdownIt-Anchor" href="#三-反射动态代理"></a> 三、反射+动态代理</h2><p>RPC 的远程过程调用时通过反射+动态代理实现的。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610161617.png" alt="img" /></p><p>RPC 框架会自动为要调用的接口生成一个代理类。当在项目中注入接口的时候，运行过程中实际绑定的就是这个接口生成的代理类。在接口方法被调用时，会被代理类拦截，这样，就可以在生成的代理类中，加入远程调用逻辑。</p><p>除了 JDK 默认的 <code>InvocationHandler</code> 能完成代理功能，还有很多其他的第三方框架也可以，比如像 Javassist、Byte Buddy 这样的框架。</p><blockquote><p>反射+动态代理更多详情可以参考：<a href="https://github.com/dunwu/javacore/blob/master/docs/basics/java-reflection.md" target="_blank" rel="noopener">深入理解 Java 反射和动态代理</a></p></blockquote><h2 id="四-网络通信"><a class="markdownIt-Anchor" href="#四-网络通信"></a> 四、网络通信</h2><p>一次 RPC 调用，本质就是服务消费者与服务提供者间的一次网络信息交换的过程。可见，通信时 RPC 实现的核心。</p><p>常见的网络 IO 模型有：同步阻塞（BIO）、同步非阻塞（NIO）、异步非阻塞（AIO）。</p><h3 id="io-多路复用"><a class="markdownIt-Anchor" href="#io-多路复用"></a> IO 多路复用</h3><p>IO 多路复用（Reactor 模式）在高并发场景下使用最为广泛，很多知名软件都应用了这一技术，如：Netty、Redis、Nginx 等。</p><p>IO 多路复用分为 select，poll 和 epoll。</p><p>什么是 IO 多路复用？字面上的理解，多路就是指多个通道，也就是多个网络连接的 IO，而复用就是指多个通道复用在一个复用器上。</p><h3 id="零拷贝"><a class="markdownIt-Anchor" href="#零拷贝"></a> 零拷贝</h3><p>系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中；而拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200717154300" alt="img" /></p><p>应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。这里我们可以看到，一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据。</p><p>应用进程的一次完整的读写操作，都需要在用户空间与内核空间中来回拷贝，并且每一次拷贝，都需要 CPU 进行一次上下文切换（由用户进程切换到系统内核，或由系统内核切换到用户进程），这样很浪费 CPU 和性能。</p><p>所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，可以通过一种方式，直接将数据写入内核或从内核中读取数据，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200717154716.jfif" alt="img" /></p><p>Netty 的零拷贝偏向于用户空间中对数据操作的优化，这对处理 TCP 传输中的拆包粘包问题有着重要的意义，对应用程序处理请求数据与返回数据也有重要的意义。</p><p>Netty 框架中很多内部的 ChannelHandler 实现类，都是通过 CompositeByteBuf、slice、wrap 操作来处理 TCP 传输中的拆包与粘包问题的。</p><p>Netty 的 ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socketd 的读写<br />操作，最终的效果与我刚才讲解的虚拟内存所实现的效果是一样的。</p><p>Netty 还提供 FileRegion 中包装 NIO 的 FileChannel.transferTo() 方法实现了零拷<br />贝，这与 Linux 中的 sendfile 方式在原理上也是一样的。</p><h2 id="五-rpc-架构模型"><a class="markdownIt-Anchor" href="#五-rpc-架构模型"></a> 五、RPC 架构模型</h2><p>了解前面的知识点（序列化、动态代理、通信），其实已经可以实现一个点对点的 RPC 架构了。</p><p>采用微内核架构的 RPC 架构模型：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610164920.png" alt="img" /></p><p>在 RPC 框架里面，怎么支持插件化架构的呢？我们可以将每个功能点抽象成一个接<br />口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离，并提供接口的默认实现。在 Java 里面，JDK 有自带的 SPI（Service Provider Interface）服务发现机<br />制，它可以动态地为某个接口寻找服务实现。使用 SPI 机制需要在 Classpath 下的 <code>META-INF/services</code> 目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体实现类。</p><p>但在实际项目中，我们其实很少使用到 JDK 自带的 SPI 机制，首先它不能按需加载，<br /><code>ServiceLoader</code> 加载某个接口实现类的时候，会遍历全部获取，也就是接口的实现类得全部载入并实例化一遍，会造成不必要的浪费。另外就是扩展如果依赖其它的扩展，那就做不到自动注入和装配，这就很难和其他框架集成，比如扩展里面依赖了一个 Spring Bean，原生的 Java SPI 就不支持。</p><h2 id="六-服务注册和发现"><a class="markdownIt-Anchor" href="#六-服务注册和发现"></a> 六、服务注册和发现</h2><p>RPC 框架必须要有服务注册和发现机制，这样，集群中的节点才能知道通信方的请求地址。</p><ul><li><strong>服务注册</strong>：在服务提供方启动的时候，将对外暴露的接口注册到注册中心之中，注册中心将这个服务节点的 IP 和接口保存下来。</li><li><strong>服务订阅</strong>：在服务调用方启动的时候，去注册中心查找并订阅服务提供方的 IP，然后缓存到本地，并用于后续的远程调用。</li></ul><h3 id="基于-zookeeper-的服务发现"><a class="markdownIt-Anchor" href="#基于-zookeeper-的服务发现"></a> 基于 ZooKeeper 的服务发现</h3><p>使用 ZooKeeper 作为服务注册中心，是 Java 分布式系统的经典方案。</p><p>搭建一个 ZooKeeper 集群作为注册中心集群，服务注册的时候只需要服务节点向 ZooKeeper 节点写入注册信息即可，利用 ZooKeeper 的 Watcher 机制完成服务订阅与服务下发功能</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610180056.png" alt="img" /></p><p>通常我们可以使用 ZooKeeper、etcd 或者分布式缓存（如 Hazelcast）来解决事件通知问题，但当集群达到一定规模之后，依赖的 ZooKeeper 集群、etcd 集群可能就不稳定了，无法满足我们的需求。</p><p>在超大规模的服务集群下，注册中心所面临的挑战就是超大批量服务节点同时上下线，注册中心集群接受到大量服务变更请求，集群间各节点间需要同步大量服务节点数据，最终导致如下问题：</p><ul><li>注册中心负载过高；</li><li>各节点数据不一致；</li><li>服务下发不及时或下发错误的服务节点列表。</li></ul><p>RPC 框架依赖的注册中心的服务数据的一致性其实并不需要满足 CP，只要满足 AP 即可。</p><h3 id="基于消息总线的最终一致性的注册中心"><a class="markdownIt-Anchor" href="#基于消息总线的最终一致性的注册中心"></a> 基于消息总线的最终一致性的注册中心</h3><p>ZooKeeper 的一大特点就是强一致性，ZooKeeper 集群的每个节点的数据每次发生更新操作，都会通知其它 ZooKeeper 节点同时执行更新。它要求保证每个节点的数据能够实时的完全一致，这也就直接导致了 ZooKeeper 集群性能上的下降。</p><p>而 RPC 框架的服务发现，在服务节点刚上线时，服务调用方是可以容忍在一段时间之后<br />（比如几秒钟之后）发现这个新上线的节点的。毕竟服务节点刚上线之后的几秒内，甚至更长的一段时间内没有接收到请求流量，对整个服务集群是没有什么影响的，所以我们可以牺牲掉 CP（强制一致性），而选择 AP（最终一致），来换取整个注册中心集群的性能和稳定性。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200717162006.png" alt="img" /></p><h2 id="七-健康检查"><a class="markdownIt-Anchor" href="#七-健康检查"></a> 七、健康检查</h2><p><strong>使用频率适中的心跳去检测目标机器的健康状态</strong>。</p><ul><li>健康状态：建立连接成功，并且心跳探活也一直成功；</li><li>亚健康状态：建立连接成功，但是心跳请求连续失败；</li><li>死亡状态：建立连接失败。</li></ul><p>可以<strong>使用可用率来作为健康状态的量化标准</strong>：</p><figure class="highlight fix"><table><tr><td class="code"><pre><span class="line"><span class="attr">可用率 </span>=<span class="string"> 一个时间窗口内接口调用成功次数 / 总调用次数</span></span><br></pre></td></tr></table></figure><p>当可用率低于某个比例，就认为这个节点存在问题，把它挪到亚健康列表，这样既考虑了高低频的调用接口，也兼顾了接口响应时间不同的问题。</p><h2 id="八-路由和负载均衡"><a class="markdownIt-Anchor" href="#八-路由和负载均衡"></a> 八、路由和负载均衡</h2><p>对于服务调用方来说，一个接口会有多个服务提供方同时提供服务，所以我们的 RPC 在每次发起请求的时候，都需要从多个服务提供方节点里面选择一个用于发请求的节点。这被称为路由策略。</p><ul><li>IP 路由：最简单的当然是 IP 路由，因为服务上线后，会暴露服务到注册中心，将自身 IP、端口等元信息告知注册中心。这样消费方就可以在向注册中心请求服务地址时，感知其存在。</li><li>参数路由：但有时，会有一些复杂的场景，如：灰度发布、定点调用，我们并不希望上线的服务被所有消费者感知，为了更加细粒度的控制，可以使用参数路由。通过参数控制通信的路由策略。</li></ul><p>除了特殊场景的路由策略以外，对于机器中多个服务方，如何选择调用哪个服务节点，可以应用负载均衡策略。RPC 负载均衡策略一般包括随机、轮询、一致性 Hash、最近最少连接等。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200717163401.png" alt="img" /></p><blockquote><p>负载均衡详情可以参考：<a href="https://github.com/dunwu/blog/blob/master/source/_posts/distributed/load-balance.md" target="_blank" rel="noopener">负载均衡基本原理</a></p></blockquote><h3 id="超时重试"><a class="markdownIt-Anchor" href="#超时重试"></a> 超时重试</h3><p>超时重试机制是指：当调用端发起的请求失败或超时未收到响应时，RPC 框架自身可以进行重试，再重新发送请求，用户可以自行设置是否开启重试以及重试的次数。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610193748.png" alt="img" /></p><h3 id="限流-降级-熔断"><a class="markdownIt-Anchor" href="#限流-降级-熔断"></a> 限流、降级、熔断</h3><p>限流方案：Redis + lua、Sentinel</p><p>熔断方案：Hystrix</p><h3 id="优雅启动关闭"><a class="markdownIt-Anchor" href="#优雅启动关闭"></a> 优雅启动关闭</h3><p>如何避免服务停机带来的业务损失：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610193806.png" alt="img" /></p><p>如何避免流量打到没有启动完成的节点：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200610193829.png" alt="img" /></p><h2 id="九-容错处理"><a class="markdownIt-Anchor" href="#九-容错处理"></a> 九、容错处理</h2><h3 id="异常重试"><a class="markdownIt-Anchor" href="#异常重试"></a> 异常重试</h3><p>就是当调用端发起的请求失败时，RPC 框架自身可以进行重试，再重新发送请求，用户可以自行设置是否开启重试以及重试的次数。</p><p>当然，不是所有的异常都要触发重试，只有符合重试条件的异常才能触发重试，比如网络超时异常、网络连接异常等等（这个需要 RPC 去判定）。</p><blockquote><p>注意：有时网络可能发生抖动，导致请求超时，这时如果 RPC 触发超时重试，会触发业务逻辑重复执行，如果接口没有幂等性设计，就可能引发问题。如：重发写表。</p></blockquote><h3 id="重试超时时间"><a class="markdownIt-Anchor" href="#重试超时时间"></a> 重试超时时间</h3><p>连续的异常重试可能会出现一种不可靠的情况，那就是连续的异常重试并且每次处理的请求时间比较长，最终会导致请求处理的时间过长，超出用户设置的超时时间。</p><p>解决这个问题最直接的方式就是，在每次重试后都重置一下请求的超时时间。</p><p>当调用端发起 RPC 请求时，如果发送请求发生异常并触发了异常重试，我们可以先判定下这个请求是否已经超时，如果已经超时了就直接返回超时异常，否则就先重置下这个请求的超时时间，之后再发起重试。</p><p>在所有发起重试、负载均衡选择节点的时候，去掉重试之前出现过问题的那个节点，以保证重试的成功率。</p><h3 id="业务异常"><a class="markdownIt-Anchor" href="#业务异常"></a> 业务异常</h3><p>RPC 框架是不会知道哪些业务异常能够去进行异常重试的，我们可以加个重试异常的白名<br />单，用户可以将允许重试的异常加入到这个白名单中。当调用端发起调用，并且配置了异常重试策略，捕获到异常之后，我们就可以采用这样的异常处理策略。如果这个异常是 RPC 框架允许重试的异常，或者这个异常类型存在于可重试异常的白名单中，我们就允许对这个请求进行重试。</p><hr /><p>综上，一个可靠的 RPC 容错处理机制如下：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200717163921.png" alt="img" /></p><h2 id="十-优雅上线下线"><a class="markdownIt-Anchor" href="#十-优雅上线下线"></a> 十、优雅上线下线</h2><p>如何避免服务停机带来的业务损失？</p><h3 id="优雅下线"><a class="markdownIt-Anchor" href="#优雅下线"></a> 优雅下线</h3><p>当服务提供方正在关闭，如果这之后还收到了新的业务请求，服务提供方直接返回一个特定的异常给调用方（比如 ShutdownException）。这个异常就是告诉调用方“我已经收到这个请求了，但是我正在关闭，并没有处理这个请求”，然后调用方收到这个异常响应后，RPC 框架把这个节点从健康列表挪出，并把请求自动重试到其他节点，因为这个请求是没有被服务提供方处理过，所以可以安全地重试到其他节点，这样就可以实现对业务无损。</p><p>在 Java 语言里面，对应的是 Runtime.addShutdownHook 方法，可以注册关闭的钩子。在 RPC 启动的时候，我们提前注册关闭钩子，并在里面添加了两个处理程序，一个负责开启关闭标识，一个负责安全关闭服务对象，服务对象在关闭的时候会通知调用方下线节点。同时需要在我们调用链里面加上挡板处理器，当新的请求来的时候，会判断关闭标识，如果正在关闭，则抛出特定异常。</p><p><img src="C:%5CUsers%5Czp%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200718205036132.png" alt="image-20200718205036132" /></p><h3 id="优雅上线"><a class="markdownIt-Anchor" href="#优雅上线"></a> 优雅上线</h3><h4 id="启动预热"><a class="markdownIt-Anchor" href="#启动预热"></a> 启动预热</h4><p>启动预热，就是让刚启动的服务提供方应用不承担全部的流量，而是让它被调用的次数随着时间的移动慢慢增加，最终让流量缓和地增加到跟已经运行一段时间后的水平一样。</p><p>首先，在真实环境中机器都会默认开启 NTP 时间同步功能，来保证所有机器时间的一致性。</p><p>调用方通过服务发现，除了可以拿到 IP 列表，还可以拿到对应的启动时间。我们需要把这个时间作用在负载均衡上。</p><p><img src="C:%5CUsers%5Czp%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200718210228814.png" alt="image-20200718210228814" /></p><p>通过这个小逻辑的改动，我们就可以保证当服务提供方运行时长小于预热时间时，对服务提供方进行降权，减少被负载均衡选择的概率，避免让应用在启动之初就处于高负载状态，从而实现服务提供方在启动后有一个预热的过程。</p><h4 id="延迟暴露"><a class="markdownIt-Anchor" href="#延迟暴露"></a> 延迟暴露</h4><p>服务提供方应用在没有启动完成的时候，调用方的请求就过来了，而调用方请求过来的原因是，服务提供方应用在启动过程中把解析到的 RPC 服务注册到了注册中心，这就导致在后续加载没有完成的情况下服务提供方的地址就被服务调用方感知到了。</p><p>为了解决这个问题，需要在应用启动加载、解析 Bean 的时候，如果遇到了 RPC 服务的 Bean，只先把这个<br />Bean 注册到 Spring-BeanFactory 里面去，而并不把这个 Bean 对应的接口注册到注册中心，只有等应用启动完成后，才把接口注册到注册中心用于服务发现，从而实现让服务调用方延迟获取到服务提供方地址。</p><p>具体如何实现呢？</p><p>我们可以在服务提供方应用启动后，接口注册到注册中心前，预留一个 Hook 过程，让用户可以实现可扩展的<br />Hook 逻辑。用户可以在 Hook 里面模拟调用逻辑，从而使 JVM 指令能够预热起来，并且用户也可以在 Hook 里面事先预加载一些资源，只有等所有的资源都加载完成后，最后才把接口注册到注册中心。</p><p><img src="C:%5CUsers%5Czp%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200718210019621.png" alt="image-20200718210019621" /></p><h2 id="十一-限流熔断"><a class="markdownIt-Anchor" href="#十一-限流熔断"></a> 十一、限流熔断</h2><p>限流算法有很多，比如最简单的计数器，还有可以做到平滑限流的滑动窗口、漏斗算法以及令牌桶算法等等。其中令牌桶算法最为常用。</p><p>服务端主要是通过限流来进行自我保护，我们在实现限流时要考虑到应用和 IP 级别，方便我们在服务治理的时候，对部分访问量特别大的应用进行合理的限流。</p><p>服务端的限流阈值配置都是作用于单机的，而在有些场景下，例如对整个服务设置限流阈值，服务进行扩容时，<br />限流的配置并不方便，我们可以在注册中心或配置中心下发限流阈值配置的时候，将总服务节点数也下发给服务节点，让 RPC 框架自己去计算限流阈值。</p><p>我们还可以让 RPC 框架的限流模块依赖一个专门的限流服务，对服务设置限流阈值进行精准地控制，但是这种方式依赖了限流服务，相比单机的限流方式，在性能和耗时上有劣势。</p><p>调用端可以通过熔断机制进行自我保护，防止调用下游服务出现异常，或者耗时过长影响调<br />用端的业务逻辑，RPC 框架可以在动态代理的逻辑中去整合熔断器，实现 RPC 框架的熔断<br />功能。</p><h2 id="十二-业务分组"><a class="markdownIt-Anchor" href="#十二-业务分组"></a> 十二、业务分组</h2><p><img src="http://dunwu.test.upcdn.net/snap/20200718204407.png" alt="img" /></p><p>在 RPC 里面我们可以通过分组的方式人为地给不同的调用方划分出不同的小集群，从而实现调用方流量隔离的效果，保障我们的核心业务不受非核心业务的干扰。但我们在考虑问题的时候，不能顾此失彼，不能因为新加一个的功能而影响到原有系统的稳定性。</p><p>其实我们不仅可以通过分组把服务提供方划分成不同规模的小集群，我们还可以利用分组完成一个接口多种实现的功能。正常情况下，为了方便我们自己管理服务，我一般都会建议每个接口完成的功能尽量保证唯一。但在有些特殊场景下，两个接口也会完全一样，只是具体实现上有那么一点不同，那么我们就可以在服务提供方应用里面同时暴露两个相同接口，但只是接口分组不一样罢了。</p><h3 id="动态分组"><a class="markdownIt-Anchor" href="#动态分组"></a> 动态分组</h3><p>分组可以帮助服务提供方实现调用方的隔离。但是因为调用方流量并不是一成不变的，而且还可能会因为突发事件导致某个分组的流量溢出，而在整个大集群还有富余能力的时候，又因为分组隔离不能为出问题的集群提供帮助。</p><p>为了解决这种突发流量的问题，我们提供了一种更高效的方案，可以实现分组的快速伸缩。事实上我们还可以利用动态分组解决分组后给每个分组预留机器冗余的问题，我们没有必要把所有冗余的机器都分配到分组里面，我们可以把这些预留的机器做成一个共享的池子，从而减少整体预留的实例数量。</p><h2 id="十三-链路跟踪"><a class="markdownIt-Anchor" href="#十三-链路跟踪"></a> 十三、链路跟踪</h2><p>分布式链路跟踪就是将一次分布式请求还原为一个完整的调用链路，我们可以在整个调用链路中跟踪到这一次分布式请求的每一个环节的调用情况，比如调用是否成功，返回什么异常，调用的哪个服务节点以及请求耗时等等。</p><p>Trace 就是代表整个链路，每次分布式都会产生一个 Trace，每个 Trace 都有它的唯一标识即 TraceId，在分布式链路跟踪系统中，就是通过 TraceId 来区分每个 Trace 的。<br />Span 就是代表了整个链路中的一段链路，也就是说 Trace 是由多个 Span 组成的。在一个 Trace 下，每个 Span 也都有它的唯一标识 SpanId，而 Span 是存在父子关系的。还是以讲过的例子为例子，在 A-&gt;B-&gt;C-&gt;D 的情况下，在整个调用链中，正常情况下会产生 3 个 Span，分别是 Span1（A-&gt;B）、Span2（B-&gt;C）、Span3（C-&gt;D），这时 Span3 的父 Span 就是 Span2，而 Span2 的父 Span 就是 Span1。</p><p>RPC 在整合分布式链路跟踪需要做的最核心的两件事就是“埋点”和“传递”。</p><p>我们前面说是因为各子应用、子服务间复杂的依赖关系，所以通过日志难定位问题。那我们就想办法通过日志定位到是哪个子应用的子服务出现问题就行了。</p><p>其实，在 RPC 框架打印的异常信息中，是包括定位异常所需要的异常信息的，比如是哪类异常引起的问题（如序列化问题或网络超时问题），是调用端还是服务端出现的异常，调用端与服务端的 IP 是什么，以及服务接口与服务分组都是什么等等。具体如下图所示：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200719082205.png" alt="img" /></p><h2 id="十四-泛化调用"><a class="markdownIt-Anchor" href="#十四-泛化调用"></a> 十四、泛化调用</h2><p>在一些特定场景下，需要在没有接口的情况下进行 RPC 调用。例如：</p><p>场景一：搭建一个统一的测试平台，可以让各个业务方在测试平台中通过输入接口、分组名、方法名以及参数值，在线测试自己发布的 RPC 服务。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200719095518.png" alt="img" /></p><p>场景二：搭建一个轻量级的服务网关，可以让各个业务方用 HTTP 的方式，通过服务网关调用其它服务。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200719095704.png" alt="img" /></p><p>为了解决这些场景的问题，可以使用泛化调用。</p><p>就是 RPC 框架提供统一的泛化调用接口（GenericService），调用端在创建 GenericService 代理时指定真正需要调用的接口的接口名以及分组名，通过调用 GenericService 代理的 $invoke 方法将服务端所需要的所有信息，包括接口名、业务分组名、方法名以及参数信息等封装成请求消息，发送给服务端，实现在没有接口的情况下进行<br />RPC 调用的功能。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GenericService</span> </span>&#123;</span><br><span class="line">Object $invoke(String methodName, String[] paramTypes, Object[] params);</span><br><span class="line">CompletableFuture&lt;Object&gt; $asyncInvoke(String methodName, String[] paramTypes</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而通过泛化调用的方式发起调用，由于调用端没有服务端提供方提供的接口 API，不能正常地进行序列化与反序列化，我们可以为泛化调用提供专属的序列化插件，来解决实际问题。</p><h2 id="时钟轮"><a class="markdownIt-Anchor" href="#时钟轮"></a> 时钟轮</h2><p>时钟轮这个机制很好地解决了定时任务中，因每个任务都创建一个线程，导致的创建过多线程的问题，以及一个线程扫描所有的定时任务，让 CPU 做了很多额外的轮询遍历操作而浪费 CPU 的问题。</p><p>时钟轮的实现机制就是模拟现实生活中的时钟，将每个定时任务放到对应的时间槽位上，这样可以减少扫描任务时对其它时间槽位定时任务的额外遍历操作。</p><p>在时间轮的使用中，有些问题需要你额外注意：</p><p>时间槽位的单位时间越短，时间轮触发任务的时间就越精确。例如时间槽位的单位时间是 10 毫秒，那么执行定时任务的时间误差就在 10 毫秒内，如果是 100 毫秒，那么误差就在 100 毫秒内。</p><p>时间轮的槽位越多，那么一个任务被重复扫描的概率就越小，因为只有在多层时钟轮中的任务才会被重复扫描。比如一个时间轮的槽位有 1000 个，一个槽位的单位时间是 10 毫秒，那么下一层时间轮的一个槽位的单位时间就是 10 秒，超过 10 秒的定时任务会被放到下一层时间轮中，也就是只有超过 10 秒的定时任务会被扫描遍历两次，但如果槽位是 10 个，那么超过 100 毫秒的任务，就会被扫描遍历两次。</p><p>结合这些特点，我们就可以视具体的业务场景而定，对时钟轮的周期和时间槽数进行设置。</p><p>在 RPC 框架中，只要涉及到定时任务，我们都可以应用时钟轮，比较典型的就是调用端的超时处理、调用端与服务端的启动超时以及定时心跳等等。</p><h2 id="流量回放"><a class="markdownIt-Anchor" href="#流量回放"></a> 流量回放</h2><p>所谓的流量就是某个时间段内的所有请求，我们通过某种手段把发送到 A 应用的所有请求录制下来，然后把这些请求统一转发到 B 应用，让 B 应用接收到的请求参数跟 A 应用保持一致，从而实现 A 接收到的请求在 B 应用里面重新请求了一遍。整个过程称之为“<strong>流量回放</strong>”。</p><p>流量回放可以做什么？</p><p>为了保障应用升级后，我们的业务行为还能保持和升级前一样，我们在大多数情况下都是依靠已有的 TestCase 去验证，但这种方式在一定程度上并不是完全可靠的。最可靠的方式就是引入线上 Case 去验证改造后的应用，把线上的真实流量在改造后的应用里面进行回放，这样不仅节省整个上线时间，还能弥补手动维护 Case 存在的缺陷。</p><p>应用引入了 RPC 后，所有的请求流量都会被 RPC 接管，所以我们可以很自然地在 RPC 里面支持流量回放功能。虽然这个功能本身并不是 RPC 的核心功能，但对于使用 RPC 的人来说，他们有了这个功能之后，就可以更放心地升级自己的应用了。</p><h2 id="rpc-高级"><a class="markdownIt-Anchor" href="#rpc-高级"></a> RPC 高级</h2><h3 id="rpc-性能"><a class="markdownIt-Anchor" href="#rpc-性能"></a> RPC 性能</h3><p>如何提升单机吞吐量？</p><p>大多数情况下，影响到 RPC 调用的吞吐量的原因也就是业务逻辑处理慢了，CPU 大部分时间都在等待资源。</p><p>为了解决等待的耗时，可以使用<strong>异步</strong>。异步可以使用 Future 或 Callback 方式，Future 最为简单。</p><p><img src="C:%5CUsers%5Czp%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200719081257192.png" alt="image-20200719081257192" /></p><p>另外，我们可以通过对 CompletableFuture 的支持，实现 RPC 调用在调用端与服务端之间的完全异步，同时提升两端的单机吞吐量。</p><h3 id="rpc-安全"><a class="markdownIt-Anchor" href="#rpc-安全"></a> RPC 安全</h3><p>虽然 RPC 经常用于解决内网应用之间的调用，内网环境相对公网也没有那么恶劣，但我们也有必要去建立一套可控的安全体系，去防止一些错误行为。对于 RPC 来说，我们所关心的安全问题不会有公网应用那么复杂，我们只要保证让服务调用方能拿到真实的服务提供方 IP 地址集合，且服务提供方可以管控调用自己的应用就够了。</p><p>服务提供方应用里面放一个用于 HMAC 签名的私钥，在授权平台上用这个私钥为申请调用的调用方应用进行签名，这个签名生成的串就变成了调用方唯一的身份。服务提供方在收到调用方的授权请求之后，我们只要需要验证下这个签名跟调用方应用信息是否对应得上就行了，这样集中式授权的瓶颈也就不存在了。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://time.geekbang.org/column/intro/280" target="_blank" rel="noopener">《RPC 实战与核心原理》</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;rpc-基本原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#rpc-基本原理&quot;&gt;&lt;/a&gt; RPC 基本原理&lt;/h1&gt;
&lt;!-- TOC depthFrom:2 depthTo:3 --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E4
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="微服务" scheme="https://dunwu.github.io/blog/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="RPC" scheme="https://dunwu.github.io/blog/tags/RPC/"/>
    
  </entry>
  
  <entry>
    <title>效率提升方法论</title>
    <link href="https://dunwu.github.io/blog/efficiency/methodology/"/>
    <id>https://dunwu.github.io/blog/efficiency/methodology/</id>
    <published>2020-02-10T08:00:00.000Z</published>
    <updated>2020-07-25T07:46:26.677Z</updated>
    
    <content type="html"><![CDATA[<h1 id="效率提升方法论"><a class="markdownIt-Anchor" href="#效率提升方法论"></a> 效率提升方法论</h1><p>在智力水平相当的前提下，常常会发现：有些人做事，事倍功半；有些人做事，事半功倍。</p><p>做任何事，如果有了清晰的思路，正确的指导方针，肯定是比毫无头绪要高效很多。所以，现实中，常常会看到这样一种现象，优秀的人，往往全面优秀，干什么都出彩；而平庸的人，做什么都出不了成绩。</p><p>大多数人不是天才，想要变得优秀，唯一的途径就是：按照正确的习惯（方式方法），坚持不懈的努力进步（自律）。</p><blockquote><p>我们日复一日做的事情，决定了我们是怎样的人。因此<strong>所谓卓越，并非指行为，而是习惯</strong>。</p><p>We are what we repeatedly do. Excellence, then, is not an act, but a habit.</p><p>——莎士比亚</p></blockquote><h2 id="5w2h"><a class="markdownIt-Anchor" href="#5w2h"></a> 5W2H</h2><p><strong>5W2H 分析法是一种思考问题的启发式思维方式</strong>。5W2H 分析法用五个以 <code>W</code> 开头的英语单词和两个以 <code>H</code> 开头的英语单词进行设问，得到关键性问题的答案，最后总结归纳出问题的目标、解决思路、处理方法等，这就叫做 5W2H 法。</p><p>5W2H 分析法又叫七问分析法，是二战中美国陆军兵器修理部首创。这种分析法广泛用于企业管理和技术活动，对于决策和执行性的活动措施也非常有帮助，也有助于弥补考虑问题的疏漏。</p><p>5W2H 分析法的意义在于：避免遇到一个问题后，不知从何入手。通过设问方式，由点成线，由线成面，把问题的关键点串联起来，整理出问题的解决思路。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200210161837.png" alt="5W2H" /></p><ul><li><p><strong>why</strong> - 为什么？为什么要这么做？理由何在？原因是什么？</p></li><li><p><strong>what</strong> - 是什么？目的是什么？作什么工作？</p></li><li><p><strong>where</strong> - 何处？在哪里做？从哪里入手？</p></li><li><p><strong>when</strong> - 何时？什么时间完成？什么时机最适宜？</p></li><li><p><strong>who</strong> - 谁？有谁来承担？谁来完成？谁负责？</p></li><li><p><strong>how</strong> - 怎么做？如何提高效率？如何实施？方法怎么样？</p></li><li><p><strong>how much</strong> - 多少？做到什么程度？数量如何？质量水平如何？费用产出如何？</p></li></ul><h2 id="四象限原则"><a class="markdownIt-Anchor" href="#四象限原则"></a> 四象限原则</h2><p><strong>四象限原则是一种时间管理方式</strong>。</p><p>有首歌唱出了大多数职场人的心声：时间都去哪儿了？</p><p>事情、任务太多，时间太少，分身乏术。</p><p>时间管理四象限法则是美国的管理学家科维提出的一个时间管理的理论，按处理顺序划分为：紧急又重要、重要不紧急、紧急不重要、不紧急不重要。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200210173335.png" alt="img" /></p><ul><li><p><strong>第一象限（重要而紧急</strong>）</p><ul><li>案例：应付难缠的客户、准时完成工作、住院开刀等等。</li><li>这是考验我们的经验、判断力的时刻，也是可以用心耕耘的园地。如果荒废了，我们很会可能变成行尸走肉。但我们也不能忘记，很多重要的事都是因为一拖再拖或事前准备不足，而变成迫在眉睫。</li><li>该象限的本质是缺乏有效的工作计划导致本处于“重要但不紧急”第二象限的事情转变过来的，这也是传统思维状态下的管理者的通常状况，就是“忙”。</li></ul></li><li><p><strong>第二象限（重要但不紧急）</strong></p><ul><li>案例：学习新技能、建立人际关系、保持身体健康、长期的规划、问题的发掘与预防、参加培训、向上级提出问题处理的建议等等事项。</li><li>荒废这个领域将使第一象限日益扩大，使我们陷入更大的压力，在危机中疲于应付。反之，多投入一些时间在这个领域有利于提高实践能力，缩小第一象限的范围。做好事先的规划、准备与预防措施，很多急事将无从产生。这个领域的事情不会对我们造成催促力量，所以必须主动去做，这是发挥个人领导力的领域。</li><li>这更是传统低效管理者与高效卓越管理者的重要区别标志，建议管理者要把 80%的精力投入到该象限的工作，以使第一象限的“急”事无限变少，不再瞎“忙”。</li></ul></li><li><p><strong>第三象限（紧急但不重要）</strong></p><ul><li>案例：电话、会议、突发的访客都属于这一类。</li><li>表面看似第一象限，因为迫切的呼声会让我们产生“这件事很重要”的错觉——实际上就算重要也是对别人而言。我们花很多时间在这个里面打转，自以为是在第一象限，其实不过是在满足别人的期望与标准。</li></ul></li><li><p><strong>第四象限（不紧急也不重要）</strong></p><ul><li>案例：阅读无聊小说、看毫无内容的电视节目、办公室聊天、刷微博、刷朋友圈等。</li><li>简而言之就是浪费生命，所以根本不值得花半点时间在这个象限。但我们往往在一、三象限来回奔走，忙得焦头烂额，不得不到第四象限去疗养一番再出发。这部分范围倒不见得都是休闲活动，因为真正有创造意义的休闲活动是很有价值的。然而像阅读令人上瘾的无聊小说、毫无内容的电视节目、办公室聊天等。这样的休息不但不是为了走更长的路，反而是对身心的毁损，刚开始时也许有滋有味，到后来你就会发现其实是很空虚的。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;效率提升方法论&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#效率提升方法论&quot;&gt;&lt;/a&gt; 效率提升方法论&lt;/h1&gt;
&lt;p&gt;在智力水平相当的前提下，常常会发现：有些人做事，事倍功半；有些人做事，事半功倍。&lt;/p&gt;
&lt;p&gt;做任何事，如果有了
      
    
    </summary>
    
    
      <category term="效率提升" scheme="https://dunwu.github.io/blog/categories/%E6%95%88%E7%8E%87%E6%8F%90%E5%8D%87/"/>
    
      <category term="方法论" scheme="https://dunwu.github.io/blog/categories/%E6%95%88%E7%8E%87%E6%8F%90%E5%8D%87/%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
    
      <category term="效率提升" scheme="https://dunwu.github.io/blog/tags/%E6%95%88%E7%8E%87%E6%8F%90%E5%8D%87/"/>
    
      <category term="方法论" scheme="https://dunwu.github.io/blog/tags/%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    
      <category term="5W2H" scheme="https://dunwu.github.io/blog/tags/5W2H/"/>
    
  </entry>
  
  <entry>
    <title>Travis CI 入门教程</title>
    <link href="https://dunwu.github.io/blog/tools/travis-ci/"/>
    <id>https://dunwu.github.io/blog/tools/travis-ci/</id>
    <published>2020-02-10T06:40:00.000Z</published>
    <updated>2020-07-25T07:46:26.685Z</updated>
    
    <content type="html"><![CDATA[<h1 id="travis-ci-入门教程"><a class="markdownIt-Anchor" href="#travis-ci-入门教程"></a> Travis CI 入门教程</h1><h2 id="一-简介"><a class="markdownIt-Anchor" href="#一-简介"></a> 一、简介</h2><p><a href="https://travis-ci.org/" target="_blank" rel="noopener">Travis CI</a> 提供的是持续集成服务（Continuous Integration，简称 CI）。我们在软件开发过程中，有构建、测试、部署这些必不可少的步骤，而这些会花掉我们很多的时间。为了提高软件开发的效率，现在涌现了很多自动化工具。<a href="https://travis-ci.org/" target="_blank" rel="noopener">Travis CI</a> 是目前<a href="https://github.blog/2017-11-07-github-welcomes-all-ci-tools/" target="_blank" rel="noopener">市场份额</a>最大的一个，而且有很详细的文档以及可以和 Github 很好的对接。</p><p>Travis CI 是 Github 项目最流行的持续集成工具。</p><h3 id="持续集成"><a class="markdownIt-Anchor" href="#持续集成"></a> 持续集成</h3><p>持续集成（Continuous integration，缩写 CI）是一种软件工程流程，即团队开发成员经常集成他们的工作，通常每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。</p><h2 id="二-使用"><a class="markdownIt-Anchor" href="#二-使用"></a> 二、使用</h2><h3 id="加载-github-项目"><a class="markdownIt-Anchor" href="#加载-github-项目"></a> 加载 Github 项目</h3><p>首先打开官方网站 <a href="https://travis-ci.org/" target="_blank" rel="noopener">travis-ci.org</a>，然后使用 Github 账号登入 Travis CI，然后 Travis 中会列出你 Github 上面所有的仓库，以及你所属于的组织。</p><p>然后，勾选你需要 Travis 帮你自动构建的仓库，打开仓库旁边的开关，打开以后，Travis 就会监听这个仓库的所有变化了。</p><p><img src="https://neveryu.github.io/images/travis-ci-1.png" alt="travis-ci-1" /></p><h3 id="配置-travisyml"><a class="markdownIt-Anchor" href="#配置-travisyml"></a> 配置 <code>.travis.yml</code></h3><p>Travis 要求项目的根目录下面，必须有一个 <code>.travis.yml</code> 文件。这是配置文件，指定了 Travis 的行为。该文件必须保存在 Github 仓库里面，一旦代码仓库有新的 <code>Commit</code>，Travis 就会去找这个文件，执行里面的命令。</p><p>所以呢，我们就可以在这个文件里，配置我们任务（Travis 监测到仓库有 <code>commit</code> 后会自动执行）。</p><p>一个简单的 <code>.travis.yml</code> 文件如下：</p><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="string">language:</span> <span class="string">node_jsscript:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>所以呢，我在 <code>.travis.yml</code> 里，配置了一个执行脚本的任务；那么现在 Travis 监测到我仓库有 <code>commit</code> 后就会找到 <code>.travis.yml</code> 这个文件，然后就执行了我的那个脚本了。</p><h4 id="install-字段"><a class="markdownIt-Anchor" href="#install-字段"></a> install 字段</h4><p><code>install</code> 字段用来指定安装脚本，如果有多个脚本，可以写成下面的形式。</p><figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">install:  - <span class="keyword">command</span>1  - <span class="keyword">command</span>2</span><br></pre></td></tr></table></figure><p>上面代码中，如果 <code>command1</code> 失败了，整个构建就会停下来，不再往下进行<br />如果不需要安装，即跳过安装阶段，就直接设为 <code>true</code>。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">install:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h4 id="script-字段"><a class="markdownIt-Anchor" href="#script-字段"></a> script 字段</h4><p><code>script</code> 字段用来配置构建或者测试脚本，如果有多个脚本，可以写成下面的形式。</p><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">script:  - comma<span class="symbol">nd1</span>  - comma<span class="symbol">nd2</span></span><br></pre></td></tr></table></figure><p>注意，<code>script</code> 与 <code>install</code> 不一样，如果 <code>command1</code> 失败，<code>command2</code> 会继续执行。但是，整个构建阶段的状态是失败。</p><p>如果 <code>command2</code> 只有在 <code>command1</code> 成功后才能执行，就要写成下面这样。</p><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">script: comma<span class="symbol">nd1</span> &amp;&amp; comma<span class="symbol">nd2</span></span><br></pre></td></tr></table></figure><h2 id="三-构建"><a class="markdownIt-Anchor" href="#三-构建"></a> 三、构建</h2><h2 id="四-部署"><a class="markdownIt-Anchor" href="#四-部署"></a> 四、部署</h2><p>现在脚本是由 Travis CI 来执行的，部署的时候，怎么让 Travis 有权限往 Github 提交代码呢？</p><p>Github 有提供一个 <a href="https://github.blog/2013-05-16-personal-api-tokens/" target="_blank" rel="noopener">Personal access tokens</a>，这个 Token 与 账号密码 以及 SSH Keys 同样具有 Github 写入能力。</p><p>前往 Github 帐号 Settings 页面，在左侧选择 <code>Personal Access Token</code>，然后在右侧面板点击 <code>“Generate new token”</code> 来新建一个 Token。需要注意的是，创建完的 Token 只有第一次可见，之后再访问就无法看见（只能看见他的名称），因此要保存好这个值。</p><p><a href="https://neveryu.github.io/images/travis-ci-2.png" target="_blank" rel="noopener"><img src="https://neveryu.github.io/images/travis-ci-2.png" alt="travis-ci-2" /></a></p><p>那么，这个 Token 怎么使用呢。</p><h3 id="方案一"><a class="markdownIt-Anchor" href="#方案一"></a> 方案一、</h3><p>一个比较方便快捷的方式，是通过 Travis 网站，写在每个仓库的设置页面里，有一个 <code>Environment Variables</code> 的配置项，给我们的 Token 起一个名字 <code>gh_token</code> 添加进去。这样以来，脚本内部就可以使用这个环境变量了。<br /><a href="https://neveryu.github.io/images/travis-ci-3.png" target="_blank" rel="noopener"><img src="https://neveryu.github.io/images/travis-ci-3.png" alt="travis-ci-1" /></a><br />你可以在你脚本内部使用 <code>${gh_token}</code> 的形式来使用这个 Token 了。【当然了，你还可以添加其他的环境变量进去。】【<a href="https://docs.travis-ci.com/user/environment-variables" target="_blank" rel="noopener">官方文档在这里</a>】</p><p>使用 <code>Personal access tokens</code> 向 GitHub 提交代码的命令格式如下：</p><figure class="highlight dust"><table><tr><td class="code"><pre><span class="line"><span class="xml"># $</span><span class="template-variable">&#123;GH_TOKEN&#125;</span><span class="xml"> 对应就是 Personal access tokens ， GH_TOKEN 是环境变量名# $</span><span class="template-variable">&#123;GH_REF&#125;</span><span class="xml"> 对应的是你的 Github 仓库地址，GH_REF 是变量名git push -f "https://$</span><span class="template-variable">&#123;GH_TOKEN&#125;</span><span class="xml">@$</span><span class="template-variable">&#123;GH_REF&#125;</span><span class="xml">" master:gh-pages</span></span><br></pre></td></tr></table></figure><p>这里需要注意的是：<br />1、GitHub 生成的这个 Token ，只有生成的时候可以看到明文，后面就看不到明文了，所以你使用的时候最好一次操作成功。<br />2、Travis CI 中添加 Token 时，记得用密文，要不然在 <code>build log</code> 中是可以被看到的。</p><h3 id="方案二"><a class="markdownIt-Anchor" href="#方案二"></a> 方案二、</h3><p>你还可以使用 Travis CI 提供的加密工具来加密我们的这个 Token。加密原理机制如下：</p><p><a href="https://neveryu.github.io/images/travis-encrypt.png" target="_blank" rel="noopener"><img src="https://neveryu.github.io/images/travis-encrypt.png" alt="travis-ci-encrypt" /></a></p><p>首先，安装 Ruby 的包 <code>travis</code> 。</p><figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta"># 安装 Travis CI 命令行工具$ gem install travis</span></span><br></pre></td></tr></table></figure><p>然后，就可以用 <code>travis encrypt</code> 命令加密信息。<br />在项目的根目录下，执行下面的命令。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ travis encrypt <span class="attribute">name</span>=secretvalue</span><br></pre></td></tr></table></figure><p>上面命令中，<code>gh_token</code> 是要加密的变量名，<code>secretvalue</code> 是要加密的变量值。执行以后，屏幕上会输出如下信息。</p><figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">secure:</span> <span class="string">"... encrypted data ..."</span></span><br></pre></td></tr></table></figure><p>现在，就可以把这一行加入 <code>.travis.yml</code> 。</p><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="string">env:</span>  <span class="string">global:</span>    - <span class="string">GH_REF:</span> github.com<span class="regexp">/Neveryu/</span>xxxxx.git    - <span class="string">secure:</span> <span class="string">"... entrypted data ..."</span></span><br></pre></td></tr></table></figure><p>然后，脚本里面就可以使用环境变量 <code>gh_token</code> 了，Travis 会在运行时自动对它解密。</p><figure class="highlight dust"><table><tr><td class="code"><pre><span class="line"><span class="xml"># $</span><span class="template-variable">&#123;gh_token&#125;</span><span class="xml"> 对应就是 Personal access tokens ， gh_token 是环境变量名# $</span><span class="template-variable">&#123;GH_REF&#125;</span><span class="xml"> 对应的是你的 Github 仓库地址，GH_REF 是变量名git push -f "https://$</span><span class="template-variable">&#123;gh_token&#125;</span><span class="xml">@$</span><span class="template-variable">&#123;GH_REF&#125;</span><span class="xml">" master:gh-pages</span></span><br></pre></td></tr></table></figure><p><code>travis encrypt</code> 命令的 <code>--add</code> 参数会把输出自动写入 <code>.travis.yml</code>，省掉了修改 <code>env</code> 字段的步骤。</p><figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">$ travis encrypt <span class="built_in">name</span>=secretvalue <span class="comment">--add</span></span><br></pre></td></tr></table></figure><p>详细信息请看<a href="https://docs.travis-ci.com/user/encryption-keys/" target="_blank" rel="noopener">官方文档</a></p><p>可以参考我的 <a href="https://github.com/Neveryu/vue-cms" target="_blank" rel="noopener">vue-cms</a> 这个项目中的 <code>.travis.yml</code> 文件</p><h2 id="faq"><a class="markdownIt-Anchor" href="#faq"></a> FAQ</h2><h3 id="如何显示-status-image"><a class="markdownIt-Anchor" href="#如何显示-status-image"></a> 如何显示 Status Image</h3><p><a href="https://travis-ci.org/Neveryu/web-bookmarks" target="_blank" rel="noopener"><img src="https://travis-ci.org/Neveryu/web-bookmarks.svg?branch=master" alt="Build Status" /></a></p><p><a href="https://neveryu.github.io/images/travis-ci-4.png" target="_blank" rel="noopener"><img src="https://neveryu.github.io/images/travis-ci-4.png" alt="travis-ci-4" /></a></p><h3 id="如何跳过自动构建"><a class="markdownIt-Anchor" href="#如何跳过自动构建"></a> 如何跳过自动构建</h3><p>如果 commit 不想让 Travis 构建，那么就在 commit message 里加上 [ci skip] 就行了。</p><figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">git</span> commit -m <span class="string">"[ci skip] commit message"</span></span><br></pre></td></tr></table></figure><h3 id="权限问题"><a class="markdownIt-Anchor" href="#权限问题"></a> 权限问题</h3><p>如果遇到脚本权限不够的提示或者问题，你可以给你的脚本加上权限：</p><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">chmod</span> <span class="selector-tag">u</span>+<span class="selector-tag">x</span> <span class="selector-tag">deploy</span><span class="selector-class">.sh</span></span><br></pre></td></tr></table></figure><p>或者在 <code>.travis.yml</code> 里加：</p><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">before_instal<span class="variable">l:</span>  - chmod <span class="keyword">u</span>+<span class="keyword">x</span> deploy.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;travis-ci-入门教程&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#travis-ci-入门教程&quot;&gt;&lt;/a&gt; Travis CI 入门教程&lt;/h1&gt;
&lt;h2 id=&quot;一-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anch
      
    
    </summary>
    
    
      <category term="工具" scheme="https://dunwu.github.io/blog/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="https://dunwu.github.io/blog/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="CI" scheme="https://dunwu.github.io/blog/tags/CI/"/>
    
  </entry>
  
  <entry>
    <title>网络通信之 VPN</title>
    <link href="https://dunwu.github.io/blog/network/vpn/"/>
    <id>https://dunwu.github.io/blog/network/vpn/</id>
    <published>2020-02-03T02:30:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="网络通信之-vpn"><a class="markdownIt-Anchor" href="#网络通信之-vpn"></a> 网络通信之 VPN</h1><blockquote><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p></blockquote><p><img src="http://dunwu.test.upcdn.net/snap/20200203095528.png" alt="img" /></p><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E7%AE%80%E4%BB%8B">简介</a></li><li><a href="#vpn-%E7%9A%84%E4%BD%9C%E7%94%A8">VPN 的作用</a><ul><li><a href="#%E9%9A%90%E8%97%8F-ip-%E5%92%8C%E4%BD%8D%E7%BD%AE">隐藏 IP 和位置</a></li><li><a href="#%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86">通信加密</a></li><li><a href="#%E7%BF%BB%E5%A2%99">翻墙</a></li><li><a href="#%E9%81%BF%E5%85%8D%E8%A2%AB%E7%9B%91%E5%90%AC">避免被监听</a></li></ul></li><li><a href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86">工作原理</a></li><li><a href="#vpn-%E5%8D%8F%E8%AE%AE">VPN 协议</a></li><li><a href="#vpn-%E6%9C%8D%E5%8A%A1">VPN 服务</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h2><p>虚拟专用网络(VPN)的功能是：在公用网络上建立专用网络，进行加密通讯。在企业网络中有广泛应用。VPN 网关通过对数据包的加密和数据包目标地址的转换实现远程访问。VPN 可通过服务器、硬件、软件等多种方式实现。</p><p>VPN 属于远程访问技术，简单地说就是利用公用网络架设专用网络。例如某公司员工出差到外地，他想访问企业内网的服务器资源，这种访问就属于远程访问。<br />在传统的企业网络配置中，要进行远程访问，传统的方法是租用 DDN（数字数据网）专线或帧中继，这样的通讯方案必然导致高昂的网络通讯和维护费用。对于移动用户（移动办公人员）与远端个人用户而言，一般会通过拨号线路（Internet）进入企业的局域网，但这样必然带来安全上的隐患。<br />让外地员工访问到内网资源，利用 VPN 的解决方法就是在内网中架设一台 VPN 服务器。外地员工在当地连上互联网后，通过互联网连接 VPN 服务器，然后通过 VPN 服务器进入企业内网。为了保证数据安全，VPN 服务器和客户机之间的通讯数据都进行了加密处理。有了数据加密，就可以认为数据是在一条专用的数据链路上进行安全传输，就如同专门架设了一个专用网络一样，但实际上 VPN 使用的是互联网上的公用链路，因此 VPN 称为虚拟专用网络，其实质上就是利用加密技术在公网上封装出一个数据通讯隧道。有了 VPN 技术，用户无论是在外地出差还是在家中办公，只要能上互联网就能利用 VPN 访问内网资源，这就是 VPN 在企业中应用得如此广泛的原因。</p><h2 id="vpn-的作用"><a class="markdownIt-Anchor" href="#vpn-的作用"></a> VPN 的作用</h2><h3 id="隐藏-ip-和位置"><a class="markdownIt-Anchor" href="#隐藏-ip-和位置"></a> 隐藏 IP 和位置</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200203100404.png" alt="img" /></p><p>VPN 可以隐藏使用者的 IP 地址和位置。</p><p>使用 VPN 的最常见原因之一是屏蔽您的真实 IP 地址。</p><p>您的 IP 地址是由 ISP 分配的唯一数字地址。 您在线上所做的所有事情都链接到您的 IP 地址，因此可以用来将您与在线活动进行匹配。 大多数网站记录其访问者的 IP 地址。</p><p>广告商还可以使用您的 IP 地址，根据您的身份和浏览历史为您提供有针对性的广告。</p><p>连接到 VPN 服务器时，您将使用该 VPN 服务器的 IP 地址。 您访问的任何网站都会看到 VPN 服务器的 IP 地址，而不是您自己的。</p><p>您将能够绕过 IP 地址阻止并浏览网站，而不会将您的活动作为一个个人追溯到您。</p><h3 id="通信加密"><a class="markdownIt-Anchor" href="#通信加密"></a> 通信加密</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200203100543.png" alt="img" /></p><p>使用 VPN 时，可以对信息进行加密，使得密码，电子邮件，照片，银行数据和其他敏感信息不会被拦截。</p><p>如果在公共场所使用公共 WiFi 连接网络时，敏感数据有被盗的风险。黑客可以利用开放和未加密的网络来窃取重要数据，例如您的密码，电子邮件，照片，银行数据和其他敏感信息。</p><p>VPN 可以加密信息，使黑客更难以拦截和窃取数据。</p><h3 id="翻墙"><a class="markdownIt-Anchor" href="#翻墙"></a> 翻墙</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200203100706.png" alt="img" /></p><p>轻松解除对 Facebook 和 Twitter，Skype，YouTube 和 Gmail 等网站和服务的阻止。 即使您被告知您所在的国家/地区不可用它，或者您所在的学校或办公室网络限制访问，也可以获取所需的东西。</p><p>某些服务（例如 Netflix 或 BBC iPlayer）会根据您访问的国家/地区限制访问内容。使用 VPN 可以绕过这些地理限制并解锁“隐藏”内容的唯一可靠方法。</p><h3 id="避免被监听"><a class="markdownIt-Anchor" href="#避免被监听"></a> 避免被监听</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200203100933.png" alt="img" /></p><p>使用 VPN 可以向政府、ISP、黑客隐藏通信信息。</p><p>您的 Internet 服务提供商（ISP）可以看到您访问的所有网站，并且几乎可以肯定会记录该信息。</p><p>在某些国家/地区，ISP 需要长时间收集和存储用户数据，并且政府能够访问，存储和搜索该信息。</p><p>在美国，英国，澳大利亚和欧洲大部分地区就是这种情况，仅举几例。</p><p>由于 VPN 会加密从设备到 VPN 服务器的互联网流量，因此您的 ISP 或任何其他第三方将无法监视您的在线活动。</p><p>要了解有关监视技术和全球大规模监视问题的更多信息，请访问 EFF 和 Privacy International。 您还可以在此处找到全球监视披露的更新列表。</p><h2 id="工作原理"><a class="markdownIt-Anchor" href="#工作原理"></a> 工作原理</h2><p>VPN 会在您的设备和私人服务器之间建立私人和加密的互联网连接。 这意味着您的数据无法被 ISP 或任何其他第三方读取或理解。 然后，私有服务器将您的流量发送到您要访问的网站或服务上。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200203102422.png" alt="img" /></p><p>VPN 的基本处理过程如下：</p><ol><li>要保护主机发送明文信息到其他 VPN 设备。</li><li>VPN 设备根据网络管理员设置的规则，确定是对数据进行加密还是直接传输。</li><li>对需要加密的数据，VPN 设备将其整个数据包（包括要传输的数据、源 IP 地址和目的 lP 地址）进行加密并附上数据签名，加上新的数据报头（包括目的地 VPN 设备需要的安全信息和一些初始化参数）重新封装。</li><li>将封装后的数据包通过隧道在公共网络上传输。</li><li>数据包到达目的 VPN 设备后，将其解封，核对数字签名无误后，对数据包解密。</li></ol><h2 id="vpn-协议"><a class="markdownIt-Anchor" href="#vpn-协议"></a> VPN 协议</h2><p><img src="http://dunwu.test.upcdn.net/snap/20200203102656.png" alt="img" /></p><ul><li><p>OpenVPN</p></li><li><p>IKEv2 / IPSec</p></li><li><p>SSTP</p></li><li><p>PPTP</p></li><li><p>Wireguard</p></li></ul><h2 id="vpn-服务"><a class="markdownIt-Anchor" href="#vpn-服务"></a> VPN 服务</h2><p>你可以选择付费 VPN 或自行搭建 VPN。</p><p>VPN 服务商：</p><ul><li><a href="https://go.nordvpn.net/aff_c?offer_id=15&amp;aff_id=22023&amp;url_id=902" target="_blank" rel="noopener">NordVPN</a></li><li><a href="https://www.linkev.com/?a_fid=techacro" target="_blank" rel="noopener">ExpressVPN</a></li><li><a href="https://cybertool.co/tchacrobat_fs_izci9mc6y" target="_blank" rel="noopener">CyberGhostVPN</a></li><li><a href="https://click.tunnelbear.com/aff_c?offer_id=36&amp;aff_id=7306" target="_blank" rel="noopener">TunnelBear</a></li><li><a href="https://www.ipvanish.com/" target="_blank" rel="noopener">IPVanish</a></li></ul><p>开源 VPN：</p><ul><li><a href="https://openvpn.net/" target="_blank" rel="noopener">OpenVPN</a></li></ul><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E4%B8%93%E7%94%A8%E7%BD%91%E7%BB%9C" target="_blank" rel="noopener">百度百科 - VPN</a></li><li><a href="https://www.expressvpn.com/what-is-vpn" target="_blank" rel="noopener">What is a VPN</a></li><li><a href="https://www.youtube.com/watch?v=_wQTRMBAvzg" target="_blank" rel="noopener">What is a VPN and How Does it Work</a></li><li><a href="https://www.top10vpn.com/guides/what-is-a-vpn/" target="_blank" rel="noopener">What Is a VPN (Virtual Private Network) and How Does It Work?</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;网络通信之-vpn&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#网络通信之-vpn&quot;&gt;&lt;/a&gt; 网络通信之 VPN&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;📦 本文已归档到：「&lt;a href=&quot;https://github.com
      
    
    </summary>
    
    
      <category term="网络" scheme="https://dunwu.github.io/blog/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="网络" scheme="https://dunwu.github.io/blog/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="通信" scheme="https://dunwu.github.io/blog/tags/%E9%80%9A%E4%BF%A1/"/>
    
      <category term="VPN" scheme="https://dunwu.github.io/blog/tags/VPN/"/>
    
  </entry>
  
  <entry>
    <title>深入剖析共识性算法 Paxos</title>
    <link href="https://dunwu.github.io/blog/theory/paxos/"/>
    <id>https://dunwu.github.io/blog/theory/paxos/</id>
    <published>2020-02-02T14:00:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深入剖析共识性算法-paxos"><a class="markdownIt-Anchor" href="#深入剖析共识性算法-paxos"></a> 深入剖析共识性算法 Paxos</h1><blockquote><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p><p>Paxos 是一种基于消息传递且具有容错性的共识性（consensus）算法。</p><p>Paxos 算法解决的问题正是分布式一致性问题。在一个节点数为 N 的分布式集群中，只要半数以上的节点（N/2 + 1）还正常工作，整个系统仍可以正常工作。</p></blockquote><p><img src="http://dunwu.test.upcdn.net/snap/20200202221611.png" alt="img" /></p><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80paxos-%E8%83%8C%E6%99%AF">一、Paxos 背景</a></li><li><a href="#%E4%BA%8Cbasic-paxos-%E7%AE%97%E6%B3%95">二、Basic Paxos 算法</a><ul><li><a href="#%E8%A7%92%E8%89%B2">角色</a></li><li><a href="#%E7%AE%97%E6%B3%95">算法</a></li><li><a href="#%E5%AE%9E%E4%BE%8B">实例</a></li></ul></li><li><a href="#%E4%B8%89multi-paxos-%E7%AE%97%E6%B3%95">三、Multi Paxos 算法</a><ul><li><a href="#basic-paxos-%E7%9A%84%E9%97%AE%E9%A2%98">Basic Paxos 的问题</a></li><li><a href="#multi-paxos-%E7%9A%84%E6%94%B9%E8%BF%9B">Multi Paxos 的改进</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-paxos-背景"><a class="markdownIt-Anchor" href="#一-paxos-背景"></a> 一、Paxos 背景</h2><p>Paxos 是 Leslie Lamport 于 1990 年提出的一种基于消息传递且具有高度容错特性的共识（consensus）算法。</p><p>为描述 Paxos 算法，Lamport 虚拟了一个叫做 Paxos 的希腊城邦，这个岛按照议会民主制的政治模式制订法律，但是没有人愿意将自己的全部时间和精力放在这种事情上。所以无论是议员，议长或者传递纸条的服务员都不能承诺别人需要时一定会出现，也无法承诺批准决议或者传递消息的时间。</p><h2 id="二-basic-paxos-算法"><a class="markdownIt-Anchor" href="#二-basic-paxos-算法"></a> 二、Basic Paxos 算法</h2><h3 id="角色"><a class="markdownIt-Anchor" href="#角色"></a> 角色</h3><p>Paxos 将分布式系统中的节点分为以下角色：</p><ul><li><strong>提议者（Proposer）</strong>：发出提案（Proposal）。Proposal 信息包括提案编号 (Proposal ID) 和提议的值 (Value)。</li><li><strong>决策者（Acceptor）</strong>：参与决策，回应 Proposer 的提案。收到 Proposal 后可以接受提案，若 Proposal 获得多数 Acceptor 的接受，则称该 Proposal 被批准。</li><li><strong>学习者（Learner）</strong>：不参与决策，从 Proposers/Acceptors 学习最新达成一致的提案（Value）。</li></ul><p>在复制状态机中，每个副本都同时具有 Proposer、Acceptor、Learner 三种角色。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200202213738.png" alt="img" /></p><h3 id="算法"><a class="markdownIt-Anchor" href="#算法"></a> 算法</h3><p>Paxos 算法通过一个决议分为两个阶段（Learn 阶段之前决议已经形成）：</p><ol><li>第一阶段：Prepare 阶段。Proposer 向 Acceptors 发出 Prepare 请求，Acceptors 针对收到的 Prepare 请求进行 Promise 承诺。</li><li>第二阶段：Accept 阶段。Proposer 收到多数 Acceptors 承诺的 Promise 后，向 Acceptors 发出 Propose 请求，Acceptors 针对收到的 Propose 请求进行 Accept 处理。</li><li>第三阶段：Learn 阶段。Proposer 在收到多数 Acceptors 的 Accept 之后，标志着本次 Accept 成功，决议形成，将形成的决议发送给所有 Learners。</li></ol><p>Paxos 算法流程中的每条消息描述如下：</p><ul><li><p><strong>Prepare</strong>: Proposer 生成全局唯一且递增的 Proposal ID (可使用时间戳加 Server ID)，向所有 Acceptors 发送 Prepare 请求，这里无需携带提案内容，只携带 Proposal ID 即可。</p></li><li><p><strong>Promise</strong>: Acceptors 收到 Prepare 请求后，做出“两个承诺，一个应答”。</p><ul><li><p>两个承诺：</p><ul><li>不再接受 Proposal ID 小于等于当前请求的 Prepare 请求。</li><li>不再接受 Proposal ID 小于当前请求的 Propose 请求。</li></ul></li><li><p>一个应答：</p><ul><li>不违背以前作出的承诺下，回复已经 Accept 过的提案中 Proposal ID 最大的那个提案的 Value 和 Proposal ID，没有则返回空值。</li></ul></li></ul></li><li><p><strong>Propose</strong>: Proposer 收到多数 Acceptors 的 Promise 应答后，从应答中选择 Proposal ID 最大的提案的 Value，作为本次要发起的提案。如果所有应答的提案 Value 均为空值，则可以自己随意决定提案 Value。然后携带当前 Proposal ID，向所有 Acceptors 发送 Propose 请求。</p></li><li><p><strong>Accept</strong>: Acceptor 收到 Propose 请求后，在不违背自己之前作出的承诺下，接受并持久化当前 Proposal ID 和提案 Value。</p></li><li><p><strong>Learn</strong>: Proposer 收到多数 Acceptors 的 Accept 后，决议形成，将形成的决议发送给所有 Learners。</p></li></ul><h3 id="实例"><a class="markdownIt-Anchor" href="#实例"></a> 实例</h3><h4 id="paxos-算法实例-1"><a class="markdownIt-Anchor" href="#paxos-算法实例-1"></a> Paxos 算法实例 1</h4><p>下面举几个例子，实例 1 如下图：</p><p><img src="https://pic1.zhimg.com/80/v2-ac7e4a827f77dc57d316c77ae95e1940_hd.jpg" alt="img" /></p><p>图中 P 代表 Prepare 阶段，A 代表 Accept 阶段。3.1 代表 Proposal ID 为 3.1，其中 3 为时间戳，1 为 Server ID。X 和 Y 代表提议 Value。</p><p>实例 1 中 P 3.1 达成多数派，其 Value(X)被 Accept，然后 P 4.5 学习到 Value(X)，并 Accept。</p><p><img src="https://pic2.zhimg.com/80/v2-3ae48cb81d39079022666ccb35821c71_hd.jpg" alt="img" />Paxos 算法实例 2</p><p>实例 2 中 P 3.1 没有被多数派 Accept（只有 S3 Accept），但是被 P 4.5 学习到，P 4.5 将自己的 Value 由 Y 替换为 X，Accept（X）。</p><p><img src="https://pic2.zhimg.com/80/v2-931f9487900f0f002867c9e116dec255_hd.jpg" alt="img" />Paxos 算法实例 3</p><p>实例 3 中 P 3.1 没有被多数派 Accept（只有 S1 Accept），同时也没有被 P 4.5 学习到。由于 P 4.5 Propose 的所有应答，均未返回 Value，则 P 4.5 可以 Accept 自己的 Value (Y)。后续 P 3.1 的 Accept (X) 会失败，已经 Accept 的 S1，会被覆盖。</p><p>Paxos 算法可能形成活锁而永远不会结束，如下图实例所示：</p><p><img src="https://pic1.zhimg.com/80/v2-0e18b29659367076ff1c0156ae46eca0_hd.jpg" alt="img" />Paxos 算法形成活锁</p><p>回顾两个承诺之一，Acceptor 不再应答 Proposal ID 小于等于当前请求的 Prepare 请求。意味着需要应答 Proposal ID 大于当前请求的 Prepare 请求。</p><p>两个 Proposers 交替 Prepare 成功，而 Accept 失败，形成活锁（Livelock）。</p><h2 id="三-multi-paxos-算法"><a class="markdownIt-Anchor" href="#三-multi-paxos-算法"></a> 三、Multi Paxos 算法</h2><h3 id="basic-paxos-的问题"><a class="markdownIt-Anchor" href="#basic-paxos-的问题"></a> Basic Paxos 的问题</h3><p>Basic Paxos 有以下问题，导致它不能应用于实际：</p><ul><li><strong>Basic Paxos 算法只能对一个值形成决议</strong>。</li><li><strong>Basic Paxos 算法会消耗大量网络带宽</strong>。Basic Paxos 中，决议的形成至少需要两次网络通信，在高并发情况下可能需要更多的网络通信，极端情况下甚至可能形成活锁。如果想连续确定多个值，Basic Paxos 搞不定了。</li></ul><h3 id="multi-paxos-的改进"><a class="markdownIt-Anchor" href="#multi-paxos-的改进"></a> Multi Paxos 的改进</h3><p>Multi Paxos 正是为解决以上问题而提出。Multi Paxos 基于 Basic Paxos 做了两点改进：</p><ul><li>针对每一个要确定的值，运行一次 Paxos 算法实例（Instance），形成决议。每一个 Paxos 实例使用唯一的 Instance ID 标识。</li><li>在所有 Proposer 中选举一个 Leader，由 Leader 唯一地提交 Proposal 给 Acceptor 进行表决。这样没有 Proposer 竞争，解决了活锁问题。在系统中仅有一个 Leader 进行 Value 提交的情况下，Prepare 阶段就可以跳过，从而将两阶段变为一阶段，提高效率。</li></ul><p>Multi Paxos 首先需要选举 Leader，Leader 的确定也是一次决议的形成，所以可执行一次 Basic Paxos 实例来选举出一个 Leader。选出 Leader 之后只能由 Leader 提交 Proposal，在 Leader 宕机之后服务临时不可用，需要重新选举 Leader 继续服务。在系统中仅有一个 Leader 进行 Proposal 提交的情况下，Prepare 阶段可以跳过。</p><p>Multi Paxos 通过改变 Prepare 阶段的作用范围至后面 Leader 提交的所有实例，从而使得 Leader 的连续提交只需要执行一次 Prepare 阶段，后续只需要执行 Accept 阶段，将两阶段变为一阶段，提高了效率。为了区分连续提交的多个实例，每个实例使用一个 Instance ID 标识，Instance ID 由 Leader 本地递增生成即可。</p><p>Multi Paxos 允许有多个自认为是 Leader 的节点并发提交 Proposal 而不影响其安全性，这样的场景即退化为 Basic Paxos。</p><p>Chubby 和 Boxwood 均使用 Multi Paxos。ZooKeeper 使用的 Zab 也是 Multi Paxos 的变形。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf" target="_blank" rel="noopener">Paxos Made Simple 论文</a></li><li><a href="https://www.jdon.com/artichect/paxos.html" target="_blank" rel="noopener">分布式系统 Paxos 算法</a></li><li><a href="https://zhuanlan.zhihu.com/p/31780743" target="_blank" rel="noopener">Paxos 算法详解</a></li><li><a href="https://zh.wikipedia.org/w/index.php?title=Paxos%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">Wiki - Paxos 算法</a></li><li><a href="https://www.bilibili.com/video/av36556594" target="_blank" rel="noopener">Raft 作者讲解 Paxos 视频</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;深入剖析共识性算法-paxos&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#深入剖析共识性算法-paxos&quot;&gt;&lt;/a&gt; 深入剖析共识性算法 Paxos&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;📦 本文已归档到：「&lt;a href=&quot;
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="共识性" scheme="https://dunwu.github.io/blog/tags/%E5%85%B1%E8%AF%86%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>分布式基础原理</title>
    <link href="https://dunwu.github.io/blog/theory/distributed-base-theory/"/>
    <id>https://dunwu.github.io/blog/theory/distributed-base-theory/</id>
    <published>2020-02-02T11:39:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式基础原理"><a class="markdownIt-Anchor" href="#分布式基础原理"></a> 分布式基础原理</h1><p><img src="http://dunwu.test.upcdn.net/snap/20200202201007.png" alt="img" /></p><blockquote><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p><p>大型网站几乎都是分布式系统。分布式系统的最大难点，在于各节点的状态如何同步。CAP 定理是这方面的基本定理，也是理解分布式系统的起点。</p></blockquote><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98">一、拜占庭将军问题</a></li><li><a href="#%E4%BA%8Ccap">二、CAP</a><ul><li><a href="#%E5%88%86%E5%8C%BA%E5%AE%B9%E9%94%99%E6%80%A7">分区容错性</a></li><li><a href="#%E4%B8%80%E8%87%B4%E6%80%A7">一致性</a></li><li><a href="#%E5%8F%AF%E7%94%A8%E6%80%A7">可用性</a></li><li><a href="#%E6%9D%83%E8%A1%A1">权衡</a></li></ul></li><li><a href="#%E4%B8%89base">三、BASE</a><ul><li><a href="#%E5%9F%BA%E6%9C%AC%E5%8F%AF%E7%94%A8">基本可用</a></li><li><a href="#%E8%BD%AF%E7%8A%B6%E6%80%81">软状态</a></li><li><a href="#%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7">最终一致性</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-拜占庭将军问题"><a class="markdownIt-Anchor" href="#一-拜占庭将军问题"></a> 一、拜占庭将军问题</h2><blockquote><p>拜占庭将军问题是由<a href="https://zh.wikipedia.org/wiki/%E8%8E%B1%E6%96%AF%E5%88%A9%C2%B7%E5%85%B0%E6%B3%A2%E7%89%B9" target="_blank" rel="noopener">莱斯利·兰波特</a>在其同名论文中提出的<a href="https://zh.wikipedia.org/wiki/%E5%AF%B9%E7%AD%89%E7%BD%91%E7%BB%9C" target="_blank" rel="noopener">分布式对等网络</a>通信容错问题。</p><p>在<a href="https://zh.wikipedia.org/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E8%A8%88%E7%AE%97" target="_blank" rel="noopener">分布式计算</a>中，不同的节点通过通讯交换信息达成共识而按照同一套协作策略行动。但有时候，系统中的节点可能出错而发送错误的信息，用于传递信息的通讯网络也可能导致信息损坏，使得网络中不同的成员关于全体协作的策略得出不同结论，从而破坏系统一致性。拜占庭将军问题被认为是容错性问题中最难的问题类型之一。</p></blockquote><p>问题描述：</p><p>一群拜占庭将军各领一支军队共同围困一座城市。</p><p>为了简化问题，军队的行动策略只有两种：进攻（Attack，后面简称 A）或撤退（Retreat，后面简称 R）。如果这些军队不是统一进攻或撤退，就可能会造成灾难性后果，因此<strong>将军们必须通过投票来达成一致策略：同进或同退</strong>。</p><p>因为将军们分别在城市的不同方位，所以他们只能<strong>通过信使互相联系</strong>。在投票过程中，<strong>每位将军都将自己的投票信息（A 或 R）通知其他所有将军</strong>，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以分析出共同的投票结果而决定行动策略。</p><p>这个抽象模型的问题在于：将军中可能存在叛徒，他们不仅会发出误导性投票，还可能选择性地发送投票信息。</p><p>由于将军之间需要通过信使通讯，叛变将军可能通过伪造信件来以其他将军的身份发送假投票。而即使在保证所有将军忠诚的情况下，也不能排除信使被敌人截杀，甚至被敌人间谍替换等情况。因此很难通过保证人员可靠性及通讯可靠性来解决问题。</p><p>假使那些忠诚（或是没有出错）的将军仍然能通过多数决定来决定他们的战略，便称达到了拜占庭容错。在此，票都会有一个默认值，若消息（票）没有被收到，则使用此默认值来投票。</p><p>上述的故事映射到分布式系统里，将军便成了机器节点，而信差就是通信系统。</p><h2 id="二-cap"><a class="markdownIt-Anchor" href="#二-cap"></a> 二、CAP</h2><p>CAP 定理是加州大学计算机科学家埃里克·布鲁尔提出来的猜想，后来被证明成为分布式计算领域公认的定理。</p><p>CAP 定理又称为 CAP 原则，指的是：<strong>在一个分布式系统中， <code>一致性（C：Consistency）</code>、<code>可用性（A：Availability）</code> 和 <code>分区容忍性（P：Partition Tolerance）</code>，最多只能同时满足其中两项</strong>。</p><div align="center"><img src="http://dunwu.test.upcdn.net/cs/design/architecture/分布式理论-CAP.jpg" width="450"/></div><h3 id="分区容错性"><a class="markdownIt-Anchor" href="#分区容错性"></a> 分区容错性</h3><p>分区容错性（Partition Tolerance）指 <strong>分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障</strong>。</p><p>大多数分布式系统都分布在多个子网络，每个子网络就叫做一个区（Partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。</p><p><img src="https://www.wangbase.com/blogimg/asset/201807/bg2018071601.png" alt="img" /></p><p>上图中，G1 和 G2 是两台跨区的服务器。G1 向 G2 发送一条消息，G2 可能无法收到。系统设计的时候，必须考虑到这种情况。</p><p><strong>一般来说，分区容错无法避免</strong>，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。</p><h3 id="一致性"><a class="markdownIt-Anchor" href="#一致性"></a> 一致性</h3><p>一致性（Consistency）指的是<strong>多个数据副本是否能保持一致</strong>的特性。</p><p>在一致性的条件下，分布式系统在执行写操作成功后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。</p><p>数据一致性又可以分为以下几点：</p><ul><li><strong>强一致性</strong> - 数据更新操作结果和操作响应总是一致的，即操作响应通知更新失败，那么数据一定没有被更新，而不是处于不确定状态。</li><li><strong>最终一致性</strong> - 即物理存储的数据可能是不一致的，终端用户访问到的数据可能也是不一致的，但系统经过一段时间的自我修复和修正，数据最终会达到一致。</li></ul><p>举例来说，某条记录是 v0，用户向 G1 发起一个写操作，将其改为 v1。</p><p><img src="https://www.wangbase.com/blogimg/asset/201807/bg2018071602.png" alt="img" /></p><p>接下来，用户的读操作就会得到 v1。这就叫一致性。</p><p><img src="https://www.wangbase.com/blogimg/asset/201807/bg2018071603.png" alt="img" /></p><p>问题是，用户有可能向 G2 发起读操作，由于 G2 的值没有发生变化，因此返回的是 v0。G1 和 G2 读操作的结果不一致，这就不满足一致性了。</p><p><img src="https://www.wangbase.com/blogimg/asset/201807/bg2018071604.png" alt="img" /></p><p>为了让 G2 也能变为 v1，就要在 G1 写操作的时候，让 G1 向 G2 发送一条消息，要求 G2 也改成 v1。</p><p><img src="https://www.wangbase.com/blogimg/asset/201807/bg2018071605.png" alt="img" /></p><p>这样的话，用户向 G2 发起读操作，也能得到 v1。</p><p><img src="https://www.wangbase.com/blogimg/asset/201807/bg2018071606.png" alt="img" /></p><h3 id="可用性"><a class="markdownIt-Anchor" href="#可用性"></a> 可用性</h3><p>可用性指<strong>分布式系统在面对各种异常时可以提供正常服务的能力</strong>，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 <code>99.99%</code> 的时间是可用的。</p><p>在可用性条件下，系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。</p><h3 id="权衡"><a class="markdownIt-Anchor" href="#权衡"></a> 权衡</h3><p>在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，<strong>CAP 理论实际在是要在可用性和一致性之间做权衡</strong>。</p><p>可用性和一致性往往是冲突的，很难都使它们同时满足。在多个节点之间进行数据同步时，</p><ul><li>为了保证一致性（<strong>CP</strong>），就需要让所有节点下线成为不可用的状态，等待同步完成；</li><li>为了保证可用性（<strong>AP</strong>），在同步过程中允许读取所有节点的数据，但是数据可能不一致。</li></ul><h2 id="三-base"><a class="markdownIt-Anchor" href="#三-base"></a> 三、BASE</h2><p>BASE 是 <strong><code>基本可用（Basically Available）</code></strong>、<strong><code>软状态（Soft State）</code></strong> 和 <strong><code>最终一致性（Eventually Consistent）</code></strong> 三个短语的缩写。</p><p>BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA-BASE.png" alt="img" /></p><h3 id="基本可用"><a class="markdownIt-Anchor" href="#基本可用"></a> 基本可用</h3><p>基本可用（Basically Available）指分布式系统在出现故障的时候，<strong>保证核心可用，允许损失部分可用性</strong>。</p><p>例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。</p><h3 id="软状态"><a class="markdownIt-Anchor" href="#软状态"></a> 软状态</h3><p>软状态（Soft State）指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即<strong>允许系统不同节点的数据副本之间进行同步的过程存在延时</strong>。</p><h3 id="最终一致性"><a class="markdownIt-Anchor" href="#最终一致性"></a> 最终一致性</h3><p>最终一致性（Eventually Consistent）强调的是<strong>系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态</strong>。</p><p>ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。</p><p>在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98" target="_blank" rel="noopener">Wiki - 拜占庭将军问题</a></li><li><a href="https://www.bilibili.com/video/av78588312/" target="_blank" rel="noopener">李永乐老师的拜占庭将军问题视频讲解</a></li><li><a href="https://www.ruanyifeng.com/blog/2018/07/cap.html" target="_blank" rel="noopener">CAP 定理的含义</a> - by 阮一峰</li><li><a href="https://juejin.im/post/5d720e86f265da03cc08de74" target="_blank" rel="noopener">神一样的 CAP 理论被应用在何方</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分布式基础原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#分布式基础原理&quot;&gt;&lt;/a&gt; 分布式基础原理&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;http://dunwu.test.upcdn.net/snap/20200202201007
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="CAP" scheme="https://dunwu.github.io/blog/tags/CAP/"/>
    
      <category term="BASE" scheme="https://dunwu.github.io/blog/tags/BASE/"/>
    
  </entry>
  
  <entry>
    <title>深入剖析共识性算法 Raft</title>
    <link href="https://dunwu.github.io/blog/theory/raft/"/>
    <id>https://dunwu.github.io/blog/theory/raft/</id>
    <published>2020-02-01T14:07:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深入剖析共识性算法-raft"><a class="markdownIt-Anchor" href="#深入剖析共识性算法-raft"></a> 深入剖析共识性算法 Raft</h1><blockquote><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p></blockquote><p><img src="http://dunwu.test.upcdn.net/snap/20200201221202.png" alt="img" /></p><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80raft-%E7%AE%80%E4%BB%8B">一、Raft 简介</a><ul><li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7">分布式一致性</a></li><li><a href="#%E5%A4%8D%E5%88%B6%E7%8A%B6%E6%80%81%E6%9C%BA">复制状态机</a></li><li><a href="#raft-%E5%BA%94%E7%94%A8">RAFT 应用</a></li></ul></li><li><a href="#%E4%BA%8Craft-%E5%9F%BA%E7%A1%80">二、Raft 基础</a><ul><li><a href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A7%92%E8%89%B2">服务器角色</a></li><li><a href="#%E4%BB%BB%E6%9C%9F">任期</a></li><li><a href="#rpc">RPC</a></li></ul></li><li><a href="#%E4%B8%89%E9%80%89%E4%B8%BE-leader">三、选举 Leader</a><ul><li><a href="#%E9%80%89%E4%B8%BE%E8%A7%84%E5%88%99">选举规则</a></li><li><a href="#%E5%8D%95-candidate-%E9%80%89%E4%B8%BE">单 Candidate 选举</a></li><li><a href="#%E5%A4%9A-candidate-%E9%80%89%E4%B8%BE">多 Candidate 选举</a></li></ul></li><li><a href="#%E5%9B%9B%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">四、日志复制</a><ul><li><a href="#%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F">日志格式</a></li><li><a href="#%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B">日志复制流程</a></li><li><a href="#%E6%97%A5%E5%BF%97%E4%B8%80%E8%87%B4%E6%80%A7">日志一致性</a></li></ul></li><li><a href="#%E4%BA%94%E5%AE%89%E5%85%A8%E6%80%A7">五、安全性</a><ul><li><a href="#%E9%80%89%E4%B8%BE%E9%99%90%E5%88%B6">选举限制</a></li><li><a href="#%E6%8F%90%E4%BA%A4%E6%97%A7%E4%BB%BB%E6%9C%9F%E7%9A%84%E6%97%A5%E5%BF%97%E6%9D%A1%E7%9B%AE">提交旧任期的日志条目</a></li></ul></li><li><a href="#%E5%85%AD%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9">六、日志压缩</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-raft-简介"><a class="markdownIt-Anchor" href="#一-raft-简介"></a> 一、Raft 简介</h2><p><strong><a href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf" target="_blank" rel="noopener">Raft</a> _是一种为了管理日志复制的分布式一致性算法</strong>*。</p><p><a href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf" target="_blank" rel="noopener">Raft</a> 出现之前，Paxos 一直是分布式一致性算法的标准。Paxos <strong>难以理解，更难以实现</strong>。Raft 的设计目标是简化 Paxos，使得算法<strong>既容易理解，也容易实现</strong>。</p><p>Paxos 和 Raft 都是分布式一致性算法，这个过程如同投票选举领袖（Leader），参选者（Candidate）需要说服大多数投票者（Follower）投票给他，一旦选举出领袖，就由领袖发号施令。Paxos 和 Raft 的区别在于选举的具体过程不同。</p><p><strong>Raft 可以解决分布式 CAP 理论中的 CP</strong>，即 <em>一致性（C：Consistency）</em> 和 <em>分区容忍性（P：Partition Tolerance）</em>，并不能解决 <em>可用性（A：Availability）</em> 的问题。</p><h3 id="分布式一致性"><a class="markdownIt-Anchor" href="#分布式一致性"></a> 分布式一致性</h3><p>分布式一致性 (distributed consensus) 是分布式系统中最基本的问题，用来保证一个分布式系统的可靠性以及容错能力。简单来说，<em><strong>分布式一致性是指多个服务器的保持状态一致</strong></em>。</p><p>在分布式系统中，可能出现各种意外（断电、网络拥塞、CPU/内存耗尽等等），使得服务器宕机或无法访问，最终导致无法和其他服务器保持状态一致。为了应对这种情况，就需要有一种一致性协议来进行容错，使得分布式系统中即使有部分服务器宕机或无法访问，整体依然可以对外提供服务。</p><p>以容错方式达成一致，自然不能要求所有服务器都达成一致状态，只要<strong>超过半数以上</strong>的服务器达成一致就可以了。假设有 N 台服务器， 大于等于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>N</mi><mn>2</mn></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{N}{2}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 台服务器就算是半数以上了 。</p><h3 id="复制状态机"><a class="markdownIt-Anchor" href="#复制状态机"></a> 复制状态机</h3><p><strong><code>复制状态机（Replicated State Machines）</code></strong> 是指一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200131233906.png" alt="img" /></p><p>复制状态机通常都是基于复制日志实现的，如上图。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。</p><p>保证复制日志相同就是一致性算法的工作了。在一台服务器上，一致性模块接收客户端发送来的指令然后增加到自己的日志中去。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，尽管有些服务器会宕机。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成一个高可靠的状态机。</p><p>实际系统中使用的一致性算法通常含有以下特性：</p><ul><li><strong>安全性保证</strong>（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、冗余和乱序等错误都可以保证正确。</li><li><strong>可用性</strong>：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。他们当有稳定的存储的时候可以从状态中恢复回来并重新加入集群。</li><li><strong>不依赖时序来保证一致性</strong>：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题。</li><li>通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。</li></ul><h3 id="raft-应用"><a class="markdownIt-Anchor" href="#raft-应用"></a> RAFT 应用</h3><p>RAFT 可以做什么？</p><p>通过 RAFT 提供的复制状态机，可以解决分布式系统的复制、修复、节点管理等问题。Raft 极大的简化当前分布式系统的设计与实现，让开发者只关注于业务逻辑，将其抽象实现成对应的状态机即可。基于这套框架，可以构建很多分布式应用：</p><ul><li>分布式锁服务，比如 Zookeeper</li><li>分布式存储系统，比如分布式消息队列、分布式块系统、分布式文件系统、分布式表格系统等</li><li>高可靠元信息管理，比如各类 Master 模块的 HA</li></ul><h2 id="二-raft-基础"><a class="markdownIt-Anchor" href="#二-raft-基础"></a> 二、Raft 基础</h2><p>Raft 将一致性问题分解成了三个子问题：</p><ul><li><strong>选举 Leader</strong></li><li><strong>日志复制</strong></li><li><strong>安全性</strong></li></ul><p>在后续章节，会详细讲解这个子问题。现在，先了解一下 Raft 的一些核心概念。</p><h3 id="服务器角色"><a class="markdownIt-Anchor" href="#服务器角色"></a> 服务器角色</h3><p>在 Raft 中，任何时刻，每个服务器都处于这三个角色之一 ：</p><ul><li><strong><code>Leader</code></strong> - 领导者，通常一个系统中是<strong>一主（Leader）多从（Follower）</strong>。Leader <strong>负责处理所有的客户端请求</strong>。</li><li><strong><code>Follower</code></strong> - 跟随者，<strong>不会发送任何请求</strong>，只是简单的 <strong>响应来自 Leader 或者 Candidate 的请求</strong>。</li><li><strong><code>Candidate</code></strong> - 参选者，选举新 Leader 时的临时角色。</li></ul><p><img src="http://dunwu.test.upcdn.net/snap/20200131215742.png" alt="img" /></p><blockquote><p>💡 图示说明：</p><ul><li>Follower 只响应来自其他服务器的请求。在一定时限内，如果 Follower 接收不到消息，就会转变成 Candidate，并发起选举。</li><li>Candidate 向 Follower 发起投票请求，如果获得集群中半数以上的选票，就会转变为 Leader。</li><li>在一个 Term 内，Leader 始终保持不变，直到下线了。Leader 需要周期性向所有 Follower 发送心跳消息，以阻止 Follower 转变为 Candidate。</li></ul></blockquote><h3 id="任期"><a class="markdownIt-Anchor" href="#任期"></a> 任期</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200131220742.png" alt="img" /></p><p>Raft 把时间分割成任意长度的 **<em><code>任期（Term）</code><em><strong>，任期用连续的整数标记。每一段任期从一次</strong>选举</em></em>开始。<strong>Raft 保证了在一个给定的任期内，最多只有一个领导者</strong>。</p><ul><li>如果选举成功，Leader 会管理整个集群直到任期结束。</li><li>如果选举失败，那么这个任期就会因为没有 Leader 而结束。</li></ul><p><strong>不同服务器节点观察到的任期转换状态可能不一样</strong>：</p><ul><li>服务器节点可能观察到多次的任期转换。</li><li>服务器节点也可能观察不到任何一次任期转换。</li></ul><p><strong>任期在 Raft 算法中充当逻辑时钟的作用，使得服务器节点可以查明一些过期的信息（比如过期的 Leader）。每个服务器节点都会存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号。</strong></p><ul><li>如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。</li><li>如果一个 Candidate 或者 Leader 发现自己的任期号过期了，那么他会立即恢复成跟随者状态。</li><li>如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。</li></ul><h3 id="rpc"><a class="markdownIt-Anchor" href="#rpc"></a> RPC</h3><p>Raft 算法中服务器节点之间的通信使用 ***<code>远程过程调用（RPC）</code>***。</p><p>基本的一致性算法只需要两种 RPC：</p><ul><li><strong><code>RequestVote RPC</code></strong> - 请求投票 RPC，由 Candidate 在选举期间发起。</li><li><strong><code>AppendEntries RPC</code></strong> - 附加条目 RPC，由 Leader 发起，用来复制日志和提供一种心跳机制。</li></ul><h2 id="三-选举-leader"><a class="markdownIt-Anchor" href="#三-选举-leader"></a> 三、选举 Leader</h2><h3 id="选举规则"><a class="markdownIt-Anchor" href="#选举规则"></a> 选举规则</h3><p><strong>Raft 使用一种心跳机制来触发 Leader 选举</strong>。</p><p><strong>Leader 需要周期性的向所有 Follower 发送心跳消息</strong>，以此维持自己的权威并阻止新 Leader 的产生。</p><p>每个 Follower 都设置了一个<strong>随机的竞选超时时间</strong>，一般为 <code>150ms ~ 300ms</code>，如果在竞选超时时间内没有收到 Leader 的心跳消息，就会认为当前 Term 没有可用的 Leader，并发起选举来选出新的 Leader。开始一次选举过程，Follower 先要增加自己的当前 Term 号，并<strong>转换为 Candidate</strong>。</p><p>Candidate 会并行的<strong>向集群中的所有服务器节点发送投票请求（<code>RequestVote RPC</code>）</strong>，它会保持当前状态直到以下三件事情之一发生：</p><ul><li><strong>自己成为 Leader</strong></li><li><strong>其他的服务器成为 Leader</strong></li><li><strong>没有任何服务器成为 Leader</strong></li></ul><h4 id="自己成为-leader"><a class="markdownIt-Anchor" href="#自己成为-leader"></a> 自己成为 Leader</h4><ul><li>当一个 Candidate 从整个集群<strong>半数以上</strong>的服务器节点获得了针对同一个 Term 的选票，那么它就赢得了这次选举并成为 Leader。每个服务器最多会对一个 Term 投出一张选票，按照先来先服务（FIFO）的原则。<em>要求半数以上选票的规则确保了最多只会有一个 Candidate 赢得此次选举</em>。</li><li>一旦 Candidate 赢得选举，就立即成为 Leader。然后它会向其他的服务器发送心跳消息来建立自己的权威并且阻止新的领导人的产生。</li></ul><h4 id="其他的服务器成为-leader"><a class="markdownIt-Anchor" href="#其他的服务器成为-leader"></a> 其他的服务器成为 Leader</h4><p>等待投票期间，Candidate 可能会从其他的服务器接收到声明它是 Leader 的 <code>AppendEntries RPC</code>。</p><ul><li>如果这个 Leader 的 Term 号（包含在此次的 RPC 中）不小于 Candidate 当前的 Term，那么 Candidate 会承认 Leader 合法并回到 Follower 状态。</li><li>如果此次 RPC 中的 Term 号比自己小，那么 Candidate 就会拒绝这个消息并继续保持 Candidate 状态。</li></ul><h4 id="没有任何服务器成为-leader"><a class="markdownIt-Anchor" href="#没有任何服务器成为-leader"></a> 没有任何服务器成为 Leader</h4><p>如果有多个 Follower 同时成为 Candidate，那么选票可能会被瓜分以至于没有 Candidate 可以赢得半数以上的投票。当这种情况发生的时候，每一个 Candidate 都会竞选超时，然后通过增加当前 Term 号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。</p><p>Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，竞选超时时间是一个<strong>随机的时间</strong>，在一个固定的区间（例如 150-300 毫秒）随机选择，这样可以把选举都分散开。</p><ul><li>以至于在大多数情况下，只有一个服务器会超时，然后它赢得选举，成为 Leader，并在其他服务器超时之前发送心跳包。</li><li>同样的机制也被用在选票瓜分的情况下：每一个 Candidate 在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。</li></ul><hr /><p>理解了上面的选举规则后，我们通过动图来加深认识。</p><h3 id="单-candidate-选举"><a class="markdownIt-Anchor" href="#单-candidate-选举"></a> 单 Candidate 选举</h3><p>（1）下图表示一个分布式系统的最初阶段，此时只有 Follower，没有 Leader。Follower A 等待一个随机的选举超时时间之后，没收到 Leader 发来的心跳消息。因此，将 Term 由 0 增加为 1，转换为 Candidate，进入选举状态。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-candidate-01.gif" alt="img" /></p><p>（2）此时，A 向所有其他节点发送投票请求。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-candidate-02.gif" alt="img" /></p><p>（3）其它节点会对投票请求进行回复，如果超过半数以上的节点投票了，那么该 Candidate 就会立即变成 Term 为 1 的 Leader。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-candidate-03.gif" alt="img" /></p><p>（4）Leader 会周期性地发送心跳消息给所有 Follower，Follower 接收到心跳包，会重新开始计时。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-candidate-04.gif" alt="img" /></p><h3 id="多-candidate-选举"><a class="markdownIt-Anchor" href="#多-candidate-选举"></a> 多 Candidate 选举</h3><p>（1）如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票。例如下图中 Candidate B 和 Candidate D 都发起 Term 为 4 的选举，且都获得两票，因此需要重新开始投票。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-multi-candidate-01.gif" alt="img" /></p><p>（2）当重新开始投票时，由于每个节点设置的随机竞选超时时间不同，因此能下一次再次出现多个 Candidate 并获得同样票数的概率很低。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-multi-candidate-02.gif" alt="img" /></p><h2 id="四-日志复制"><a class="markdownIt-Anchor" href="#四-日志复制"></a> 四、日志复制</h2><h3 id="日志格式"><a class="markdownIt-Anchor" href="#日志格式"></a> 日志格式</h3><p><strong>日志由含日志索引（log index）的日志条目（log entry）组成</strong>。每个日志条目包含它被创建时的 Term 号（下图中方框中的数字），和一个复制状态机需要执行的指令。如果一个日志条目被复制到半数以上的服务器上，就被认为可以提交（Commit）了。</p><ul><li>日志条目中的 Term 号被用来检查是否出现不一致的情况。</li><li>日志条目中的日志索引（一个整数值）用来表明它在日志中的位置。</li></ul><p><img src="https://pic3.zhimg.com/80/v2-ee29a89e4eb63468e142bb6103dbe4de_hd.jpg" alt="img" /></p><p>Raft 日志同步保证如下两点：</p><ul><li>如果不同日志中的两个日志条目有着相同的日志索引和 Term，则<strong>它们所存储的命令是相同的</strong>。<ul><li>这个特性基于这条原则：Leader 最多在一个 Term 内、在指定的一个日志索引上创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。</li></ul></li><li>如果不同日志中的两个日志条目有着相同的日志索引和 Term，则<strong>它们之前的所有条目都是完全一样的</strong>。<ul><li>这个特性由 <code>AppendEntries RPC</code> 的一个简单的一致性检查所保证。在发送 <code>AppendEntries RPC</code> 时，Leader 会把新日志条目之前的日志条目的日志索引和 Term 号一起发送。如果 Follower 在它的日志中找不到包含相同日志索引和 Term 号的日志条目，它就会拒绝接收新的日志条目。</li></ul></li></ul><h3 id="日志复制流程"><a class="markdownIt-Anchor" href="#日志复制流程"></a> 日志复制流程</h3><p><img src="http://dunwu.test.upcdn.net/snap/20200201115848.png" alt="img" /></p><ol><li>Leader 负责处理所有客户端的请求。</li><li>Leader 把请求作为日志条目加入到它的日志中，然后并行的向其他服务器发送 <code>AppendEntries RPC</code> 请求，要求 Follower 复制日志条目。</li><li>Follower 复制成功后，返回确认消息。</li><li>当这个日志条目被半数以上的服务器复制后，Leader 提交这个日志条目到它的复制状态机，并向客户端返回执行结果。</li></ol><blockquote><p>注意：如果 Follower 崩溃或者运行缓慢，再或者网络丢包，Leader 会不断的重复尝试发送 <code>AppendEntries RPC</code> 请求 （尽管已经回复了客户端），直到所有的跟随者都最终复制了所有的日志条目。</p></blockquote><p>下面，通过一组动图来加深认识：</p><p>（1）来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-sync-log-01.gif" alt="img" /></p><p>（2）Leader 会把修改复制到所有 Follower。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-sync-log-02.gif" alt="img" /></p><p>（3）Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-sync-log-03.gif" alt="img" /></p><p>（4）此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/architecture/raft-sync-log-04.gif" alt="img" /></p><h3 id="日志一致性"><a class="markdownIt-Anchor" href="#日志一致性"></a> 日志一致性</h3><p>一般情况下，Leader 和 Followers 的日志保持一致，因此日志条目一致性检查通常不会失败。然而，Leader 崩溃可能会导致日志不一致：旧的 Leader 可能没有完全复制完日志中的所有条目。</p><h4 id="leader-和-follower-日志不一致的可能"><a class="markdownIt-Anchor" href="#leader-和-follower-日志不一致的可能"></a> Leader 和 Follower 日志不一致的可能</h4><p>Leader 和 Follower 可能存在多种日志不一致的可能。</p><p><img src="https://pic4.zhimg.com/80/v2-d36c587901391cae50788061f568d24f_hd.jpg" alt="img" /></p><blockquote><p>💡 图示说明：</p><p>上图阐述了 Leader 和 Follower 可能存在多种日志不一致的可能，每一个方框表示一个日志条目，里面的数字表示任期号 。</p><p>当一个 Leader 成功当选时，Follower 可能出现以下情况（a-f）：</p><ul><li><strong>存在未更新日志条目</strong>，如（a、b）。</li><li><strong>存在未提交日志条目</strong>，如（c、d）。</li><li>或<strong>两种情况都存在</strong>，如（e、f）。</li></ul><p><em>例如，场景 f 可能会这样发生，某服务器在 Term2 的时候是 Leader，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在 Term3 重新被选为 Leader，并且又增加了一些日志条目到自己的日志中；在 Term 2 和 Term 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态</em>。</p></blockquote><h4 id="leader-和-follower-日志一致的保证"><a class="markdownIt-Anchor" href="#leader-和-follower-日志一致的保证"></a> Leader 和 Follower 日志一致的保证</h4><p>Leader 通过强制 Followers 复制它的日志来处理日志的不一致，<strong>Followers 上的不一致的日志会被 Leader 的日志覆盖</strong>。</p><ul><li><p>Leader 为了使 Followers 的日志同自己的一致，Leader 需要找到 Followers 同它的日志一致的地方，然后覆盖 Followers 在该位置之后的条目。</p></li><li><p>Leader 会从后往前试，每次日志条目失败后尝试前一个日志条目，直到成功找到每个 Follower 的日志一致位点，然后向后逐条覆盖 Followers 在该位置之后的条目。</p></li></ul><h2 id="五-安全性"><a class="markdownIt-Anchor" href="#五-安全性"></a> 五、安全性</h2><p>前面描述了 Raft 算法是如何选举 Leader 和复制日志的。</p><p>Raft 还增加了一些限制来完善 Raft 算法，以保证安全性：保证了任意 Leader 对于给定的 Term，都拥有了之前 Term 的所有被提交的日志条目。</p><h3 id="选举限制"><a class="markdownIt-Anchor" href="#选举限制"></a> 选举限制</h3><p>拥有最新的已提交的日志条目的 Follower 才有资格成为 Leader。</p><p>Raft 使用投票的方式来阻止一个 Candidate 赢得选举除非这个 Candidate 包含了所有已经提交的日志条目。 Candidate 为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果 Candidate 的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。</p><p><code>RequestVote RPC</code> 实现了这样的限制：<strong>RequestVote RPC 中包含了 Candidate 的日志信息， Follower 会拒绝掉那些日志没有自己新的投票请求</strong>。</p><p>如何判断哪个日志条目比较新？</p><p>Raft 通过比较两份日志中最后一条日志条目的日志索引和 Term 来判断哪个日志比较新。</p><ul><li>先判断 Term，哪个数值大即代表哪个日志比较新。</li><li>如果 Term 相同，再比较 日志索引，哪个数值大即代表哪个日志比较新。</li></ul><h3 id="提交旧任期的日志条目"><a class="markdownIt-Anchor" href="#提交旧任期的日志条目"></a> 提交旧任期的日志条目</h3><p>一个当前 Term 的日志条目被复制到了半数以上的服务器上，Leader 就认为它是可以被提交的。如果这个 Leader 在提交日志条目前就下线了，后续的 Leader 可能会覆盖掉这个日志条目。</p><p><img src="https://pic4.zhimg.com/80/v2-12a5ebab63781f9ec49e14e331775537_hd.jpg" alt="img" /></p><blockquote><p>💡 图示说明：</p><p>上图解释了为什么 Leader 无法对旧 Term 的日志条目进行提交。</p><ul><li>阶段 (a) ，S1 是 Leader，且 S1 写入日志条目为 (Term 2，日志索引 2），只有 S2 复制了这个日志条目。</li><li>阶段 (b)，S1 下线，S5 被选举为 Term3 的 Leader。S5 写入日志条目为 (Term 3，日志索引 2）。</li><li>阶段 ©，S5 下线，S1 重新上线，并被选举为 Term4 的 Leader。此时，Term 2 的那条日志条目已经被复制到了集群中的大多数节点上，但是还没有被提交。</li><li>阶段 (d)，S1 再次下线，S5 重新上线，并被重新选举为 Term3 的 Leader。然后 S5 覆盖了日志索引 2 处的日志。</li><li>阶段 (e)，如果阶段 (d) 还未发生，即 S1 再次下线之前，S1 把自己主导的日志条目复制到了大多数节点上，那么在后续 Term 里面这些新日志条目就会被提交。这样在同一时刻就同时保证了，之前的所有旧日志条目就会被提交。</li></ul></blockquote><p><strong>Raft 永远不会通过计算副本数目的方式去提交一个之前 Term 内的日志条目</strong>。只有 Leader 当前 Term 里的日志条目通过计算副本数目可以被提交；一旦当前 Term 的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。</p><p>当 Leader 复制之前任期里的日志时，Raft 会为所有日志保留原始的 Term，这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。</p><h2 id="六-日志压缩"><a class="markdownIt-Anchor" href="#六-日志压缩"></a> 六、日志压缩</h2><p>在实际的系统中，不能让日志无限膨胀，否则系统重启时需要花很长的时间进行恢复，从而影响可用性。Raft 采用对整个系统进行快照来解决，快照之前的日志都可以丢弃。</p><p>每个副本独立的对自己的系统状态生成快照，并且只能对已经提交的日志条目生成快照。</p><p>快照包含以下内容：</p><ul><li>日志元数据。最后一条已提交的日志条目的日志索引和 Term。这两个值在快照之后的第一条日志条目的 <code>AppendEntries RPC</code> 的完整性检查的时候会被用上。</li><li>系统当前状态。</li></ul><p>当 Leader 要发送某个日志条目，落后太多的 Follower 的日志条目会被丢弃，Leader 会将快照发给 Follower。或者新上线一台机器时，也会发送快照给它。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200201220628.png" alt="img" /></p><p><strong>生成快照的频率要适中</strong>，频率过高会消耗大量 I/O 带宽；频率过低，一旦需要执行恢复操作，会丢失大量数据，影响可用性。推荐当日志达到某个固定的大小时生成快照。</p><p>生成一次快照可能耗时过长，影响正常日志同步。可以通过使用 copy-on-write 技术避免快照过程影响正常日志同步。</p><blockquote><p>说明：本文仅阐述 Raft 算法的核心内容，不包括算法论证、评估等</p></blockquote><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf" target="_blank" rel="noopener">Raft 一致性算法论文原文</a></li><li><a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md" target="_blank" rel="noopener">Raft 一致性算法论文译文</a></li><li><a href="https://www.youtube.com/watch?v=YbZ3zDzDnrw&amp;feature=youtu.be" target="_blank" rel="noopener">Raft 作者讲解视频</a></li><li><a href="http://www2.cs.uh.edu/~paris/6360/PowerPoint/Raft.ppt" target="_blank" rel="noopener">Raft 作者讲解视频对应的 PPT</a></li><li><a href="https://www.jdon.com/artichect/raft.html" target="_blank" rel="noopener">分布式系统的 Raft 算法</a></li><li><a href="https://zhuanlan.zhihu.com/p/32052223" target="_blank" rel="noopener">Raft 算法详解</a></li><li><a href="http://thesecretlivesofdata.com/raft" target="_blank" rel="noopener">Raft: Understandable Distributed Consensus</a> - 一个动画教程</li><li><a href="https://github.com/sofastack/sofa-jraft" target="_blank" rel="noopener">sofa-jraft</a> - 蚂蚁金服的 Raft 算法实现库（Java 版）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;深入剖析共识性算法-raft&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#深入剖析共识性算法-raft&quot;&gt;&lt;/a&gt; 深入剖析共识性算法 Raft&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;📦 本文已归档到：「&lt;a href=&quot;htt
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="共识性" scheme="https://dunwu.github.io/blog/tags/%E5%85%B1%E8%AF%86%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>Markdown Cheat Sheet</title>
    <link href="https://dunwu.github.io/blog/tools/markdown/"/>
    <id>https://dunwu.github.io/blog/tools/markdown/</id>
    <published>2020-01-26T16:00:00.000Z</published>
    <updated>2020-07-25T07:46:26.685Z</updated>
    
    <content type="html"><![CDATA[<h1 id="markdown-cheat-sheet"><a class="markdownIt-Anchor" href="#markdown-cheat-sheet"></a> Markdown Cheat Sheet</h1><blockquote><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p></blockquote><h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2><!-- TOC depthFrom:2 depthTo:2 --><ul><li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li><li><a href="#%E6%A0%87%E9%A2%98">标题</a></li><li><a href="#%E6%96%87%E6%9C%AC%E6%A0%B7%E5%BC%8F">文本样式</a></li><li><a href="#%E5%88%97%E8%A1%A8">列表</a></li><li><a href="#%E5%88%86%E5%89%B2%E7%BA%BF">分割线</a></li><li><a href="#%E9%93%BE%E6%8E%A5">链接</a></li><li><a href="#%E5%BC%95%E7%94%A8">引用</a></li><li><a href="#%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE">代码高亮</a></li><li><a href="#%E8%A1%A8%E6%A0%BC">表格</a></li><li><a href="#emoji-%E8%A1%A8%E6%83%85">Emoji 表情</a></li><li><a href="#%E6%B3%A8%E8%84%9A">注脚</a></li><li><a href="#%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F">数学公式</a></li><li><a href="#diff">Diff</a></li><li><a href="#%E6%B5%81%E7%A8%8B%E5%9B%BE">流程图</a></li><li><a href="#html">HTML</a></li><li><a href="#%E7%BC%96%E8%BE%91%E5%99%A8">编辑器</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="标题"><a class="markdownIt-Anchor" href="#标题"></a> 标题</h2><p>Markdown 支持六个级别的标题。</p><figure class="highlight clean"><table><tr><td class="code"><pre><span class="line">语法：</span><br><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">### 三级标题</span><br><span class="line">#### 四级标题</span><br><span class="line">##### 五级标题</span><br><span class="line">###### 六级标题</span><br></pre></td></tr></table></figure><h2 id="文本样式"><a class="markdownIt-Anchor" href="#文本样式"></a> 文本样式</h2><blockquote><p>💡 粗体、斜体、删除线可以混合使用。</p><p>在 Markdown 中，粗体文本、斜体文本可以使用 <code>*</code> 或 <code>_</code> 符号标记。建议统一风格，始终只用一种符号。</p></blockquote><table><thead><tr><th>语法</th><th>效果</th></tr></thead><tbody><tr><td>普通文本</td><td>普通文本</td></tr><tr><td><code>*斜体文本*</code> <code>_斜体文本_</code></td><td><em>斜体文本</em> <em>斜体文本</em></td></tr><tr><td><code>**粗体文本**</code> <code>__粗体文本__</code></td><td><strong>粗体文本</strong> <strong>粗体文本</strong></td></tr><tr><td><code>~~删除文本~~</code></td><td><s>删除文本</s></td></tr><tr><td><code>***粗斜体文本***</code> <code>___粗斜体文本___</code></td><td><em><strong>粗斜体文本</strong></em> <em><strong>粗斜体文本</strong></em></td></tr></tbody></table><h2 id="列表"><a class="markdownIt-Anchor" href="#列表"></a> 列表</h2><h3 id="无序列表"><a class="markdownIt-Anchor" href="#无序列表"></a> 无序列表</h3><ul><li>RED</li><li>YELLOW</li><li>BLUE</li></ul><h3 id="有序列表"><a class="markdownIt-Anchor" href="#有序列表"></a> 有序列表</h3><ol><li>第一步</li><li>第二步</li><li>第三步</li></ol><h3 id="任务列表"><a class="markdownIt-Anchor" href="#任务列表"></a> 任务列表</h3><ul><li>[x] 完成任务</li><li>[ ] 计划任务</li></ul><h3 id="多级列表"><a class="markdownIt-Anchor" href="#多级列表"></a> 多级列表</h3><ul><li>数据结构<ul><li>线性表<ul><li>顺序表</li><li>链表<ul><li>单链表</li><li>双链表</li></ul></li></ul></li><li>树<ul><li>二叉树<ul><li>二叉平衡树</li></ul></li></ul></li></ul></li></ul><h2 id="分割线"><a class="markdownIt-Anchor" href="#分割线"></a> 分割线</h2><p><code>***</code>、<code>---</code>、<code>___</code> 都可以作为分割线。</p><hr /><hr /><hr /><h2 id="链接"><a class="markdownIt-Anchor" href="#链接"></a> 链接</h2><h3 id="普通链接"><a class="markdownIt-Anchor" href="#普通链接"></a> 普通链接</h3><p>语法：</p><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">[<span class="string">我的博客</span>](<span class="link">https://dunwu.github.io/blog/</span>)</span><br></pre></td></tr></table></figure><ul><li><code>[]</code> 中标记链接名。类似 HTML 中 <code>&lt;a&gt;</code> 元素的 <code>title</code> 属性。</li><li><code>()</code> 中标记链接的 url，也支持相对路径（前提是资源可以访问）。类似 HTML 中 <code>&lt;a&gt;</code> 元素的 <code>href</code> 属性。</li></ul><p>效果：</p><ul><li><a href="https://dunwu.github.io/blog/" title="blog">我的博客</a></li></ul><h3 id="图片"><a class="markdownIt-Anchor" href="#图片"></a> 图片</h3><p>Markdown 引用图片的语法：</p><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">![<span class="string">alt</span>](<span class="link">url title</span>)</span><br></pre></td></tr></table></figure><p>alt 和 title 即对应 HTML 中 img 元素的 alt 和 title 属性（都可省略）：</p><ul><li><p>alt - 表示图片显示失败时的替换文本。</p></li><li><p>title - 表示鼠标悬停在图片时的显示文本（注意这里要加引号）</p></li><li><p>url - 即图片的 url 地址</p></li></ul><p><img src="http://dunwu.test.upcdn.net/common/logo/zp.png" alt="logo" title="logo" /></p><h3 id="图片链接"><a class="markdownIt-Anchor" href="#图片链接"></a> 图片链接</h3><p>可以将图片和链接混合使用。</p><p><a href="https://dunwu.github.io/blog/"><img src="http://dunwu.test.upcdn.net/common/logo/zp.png" alt="logo" title="logo" /></a></p><h3 id="锚点"><a class="markdownIt-Anchor" href="#锚点"></a> 锚点</h3><p>其实呢，每一个标题都是一个锚点，和 HTML 的锚点（<code>#</code>）类似，比如：<a href="#Markdown-%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97">回到顶部</a></p><h2 id="引用"><a class="markdownIt-Anchor" href="#引用"></a> 引用</h2><p>普通引用：</p><blockquote><p>❓ 什么是 <code>Markdown</code></p><p><strong>Markdown</strong>是一种<a href="https://zh.wikipedia.org/wiki/%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80" target="_blank" rel="noopener">轻量级标记语言</a>，创始人为<a href="https://zh.wikipedia.org/wiki/%E7%B4%84%E7%BF%B0%C2%B7%E6%A0%BC%E9%AD%AF%E4%BC%AF" target="_blank" rel="noopener">约翰·格鲁伯</a>（英语：John Gruber）。它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的<a href="https://zh.wikipedia.org/wiki/XHTML" target="_blank" rel="noopener">XHTML</a>（或者<a href="https://zh.wikipedia.org/wiki/HTML" target="_blank" rel="noopener">HTML</a>）文档”。[<a href="https://zh.wikipedia.org/wiki/Markdown#cite_note-md-4" target="_blank" rel="noopener">4]</a>这种语言吸收了很多在<a href="https://zh.wikipedia.org/wiki/%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6" target="_blank" rel="noopener">电子邮件</a>中已有的纯文本标记的特性。 —— 摘自 Wiki</p></blockquote><p>嵌套引用：</p><blockquote><p>数据结构</p><blockquote><p>树</p><blockquote><p>二叉树</p><blockquote><p>平衡二叉树</p><blockquote><p>满二叉树</p></blockquote></blockquote></blockquote></blockquote></blockquote><h2 id="代码高亮"><a class="markdownIt-Anchor" href="#代码高亮"></a> 代码高亮</h2><h3 id="标签"><a class="markdownIt-Anchor" href="#标签"></a> 标签</h3><p>语法：</p><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">`Markdown` `Doc`</span><br></pre></td></tr></table></figure><p>效果：</p><p><code>Markdown</code>, <code>Doc</code></p><h3 id="代码块"><a class="markdownIt-Anchor" href="#代码块"></a> 代码块</h3><p>语法一：在文本前后都使用三个反引号进行标记。【✔️ 推荐】</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这是一个文本块。</span><br><span class="line">这是一个文本块。</span><br><span class="line">这是一个文本块。</span><br></pre></td></tr></table></figure><p>语法二：在连续几行的文本开头加入 1 个 Tab 或者 4 个空格。【❌ 不推荐】</p><pre><code>这是一个文本块。这是一个文本块。这是一个文本块。</code></pre><h3 id="语法"><a class="markdownIt-Anchor" href="#语法"></a> 语法</h3><p>在三个反引号后面加上编程语言的名字，另起一行开始写代码，最后一行再加上三个反引号。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[]args)</span></span>&#123;&#125; <span class="comment">//Java</span></span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> <span class="comment">//C</span></span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"hello GitHub"</span> <span class="comment">#Bash</span></span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">document</span>.getElementById(<span class="string">'myH1'</span>).innerHTML = <span class="string">'Welcome to my Homepage'</span> <span class="comment">//javascipt</span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">string</span> &amp;<span class="keyword">operator</span>+(<span class="keyword">const</span> <span class="built_in">string</span>&amp; A,<span class="keyword">const</span> <span class="built_in">string</span>&amp; B) <span class="comment">//cpp</span></span><br></pre></td></tr></table></figure><h2 id="表格"><a class="markdownIt-Anchor" href="#表格"></a> 表格</h2><p>一般表格：</p><table><thead><tr><th>表头 1</th><th>表头 2</th></tr></thead><tbody><tr><td>表格单元</td><td>表格单元</td></tr><tr><td>表格单元</td><td>表格单元</td></tr></tbody></table><p>表格可以指定对齐方式：</p><table><thead><tr><th style="text-align:center">序号</th><th style="text-align:left">商品</th><th style="text-align:right">价格</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:left">电脑</td><td style="text-align:right">6000.0</td></tr><tr><td style="text-align:center">2</td><td style="text-align:left">鼠标</td><td style="text-align:right">100.0</td></tr><tr><td style="text-align:center">3</td><td style="text-align:left">键盘</td><td style="text-align:right">200.0</td></tr></tbody></table><h2 id="emoji-表情"><a class="markdownIt-Anchor" href="#emoji-表情"></a> Emoji 表情</h2><blockquote><p>💡 注意：部分 Markdown 引擎支持 Emoji。</p></blockquote><p>合理使用 Emoji 表情，往往可以使得文章内容更加丰富生动。例如：✔️ ❌ 💡 🔔 ❗️ ❓</p><blockquote><p>更多 Emoji 表情请参考：</p><ul><li><a href="http://emojihomepage.com/" target="_blank" rel="noopener">http://emojihomepage.com/</a></li><li><a href="http://www.emoji-cheat-sheet.com" target="_blank" rel="noopener">http://www.emoji-cheat-sheet.com</a></li></ul></blockquote><h2 id="注脚"><a class="markdownIt-Anchor" href="#注脚"></a> 注脚</h2><blockquote><p>💡 注意：部分 Markdown 引擎支持注脚。</p></blockquote><p>一个具有注脚的文本。<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p><h2 id="数学公式"><a class="markdownIt-Anchor" href="#数学公式"></a> 数学公式</h2><blockquote><p>💡  注意：部分 Markdown 引擎支持 Latex。</p></blockquote><p>很多文档中，需要引入一些数学符号、特殊符号，其排版问题比较头疼。这种问题，可以用 Latex 来解决，大部分 Markdown 引擎都支持 Latex。</p><p>Latex 可以使用 <code>$</code> 符号来标记 Latex 表达式，下面是一个数学公式示例：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∫</mo><mn>0</mn><mi mathvariant="normal">∞</mi></msubsup><msup><mi>t</mi><mrow><mi>z</mi><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>e</mi><mrow><mo>−</mo><mi>t</mi></mrow></msup><mi>d</mi><mi>t</mi><mtext> </mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt\,.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Γ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.326242em;vertical-align:-0.9119499999999999em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.414292em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span></span></span></span></span></p><p>列举一些常用数学符号：</p><table><thead><tr><th style="text-align:center">符号</th><th>语法</th><th>描述</th></tr></thead><tbody><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≤</mo></mrow><annotation encoding="application/x-tex">\leq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≤</span></span></span></span></td><td><code>$\leq$</code></td><td>小于等于</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≥</mo></mrow><annotation encoding="application/x-tex">\geq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span></span></span></span></td><td><code>$\geq$</code></td><td>大于等于</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">≠</mi></mrow><annotation encoding="application/x-tex">\neq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span></span></span></span></td><td><code>$\neq$</code></td><td>不等于</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.48312em;vertical-align:0em;"></span><span class="mrel">≈</span></span></span></span></td><td><code>$\approx$</code></td><td>约等于</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord">∞</span></span></span></span></td><td><code>$\infty$</code></td><td>无穷</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mo>∏</mo><mi>x</mi><mi>y</mi></msubsup></mrow><annotation encoding="application/x-tex">\prod_{x}^{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.104002em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span style="top:-3.2029000000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span></span></span></span></td><td><code>$\prod_{x}^{y}$</code></td><td>累乘</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></msubsup></mrow><annotation encoding="application/x-tex">\sum_{i=0}^n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.104002em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span></span></span></span></td><td><code>$\sum_{i=0}^n$</code></td><td>求和</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>∫</mo></mrow><annotation encoding="application/x-tex">\int</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.11112em;vertical-align:-0.30612em;"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;">∫</span></span></span></span></td><td><code>$\int$</code></td><td>积分</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>∬</mo></mrow><annotation encoding="application/x-tex">\iint</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.111em;vertical-align:-0.306em;"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0004999999999999727em;">∬</span></span></span></span></td><td><code>$\iint$</code></td><td>双重积分</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mo><mi>log</mi><mo>⁡</mo></mo><mi>x</mi></msub><mi>y</mi></mrow><annotation encoding="application/x-tex">\log_x{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93858em;vertical-align:-0.24414em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.057252em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span></span></td><td><code>$\log_x{y}$</code></td><td>对数</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mrow><mi>y</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">x^{y+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></td><td><code>$x^{y+1}$</code></td><td>上标</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>y</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_{y+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></td><td><code>$x_{y+1}$</code></td><td>下标</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>x</mi><mi>y</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{x}{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1764999999999999em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></td><td><code>$\frac{x}{y}$</code></td><td>分数</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mroot><mi>x</mi><mi>y</mi></mroot></mrow><annotation encoding="application/x-tex">\sqrt[y]{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.23972em;"></span><span class="mord sqrt"><span class="root"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5516160000000001em;"><span style="top:-2.836336em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size6 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span></span></span></span><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8002800000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">x</span></span></span><span style="top:-2.76028em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80H400000v40H845z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.23972em;"><span></span></span></span></span></span></span></span></span></td><td><code>$\sqrt[y]{x}$</code></td><td>开方</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>sin</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\sin</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66786em;vertical-align:0em;"></span><span class="mop">sin</span></span></span></span></td><td><code>$\sin$</code></td><td>正弦</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>cos</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\cos</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mop">cos</span></span></span></span></td><td><code>$\cos$</code></td><td>余弦</td></tr><tr><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>tan</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\tan</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mop">tan</span></span></span></span></td><td><code>$\tan$</code></td><td>正切</td></tr></tbody></table><blockquote><p>更多数学符号支持请参考：</p><ul><li><a href="https://github.com/luong-komorebi/Begin-Latex-in-minutes" target="_blank" rel="noopener">Begin-Latex-in-minutes</a></li><li><a href="https://blog.csdn.net/Katherine_hsr/article/details/79179622" target="_blank" rel="noopener">Markdown 数学符号&amp;公式</a></li></ul></blockquote><h2 id="diff"><a class="markdownIt-Anchor" href="#diff"></a> Diff</h2><blockquote><p>💡  注意：部分 Markdown 引擎支持 Diff。</p></blockquote><p>版本控制的系统中都少不了 diff 的功能，即展示一个文件内容的增加与删除。<br />GFM 中可以显示的展示 diff 效果。可以用 <code>+</code> 开头表示新增，<code>-</code> 开头表示删除。</p><figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="addition">+ 新增内容</span></span><br><span class="line"><span class="deletion">- 删除内容</span></span><br></pre></td></tr></table></figure><h2 id="uml-图"><a class="markdownIt-Anchor" href="#uml-图"></a> UML 图</h2><blockquote><p>💡  注意：部分 Markdown 引擎支持 <a href="https://mermaid-js.github.io/mermaid/" target="_blank" rel="noopener">mermaid</a>。</p><p><a href="https://mermaid-js.github.io/mermaid/" target="_blank" rel="noopener">mermaid</a> 提供了多种 UML 图。详情请参考：<a href="https://mermaidjs.github.io/" target="_blank" rel="noopener">mermaid 文档</a></p></blockquote><h3 id="流程图"><a class="markdownIt-Anchor" href="#流程图"></a> 流程图</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    A[Hard edge] --&gt;|Link text| B(Round edge)</span><br><span class="line">    B --&gt; C&#123;Decision&#125;</span><br><span class="line">    C --&gt;|One| D[Result one]</span><br><span class="line">    C --&gt;|Two| E[Result two]</span><br></pre></td></tr></table></figure><h3 id="时序图"><a class="markdownIt-Anchor" href="#时序图"></a> 时序图</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    Alice-&gt;&gt;Bob: Hello Bob, how are you?</span><br><span class="line">    alt is sick</span><br><span class="line">        Bob-&gt;&gt;Alice: Not so good :(</span><br><span class="line">    else is well</span><br><span class="line">        Bob-&gt;&gt;Alice: Feeling fresh like a daisy</span><br><span class="line">    end</span><br><span class="line">    opt Extra response</span><br><span class="line">        Bob-&gt;&gt;Alice: Thanks for asking</span><br><span class="line">    end</span><br></pre></td></tr></table></figure><h3 id="甘特图"><a class="markdownIt-Anchor" href="#甘特图"></a> 甘特图</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gantt</span><br><span class="line">       dateFormat  YYYY-MM-DD</span><br><span class="line">       title Adding GANTT diagram functionality to mermaid</span><br><span class="line"></span><br><span class="line">       section A section</span><br><span class="line">       Completed task            :done,    des1, 2014-01-06,2014-01-08</span><br><span class="line">       Active task               :active,  des2, 2014-01-09, 3d</span><br><span class="line">       Future task               :         des3, after des2, 5d</span><br><span class="line">       Future task2              :         des4, after des3, 5d</span><br><span class="line"></span><br><span class="line">       section Critical tasks</span><br><span class="line">       Completed task in the critical line :crit, done, 2014-01-06,24h</span><br><span class="line">       Implement parser and jison          :crit, done, after des1, 2d</span><br><span class="line">       Create tests for parser             :crit, active, 3d</span><br><span class="line">       Future task in critical line        :crit, 5d</span><br><span class="line">       Create tests for renderer           :2d</span><br><span class="line">       Add to mermaid                      :1d</span><br><span class="line"></span><br><span class="line">       section Documentation</span><br><span class="line">       Describe gantt syntax               :active, a1, after des1, 3d</span><br><span class="line">       Add gantt diagram to demo page      :after a1  , 20h</span><br><span class="line">       Add another diagram to demo page    :doc1, after a1  , 48h</span><br><span class="line"></span><br><span class="line">       section Last section</span><br><span class="line">       Describe gantt syntax               :after doc1, 3d</span><br><span class="line">       Add gantt diagram to demo page      :20h</span><br><span class="line">       Add another diagram to demo page    :48h</span><br></pre></td></tr></table></figure><h2 id="html"><a class="markdownIt-Anchor" href="#html"></a> HTML</h2><p>有些 Markdown 引擎支持在文档中嵌入的 html 元素。</p><p>有些 Markdown 语法所不支持的特性，可以使用 html 元素来支持。</p><h3 id="折叠"><a class="markdownIt-Anchor" href="#折叠"></a> 折叠</h3><details>  <summary>折叠内容一</summary>  <p>展开才能看到的内容</p></details><details>  <summary>折叠内容二</summary>  <p>展开才能看到的内容</p></details><h3 id="居中"><a class="markdownIt-Anchor" href="#居中"></a> 居中</h3><div align="center"><p>居中显示的文本</p></div><h3 id="图片尺寸"><a class="markdownIt-Anchor" href="#图片尺寸"></a> 图片尺寸</h3><div align="center"><img width="100px" src="http://dunwu.test.upcdn.net/common/logo/zp.png" /></div><h2 id="编辑器"><a class="markdownIt-Anchor" href="#编辑器"></a> 编辑器</h2><p>推荐 Markdown 编辑器</p><ul><li><a href="https://www.typora.io/" target="_blank" rel="noopener">Typora</a> - 个人认为是功能最强的 Markdown 编辑器。</li><li><a href="https://github.com/microsoft/vscode" target="_blank" rel="noopener">Visual Studio Code</a> - 可以通过安装插件，量身打造 Markdown 编辑器。</li><li><a href="https://github.com/marktext/marktext" target="_blank" rel="noopener">marktext</a> - 一款简单优雅的 Markdown 编辑器。</li><li><a href="https://stackedit.io/" target="_blank" rel="noopener">StackEdit</a> - 在线 Markdown 编辑器。</li><li><a href="https://pandao.github.io/editor.md/" target="_blank" rel="noopener">Editor.md</a> - 在线 Markdown 编辑器。</li><li><a href="https://maxiang.io/" target="_blank" rel="noopener">Marxico</a> - 一款专为印象笔记（Evernote）打造的 Markdown 编辑器。</li></ul><blockquote><p>想了解更多 Markdown 编辑器可以参考：<a href="https://zhuanlan.zhihu.com/p/69210764" target="_blank" rel="noopener">主流 Markdown 编辑器推荐</a></p></blockquote><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://zh.wikipedia.org/wiki/Markdown" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Markdown</a></li><li><a href="https://github.com/guodongxiaren/README" target="_blank" rel="noopener">https://github.com/guodongxiaren/README</a></li><li><a href="https://github.com/tchapi/markdown-cheatsheet" target="_blank" rel="noopener">markdown-cheatsheet</a></li><li><a href="https://github.com/luong-komorebi/Begin-Latex-in-minutes" target="_blank" rel="noopener">Begin-Latex-in-minutes</a></li><li><a href="https://github.com/mermaid-js/mermaid" target="_blank" rel="noopener">https://github.com/mermaid-js/mermaid</a></li></ul><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>注脚的解释 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;markdown-cheat-sheet&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#markdown-cheat-sheet&quot;&gt;&lt;/a&gt; Markdown Cheat Sheet&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;📦 本文
      
    
    </summary>
    
    
      <category term="效率提升" scheme="https://dunwu.github.io/blog/categories/%E6%95%88%E7%8E%87%E6%8F%90%E5%8D%87/"/>
    
      <category term="规范" scheme="https://dunwu.github.io/blog/categories/%E6%95%88%E7%8E%87%E6%8F%90%E5%8D%87/%E8%A7%84%E8%8C%83/"/>
    
    
      <category term="效率提升" scheme="https://dunwu.github.io/blog/tags/%E6%95%88%E7%8E%87%E6%8F%90%E5%8D%87/"/>
    
      <category term="规范" scheme="https://dunwu.github.io/blog/tags/%E8%A7%84%E8%8C%83/"/>
    
      <category term="markdown" scheme="https://dunwu.github.io/blog/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>限流算法</title>
    <link href="https://dunwu.github.io/blog/theory/limiting/"/>
    <id>https://dunwu.github.io/blog/theory/limiting/</id>
    <published>2020-01-20T03:06:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="限流算法"><a class="markdownIt-Anchor" href="#限流算法"></a> 限流算法</h1><blockquote><p>在高并发场景下，为了应对瞬时海量请求的压力，保障系统的平稳运行，必须预估系统的流量阈值，通过限流规则阻断处理不过来的请求。</p><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p></blockquote><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E9%99%90%E6%B5%81%E7%AE%80%E4%BB%8B">一、限流简介</a></li><li><a href="#%E4%BA%8C%E8%AE%A1%E6%95%B0%E5%99%A8%E6%B3%95">二、计数器法</a></li><li><a href="#%E4%B8%89%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%B3%95">三、滑动窗口法</a></li><li><a href="#%E5%9B%9B%E4%BB%A4%E7%89%8C%E6%A1%B6%E6%B3%95">四、令牌桶法</a></li><li><a href="#%E4%BA%94%E6%BC%8F%E6%A1%B6%E6%B3%95">五、漏桶法</a></li><li><a href="#%E5%85%AD%E9%99%90%E6%B5%81%E5%B7%A5%E5%85%B7">六、限流工具</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-限流简介"><a class="markdownIt-Anchor" href="#一-限流简介"></a> 一、限流简介</h2><p>限流可以认为是服务降级的一种。限流就是<strong>限制系统的输入和输出流量已达到保护系统的目的</strong>。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。</p><p>限流规则包含三个部分：时间粒度，接口粒度，最大限流值。限流规则设置是否合理直接影响到限流是否合理有效。</p><h2 id="二-计数器法"><a class="markdownIt-Anchor" href="#二-计数器法"></a> 二、计数器法</h2><p>计数器法的<strong>原理</strong>是：设置一个计数器，用于统计指定时间段内的请求数量，并在指定时间段之后重置计数器。在这个过程中，如果请求量超过限定的阈值，则拒绝请求。</p><p>这种算法的缺陷是：这种算法是针对一个时间段进行统计，如果请求分布不均匀，极端情况下，<strong>所有请求都在某一刻收到，还是可能压垮系统</strong>。例如，假设我们限流规则为每秒钟不超过 100 次接口请求，第一个 1s 时间窗口内，100 次接口请求都集中在最后的 10ms 内，在第二个 1s 的时间窗口内，100 次接口请求都集中在最开始的 10ms 内，虽然两个时间窗口内流量都符合限流要求，但是在这两个时间窗口临界的 20ms 内会集中有 200 次接口请求，如果不做限流，集中在这 20ms 内的 200 次请求就有可能压垮系统。</p><p>【示例】使用 <code>AtomicInteger</code> 实现计数器法</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Counter</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 最大访问数量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> limit = <span class="number">10</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 访问时间差</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> timeout = <span class="number">1000</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 请求时间</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> time;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当前计数器</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> AtomicInteger reqCount = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">limit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> now = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">if</span> (now &lt; time + timeout) &#123;</span><br><span class="line">            <span class="comment">// 单位时间内</span></span><br><span class="line">            reqCount.addAndGet(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">return</span> reqCount.get() &lt;= limit;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 超出单位时间</span></span><br><span class="line">            time = now;</span><br><span class="line">            reqCount = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【示例】基于 Redis Lua 计数限流算法的实现</p><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 实现原理</span></span><br><span class="line"><span class="comment">-- 每次请求都将当前时间，精确到秒作为 key 放入 Redis 中，超时时间设置为 2s， Redis 将该 key 的值进行自增</span></span><br><span class="line"><span class="comment">-- 当达到阈值时返回错误，表示请求被限流</span></span><br><span class="line"><span class="comment">-- 写入 Redis 的操作用 Lua 脚本来完成，利用 Redis 的单线程机制可以保证每个 Redis 请求的原子性</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 资源唯一标志位</span></span><br><span class="line"><span class="keyword">local</span> key = KEYS[<span class="number">1</span>]</span><br><span class="line"><span class="comment">-- 限流大小</span></span><br><span class="line"><span class="keyword">local</span> limit = <span class="built_in">tonumber</span>(ARGV[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 获取当前流量大小</span></span><br><span class="line"><span class="keyword">local</span> currentLimit = <span class="built_in">tonumber</span>(redis.call(<span class="string">'get'</span>, key) <span class="keyword">or</span> <span class="string">"0"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> currentLimit + <span class="number">1</span> &gt; limit <span class="keyword">then</span></span><br><span class="line">    <span class="comment">-- 达到限流大小 返回</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="comment">-- 没有达到阈值 value + 1</span></span><br><span class="line">    redis.call(<span class="string">"INCRBY"</span>, key, <span class="number">1</span>)</span><br><span class="line">    <span class="comment">-- 设置过期时间</span></span><br><span class="line">    redis.call(<span class="string">"EXPIRE"</span>, key, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> currentLimit + <span class="number">1</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2 id="三-滑动窗口法"><a class="markdownIt-Anchor" href="#三-滑动窗口法"></a> 三、滑动窗口法</h2><p>滑动窗口法的<strong>原理</strong>：</p><p>滑动窗口法是计数器算法的一种改进，<strong>增加一个时间粒度的度量单位，将原来的一个时间窗口划分成多个时间窗口，并且不断向右滑动该窗口</strong>。流量经过滑动时间窗口算法整形之后，可以保证任意时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑，可以部分解决上面提到的临界突发流量问题。</p><p>对比固定时间窗口限流算法，滑动时间窗口限流算法的时间窗口是持续滑动的，并且除了需要一个计数器来记录时间窗口内接口请求次数之外，还需要记录在时间窗口内每个接口请求到达的时间点，对内存的占用会比较多。 在临界位置的突发请求都会被算到时间窗口内，因此可以解决计数器算法的临界问题，</p><p>比如在上文的例子中，通过滑动窗口算法整型后，第一个 1s 的时间窗口的 100 次请求都会通过，第二个时间窗口最开始的 10ms 内的 100 个请求都会被限流熔断。</p><p>滑动窗口法的<strong>缺陷</strong>：基于时间窗口的限流算法，<strong>只能在选定的时间粒度上限流，对选定时间粒度内的更加细粒度的访问频率不做限制</strong>。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentLinkedQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.stream.IntStream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeWindow</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ConcurrentLinkedQueue&lt;Long&gt; queue = <span class="keyword">new</span> ConcurrentLinkedQueue&lt;Long&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 间隔秒数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> seconds;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 最大限流</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> max;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TimeWindow</span><span class="params">(<span class="keyword">int</span> max, <span class="keyword">int</span> seconds)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.seconds = seconds;</span><br><span class="line">        <span class="keyword">this</span>.max = max;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 永续线程执行清理queue 任务</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 等待 间隔秒数-1 执行清理操作</span></span><br><span class="line">                    Thread.sleep((seconds - <span class="number">1</span>) * <span class="number">1000L</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                clean();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> TimeWindow timeWindow = <span class="keyword">new</span> TimeWindow(<span class="number">10</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 测试3个线程</span></span><br><span class="line">        IntStream.range(<span class="number">0</span>, <span class="number">3</span>).forEach((i) -&gt; &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        Thread.sleep(<span class="keyword">new</span> Random().nextInt(<span class="number">20</span>) * <span class="number">100</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                    timeWindow.take();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;).start();</span><br><span class="line"></span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取令牌，并且添加时间</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">take</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> size = sizeOfValid();</span><br><span class="line">            <span class="keyword">if</span> (size &gt; max) &#123;</span><br><span class="line">                System.err.println(<span class="string">"超限"</span>);</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">synchronized</span> (queue) &#123;</span><br><span class="line">                <span class="keyword">if</span> (sizeOfValid() &gt; max) &#123;</span><br><span class="line">                    System.err.println(<span class="string">"超限"</span>);</span><br><span class="line">                    System.err.println(<span class="string">"queue中有 "</span> + queue.size() + <span class="string">" 最大数量 "</span> + max);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">this</span>.queue.offer(System.currentTimeMillis());</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">"queue中有 "</span> + queue.size() + <span class="string">" 最大数量 "</span> + max);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sizeOfValid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Iterator&lt;Long&gt; it = queue.iterator();</span><br><span class="line">        Long ms = System.currentTimeMillis() - seconds * <span class="number">1000</span>;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">            <span class="keyword">long</span> t = it.next();</span><br><span class="line">            <span class="keyword">if</span> (t &gt; ms) &#123;</span><br><span class="line">                <span class="comment">// 在当前的统计时间范围内</span></span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 清理过期的时间</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clean</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Long c = System.currentTimeMillis() - seconds * <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line">        Long tl = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ((tl = queue.peek()) != <span class="keyword">null</span> &amp;&amp; tl &lt; c) &#123;</span><br><span class="line">            System.out.println(<span class="string">"清理数据"</span>);</span><br><span class="line">            queue.poll();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="四-令牌桶法"><a class="markdownIt-Anchor" href="#四-令牌桶法"></a> 四、令牌桶法</h2><p>令牌桶算法的<strong>原理</strong>：</p><ol><li>接口限制 T 秒内最大访问次数为 N，则每隔 T/N 秒会放一个 token 到桶中</li><li>桶内最多存放 M 个 token，如果 token 到达时令牌桶已经满了，那么这个 token 就会被丢弃</li><li>接口请求会先从令牌桶中取 token，拿到 token 则处理接口请求，拿不到 token 则进行限流处理</li></ol><p>因为令牌桶存放了很多令牌，那么大量的突发请求会被执行，但是它不会出现临界问题，在令牌用完之后，令牌是以一个恒定的速率添加到令牌桶中的，因此不能再次发送大量突发请求。</p><p>规定固定容量的桶，token 以固定速度往桶内填充，当桶满时 token 不会被继续放入，每过来一个请求把 token 从桶中移除,如果桶中没有 token 不能请求。</p><p>【示例】Java 实现令牌桶算法</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenBucket</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 时间</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> time;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 总量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Double total;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * token 放入速度</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Double rate;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当前总量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Double nowSize;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">limit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> now = System.currentTimeMillis();</span><br><span class="line">        nowSize = Math.min(total, nowSize + (now - time) * rate);</span><br><span class="line">        time = now;</span><br><span class="line">        <span class="keyword">if</span> (nowSize &lt; <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">// 桶里没有token</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 存在token</span></span><br><span class="line">            nowSize -= <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【示例】基于 Redis Lua 令牌桶限流算法实现</p><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 令牌桶限流</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 令牌的唯一标识</span></span><br><span class="line"><span class="keyword">local</span> bucketKey = KEYS[<span class="number">1</span>]</span><br><span class="line"><span class="comment">-- 上次请求的时间</span></span><br><span class="line"><span class="keyword">local</span> last_mill_request_key = KEYS[<span class="number">2</span>]</span><br><span class="line"><span class="comment">-- 令牌桶的容量</span></span><br><span class="line"><span class="keyword">local</span> limit = <span class="built_in">tonumber</span>(ARGV[<span class="number">1</span>])</span><br><span class="line"><span class="comment">-- 请求令牌的数量</span></span><br><span class="line"><span class="keyword">local</span> permits = <span class="built_in">tonumber</span>(ARGV[<span class="number">2</span>])</span><br><span class="line"><span class="comment">-- 令牌流入的速率</span></span><br><span class="line"><span class="keyword">local</span> rate = <span class="built_in">tonumber</span>(ARGV[<span class="number">3</span>])</span><br><span class="line"><span class="comment">-- 当前时间</span></span><br><span class="line"><span class="keyword">local</span> curr_mill_time = <span class="built_in">tonumber</span>(ARGV[<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 添加令牌</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 获取当前令牌的数量</span></span><br><span class="line"><span class="keyword">local</span> current_limit = <span class="built_in">tonumber</span>(redis.call(<span class="string">'get'</span>, bucketKey) <span class="keyword">or</span> <span class="string">"0"</span>)</span><br><span class="line"><span class="comment">-- 获取上次请求的时间</span></span><br><span class="line"><span class="keyword">local</span> last_mill_request_time = <span class="built_in">tonumber</span>(redis.call(<span class="string">'get'</span>, last_mill_request_key) <span class="keyword">or</span> <span class="string">"0"</span>)</span><br><span class="line"><span class="comment">-- 计算向桶里添加令牌的数量</span></span><br><span class="line"><span class="keyword">if</span> last_mill_request_time == <span class="number">0</span> <span class="keyword">then</span></span><br><span class="line"><span class="comment">-- 令牌桶初始化</span></span><br><span class="line"><span class="comment">-- 更新上次请求时间</span></span><br><span class="line">redis.call(<span class="string">"HSET"</span>, last_mill_request_key, curr_mill_time)</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">local</span> add_token_num = <span class="built_in">math</span>.<span class="built_in">floor</span>((curr_mill_time - last_mill_request_time) * rate)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 更新令牌的数量</span></span><br><span class="line"><span class="keyword">if</span> current_limit + add_token_num &gt; limit <span class="keyword">then</span></span><br><span class="line">    current_limit = limit</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">current_limit = current_limit + add_token_num</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">redis.<span class="built_in">pcall</span>(<span class="string">"HSET"</span>,bucketKey, current_limit)</span><br><span class="line"><span class="comment">-- 设置过期时间</span></span><br><span class="line">redis.call(<span class="string">"EXPIRE"</span>, bucketKey, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 限流判断</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> current_limit - permits &lt; <span class="number">1</span> <span class="keyword">then</span></span><br><span class="line">    <span class="comment">-- 达到限流大小</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="comment">-- 没有达到限流大小</span></span><br><span class="line">current_limit = current_limit - permits</span><br><span class="line">redis.<span class="built_in">pcall</span>(<span class="string">"HSET"</span>, bucketKey, current_limit)</span><br><span class="line">    <span class="comment">-- 设置过期时间</span></span><br><span class="line">    redis.call(<span class="string">"EXPIRE"</span>, bucketKey, <span class="number">2</span>)</span><br><span class="line"><span class="comment">-- 更新上次请求的时间</span></span><br><span class="line">redis.call(<span class="string">"HSET"</span>, last_mill_request_key, curr_mill_time)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2 id="五-漏桶法"><a class="markdownIt-Anchor" href="#五-漏桶法"></a> 五、漏桶法</h2><p>相比于令牌桶算法，漏桶法对于取令牌的频率也有限制，要按照 T/N 的固定速率来取令牌 。</p><p>令牌桶算法和漏桶算法对流量的整形效果比较好，但是并不是整型效果好就越合适，对于没有提前预热的令牌桶，如果做否决式限流，会导致误杀很多请求。上述算法中当 n 比较小时，比如 50，间隔 20ms 才会向桶中放入一个令牌，而接口的访问在 1s 内可能随机性很强，这就会出现：尽管从曲线上看对最大访问频率的限制很有效，流量在细时间粒度上面都很平滑，但是误杀了很多本不应该拒绝的接口请求。</p><p>【示例】漏桶法实现</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LeakBucket</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 时间</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> time;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 总量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Double total;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 水流出去的速度</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Double rate;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当前总量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Double nowSize;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">limit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> now = System.currentTimeMillis();</span><br><span class="line">        nowSize = Math.max(<span class="number">0</span>, (nowSize - (now - time) * rate));</span><br><span class="line">        time = now;</span><br><span class="line">        <span class="keyword">if</span> ((nowSize + <span class="number">1</span>) &lt; total) &#123;</span><br><span class="line">            nowSize++;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="六-限流工具"><a class="markdownIt-Anchor" href="#六-限流工具"></a> 六、限流工具</h2><p>前面介绍了限流算法的基本原理和一些简单的实现。但在生产环境，我们一般应该使用更成熟的限流工具。</p><ul><li>Guava 的 <code>RateLimiter</code>：RateLimiter 基于漏桶算法，但它参考了令牌桶算法。具体用法可以参考：<a href="https://blog.csdn.net/forezp/article/details/100060686" target="_blank" rel="noopener">RateLimiter 基于漏桶算法，但它参考了令牌桶算法</a></li><li><a href="https://github.com/Netflix/Hystrix" target="_blank" rel="noopener">Hystrix</a>：经典的限流、熔断工具，很值得借鉴学习。注：官方已停止发布版本。</li><li><a href="https://github.com/alibaba/Sentinel" target="_blank" rel="noopener">Sentinel</a>：阿里的限流、熔断工具。</li></ul><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://item.jd.com/11322972.html" target="_blank" rel="noopener">《大型网站技术架构：核心原理与案例分析》</a></li><li><a href="https://www.jianshu.com/p/76cc8ba5ca91" target="_blank" rel="noopener">谈谈限流算法的几种实现</a></li><li><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/huifer-how-to-limit-current.md" target="_blank" rel="noopener">如何限流？在工作中是怎么做的？说一下具体的实现？</a></li><li><a href="https://gongfukangee.github.io/2019/04/04/Limit/" target="_blank" rel="noopener">浅析限流算法</a></li><li><a href="https://blog.csdn.net/forezp/article/details/100060686" target="_blank" rel="noopener">RateLimiter 基于漏桶算法，但它参考了令牌桶算法</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;限流算法&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#限流算法&quot;&gt;&lt;/a&gt; 限流算法&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;在高并发场景下，为了应对瞬时海量请求的压力，保障系统的平稳运行，必须预估系统的流量阈值，通过限流规则阻断处
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="限流" scheme="https://dunwu.github.io/blog/tags/%E9%99%90%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>系统测试架构</title>
    <link href="https://dunwu.github.io/blog/design/architecture/test-architecture/"/>
    <id>https://dunwu.github.io/blog/design/architecture/test-architecture/</id>
    <published>2019-12-10T09:00:00.000Z</published>
    <updated>2020-07-25T07:46:26.677Z</updated>
    
    <content type="html"><![CDATA[<h1 id="系统测试架构"><a class="markdownIt-Anchor" href="#系统测试架构"></a> 系统测试架构</h1><blockquote><p>软件测试描述一种用来促进鉴定软件的正确性、完整性、安全性和质量的过程。软件测试的经典定义是：在规定的条件下对程序进行操作，以发现程序错误，衡量软件质量，并对其是否能满足设计要求进行评估的过程。</p><p>现代软件开发项目中，分工明确，基本上都会有研发、测试、QA 等角色。不同角色由于关注的视角不同，测试目标和测试方法也不完全相同。本文主要从研发、测试的视角去考量软件测试技术。</p><p>注意：</p><ul><li>为了方便，只有测试人员需要关注的测试点用【测试】标注；</li><li>而只有研发人员需要关注的测试点用【研发】标注；</li><li>都需要关注的测试点则不作标注。</li></ul></blockquote><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95%E5%88%86%E7%B1%BB">测试方法分类</a><ul><li><a href="#%E4%BB%8E%E6%B5%8B%E8%AF%95%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95%E5%88%86%E7%B1%BB">从测试设计方法分类</a></li><li><a href="#%E4%BB%8E%E6%B5%8B%E8%AF%95%E7%9A%84%E7%9B%AE%E7%9A%84%E5%88%86%E7%B1%BB">从测试的目的分类</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="测试方法分类"><a class="markdownIt-Anchor" href="#测试方法分类"></a> 测试方法分类</h2><h3 id="从测试设计方法分类"><a class="markdownIt-Anchor" href="#从测试设计方法分类"></a> 从测试设计方法分类</h3><ul><li><strong>黑盒测试【测试】</strong> - 把软件系统当作一个“黑箱”，无法了解或使用系统的内部结构及知识。从软件的行为，而不是内部结构出发来设计测试。</li><li><strong>白盒测试【研发】</strong> - 设计者可以看到软件系统的内部结构，并且使用软件的内部知识来指导测试数据及方法的选择。</li><li><strong>灰盒测试</strong> - 介于黑盒和白盒之间。</li></ul><blockquote><p>小结：</p><ul><li>黑河测试通常针对的是软件的行为或功能，一般是测试人员主要关注的。</li><li>白盒测试通常则需要对软件有一定程度的了解，一般是开发人员所关注的。</li><li>灰盒测试通常是为了测试软件在特定的场景下的表现，而非主场景。</li></ul></blockquote><h3 id="从测试的目的分类"><a class="markdownIt-Anchor" href="#从测试的目的分类"></a> 从测试的目的分类</h3><h4 id="功能测试"><a class="markdownIt-Anchor" href="#功能测试"></a> 功能测试</h4><ul><li><strong>单元测试（Unit Test）</strong> - 在最低粒度的功能/参数上验证程序的准确性，比如测试一个函数的正确性。【研发】<ul><li>常用技术：<a href="https://github.com/junit-team/junit4" target="_blank" rel="noopener"><strong>junit4</strong></a>、<a href="https://github.com/junit-team/junit5" target="_blank" rel="noopener"><strong>junit5</strong></a>、<a href="https://github.com/mockito/mockito" target="_blank" rel="noopener"><strong>mockito</strong></a>、<a href="https://github.com/joel-costigliola/assertj-core" target="_blank" rel="noopener"><strong>assertj-core</strong></a></li></ul></li><li><strong>功能测试（Functional Test）</strong> - 验证模块的功能。【测试】</li><li><strong>集成测试（Integration Test）</strong> - 验证几个互相有依赖关系的模块的功能。【测试】</li><li><strong>场景测试（Scenario Test）</strong>- 验证几个模块是否能完成一个用户场景。【测试】</li><li><strong>系统测试（System Test）</strong> - 对于整个系统功能的测试。【测试】</li><li><strong>Alpha 测试</strong> - 软件测试人员在真实用户环境中对软件进行全面的测试。【测试】</li><li><strong>Beta 测试</strong> - 也叫公测，是真实的用户在真实的环境中进行的测试。</li></ul><h4 id="非功能测试"><a class="markdownIt-Anchor" href="#非功能测试"></a> 非功能测试</h4><ul><li><strong>压力测试（Stress test）</strong> - 验证软件在超过负载设计的情况下仍能返回正确的结果，没有崩溃</li><li><strong>负载测试（Load test）</strong> - 测试软件在负载情况下能否正常工作</li><li><strong>性能测试（Performance test）</strong> - 测试软件的效能，是否提供满意的服务质量。<ul><li>常用技术：<a href="https://jmeter.apache.org/" target="_blank" rel="noopener"><strong>JMeter</strong></a>、JMH。</li></ul></li><li><strong>软件辅助功能测试（Accessibility test</strong>） - 测试软件是否向残疾用户提供足够的辅助功能</li><li><strong>本地化/全球化测试（Localization/Globalization</strong>）</li><li><strong>兼容性测试（Compatibility Test）</strong></li><li><strong>配置测试（Configuration Test）</strong> - 测试软件在各种配置下能否正常工作</li><li><strong>可用性测试（Usability Test）</strong> – 测试软件是否好用</li><li><strong>安全性测试（Security Test）</strong></li></ul><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://www.cnblogs.com/TankXiao/archive/2012/02/20/2347016.html" target="_blank" rel="noopener">软件测试 (一) 软件测试方法大汇总</a></li><li><a href="https://www.xncoding.com/2018/01/07/java/jmh.html" target="_blank" rel="noopener">Java 微基准测试框架 JMH</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;系统测试架构&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#系统测试架构&quot;&gt;&lt;/a&gt; 系统测试架构&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;软件测试描述一种用来促进鉴定软件的正确性、完整性、安全性和质量的过程。软件测试的经典定义是：在
      
    
    </summary>
    
    
      <category term="设计" scheme="https://dunwu.github.io/blog/categories/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="架构" scheme="https://dunwu.github.io/blog/categories/%E8%AE%BE%E8%AE%A1/%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="设计" scheme="https://dunwu.github.io/blog/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="架构" scheme="https://dunwu.github.io/blog/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="测试" scheme="https://dunwu.github.io/blog/tags/%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>分布式存储基本原理</title>
    <link href="https://dunwu.github.io/blog/theory/distributed-storage/"/>
    <id>https://dunwu.github.io/blog/theory/distributed-storage/</id>
    <published>2019-10-16T12:54:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式存储基本原理"><a class="markdownIt-Anchor" href="#分布式存储基本原理"></a> 分布式存储基本原理</h1><blockquote><p>分片（Sharding）的基本思想就要把一个数据库切分成多个部分，存储在不同的数据库(server)上，从而缓解单一数据库的性能问题。</p><p>分库分表一定是为了支撑 <strong>高并发、数据量大</strong> 两个问题的。</p><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p></blockquote><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB">一、读写分离</a><ul><li><a href="#%E4%B8%BA%E4%BD%95%E8%A6%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB">为何要读写分离</a></li><li><a href="#%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%8E%9F%E7%90%86">读写分离的原理</a></li><li><a href="#%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E9%97%AE%E9%A2%98">读写分离的问题</a></li></ul></li><li><a href="#%E4%BA%8C%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8">二、分库分表</a><ul><li><a href="#%E4%B8%BA%E4%BD%95%E8%A6%81%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8">为何要分库分表</a></li><li><a href="#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%8E%9F%E7%90%86">分库分表原理</a></li><li><a href="#%E8%BF%81%E7%A7%BB%E5%92%8C%E6%89%A9%E5%AE%B9">迁移和扩容</a></li><li><a href="#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%9A%84%E9%97%AE%E9%A2%98">分库分表的问题</a></li></ul></li><li><a href="#%E4%B8%89%E4%B8%AD%E9%97%B4%E4%BB%B6">三、中间件</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-读写分离"><a class="markdownIt-Anchor" href="#一-读写分离"></a> 一、读写分离</h2><p><strong>读写分离的基本原理是：主服务器用来处理写操作以及实时性要求比较高的读操作，而从服务器用来处理读操作</strong>。</p><h3 id="为何要读写分离"><a class="markdownIt-Anchor" href="#为何要读写分离"></a> 为何要读写分离</h3><ul><li><strong>有效减少锁竞争</strong> - 主服务器只负责写，从服务器只负责读，能够有效的避免由数据更新导致的行锁竞争，使得整个系统的查询性能得到极大的改善。</li><li><strong>提高查询吞吐量</strong> - 通过一主多从的配置方式，可以将查询请求均匀的分散到多个数据副本，能够进一步的提升系统的处理能力。</li><li><strong>提升数据库可用性</strong> - 使用多主多从的方式，不但能够提升系统的吞吐量，还能够提升数据库的可用性，可以达到在任何一个数据库宕机，甚至磁盘物理损坏的情况下仍然不影响系统的正常运行。</li></ul><h3 id="读写分离的原理"><a class="markdownIt-Anchor" href="#读写分离的原理"></a> 读写分离的原理</h3><p>读写分离的实现是根据 SQL 语义分析，将读操作和写操作分别路由至主库与从库。</p><p><img src="https://shardingsphere.apache.org/document/current/img/read-write-split/read-write-split.png" alt="读写分离" /></p><p>读写分离的基本实现是：</p><p><img src="http://dunwu.test.upcdn.net/cs/database/mysql/master-slave-proxy.png" alt="img" /></p><ul><li>数据库服务器搭建主从集群，一主一从、一主多从都可以。</li><li>数据库主机负责读写操作，从机只负责读操作。</li><li>数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了全量数据。</li><li>业务服务器将写操作发给数据库主机，将读操作发给数据库从机。</li><li>主机会记录请求的二进制日志，然后推送给从库，从库解析并执行日志中的请求，完成主从复制。这意味着：复制过程存在时延，这段时间内，主从数据可能不一致。</li></ul><h3 id="读写分离的问题"><a class="markdownIt-Anchor" href="#读写分离的问题"></a> 读写分离的问题</h3><p>读写分离存在两个问题：<strong>数据一致性</strong>和<strong>分发机制</strong>。</p><h4 id="数据一致性"><a class="markdownIt-Anchor" href="#数据一致性"></a> 数据一致性</h4><p>读写分离产生了主库与从库之间的数据一致性的问题。</p><p><img src="https://shardingsphere.apache.org/document/current/img/read-write-split/sharding-read-write-split.png" alt="数据分片 + 读写分离" /></p><h4 id="分发机制"><a class="markdownIt-Anchor" href="#分发机制"></a> 分发机制</h4><p>数据库读写分离后，一个 SQL 请求具体分发到哪个数据库节点？一般有两种分发方式：客户端分发和中间件代理分发。</p><p>客户端分发，是基于程序代码，自行控制数据分发到哪个数据库节点。更细一点来说，一般程序中建立多个数据库的连接，根据一定的算法，选择合适的连接去发起 SQL 请求。这种方式也被称为客户端中间件，代表有：jdbc-sharding。</p><p>中间件代理分发，指的是独立一套系统出来，实现读写操作分离和数据库服务器连接的管理。中间件对业务服务器提供 SQL 兼容的协议，业务服务器无须自己进行读写分离。对于业务服务器来说，访问中间件和访问数据库没有区别，事实上在业务服务器看来，中间件就是一个数据库服务器。代表有：Mycat。</p><h2 id="二-分库分表"><a class="markdownIt-Anchor" href="#二-分库分表"></a> 二、分库分表</h2><h3 id="为何要分库分表"><a class="markdownIt-Anchor" href="#为何要分库分表"></a> 为何要分库分表</h3><p>分库分表主要基于以下理由：</p><ul><li><strong>并发连接</strong> - 单库超过每秒 2000 个并发时，而一个健康的单库最好保持在每秒 1000 个并发左右，不要太大。</li><li><strong>磁盘容量</strong> - 磁盘容量占满，会导致服务器不可用。</li><li><strong>SQL 性能</strong> - 单表数据量过大，会导致 SQL 执行效率低下。一般，单表有 200 万条数据，就可以考虑分表了。</li></ul><table><thead><tr><th>#</th><th>分库分表前</th><th>分库分表后</th></tr></thead><tbody><tr><td>并发支撑情况</td><td>MySQL 单机部署，扛不住高并发</td><td>MySQL 从单机到多机，能承受的并发增加了多倍</td></tr><tr><td>磁盘使用情况</td><td>MySQL 单机磁盘容量几乎撑满</td><td>拆分为多个库，数据库服务器磁盘使用率大大降低</td></tr><tr><td>SQL 执行性能</td><td>单表数据量太大，SQL 越跑越慢</td><td>单表数据量减少，SQL 执行效率明显提升</td></tr></tbody></table><h3 id="分库分表原理"><a class="markdownIt-Anchor" href="#分库分表原理"></a> 分库分表原理</h3><p><strong>数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果</strong>。 数据分片的有效手段是对关系型数据库进行分库和分表。分库和分表均可以有效的避免由数据量超过可承受阈值而产生的查询瓶颈。 除此之外，分库还能够用于有效的分散对数据库单点的访问量；分表虽然无法缓解数据库压力，但却能够提供尽量将分布式事务转化为本地事务的可能，一旦涉及到跨库的更新操作，分布式事务往往会使问题变得复杂。 使用多主多从的分片方式，可以有效的避免数据单点，从而提升数据架构的可用性。</p><p>通过分库和分表进行数据的拆分来使得各个表的数据量保持在阈值以下，以及对流量进行疏导应对高访问量，是应对高并发和海量数据系统的有效手段。 数据分片的拆分方式又分为垂直分片和水平分片。</p><h4 id="垂直分片"><a class="markdownIt-Anchor" href="#垂直分片"></a> 垂直分片</h4><p>垂直分片有两种拆分考量：业务拆分和访问频率拆分</p><p>（1）业务拆分</p><blockquote><p>业务拆分的核心理念是<strong>专库专用</strong>。</p></blockquote><p>在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务。而拆分之后，则是<strong>按照业务将表进行归类，分布到不同的数据库中</strong>，从而将压力分散至不同的数据库。下图展示了根据业务需要，将用户表和订单表垂直分片到不同的数据库的方案。</p><p>垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对互联网业务需求快速变化的；而且，它也并无法真正的解决单点瓶颈。<strong>垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理</strong>。</p><p>（2）访问频率拆分</p><blockquote><p>访问频率拆分，是 <strong>把一个有很多字段的表给拆分成多个表，或者是多个库上去</strong>。一般来说，会 <strong>将较少的、访问频率较高的字段放到一个表中</strong>，然后 <strong>将较多的、访问频率较低的字段放到另外一个表中</strong>。因为数据库是有缓存的，访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。</p></blockquote><p><img src="http://dunwu.test.upcdn.net/snap/image-20200114211639899.png" alt="image-20200114211639899" /></p><p>一般来说，满足下面的条件就可以考虑扩容了：</p><ul><li>Mysql 单库超过 5000 万条记录，Oracle 单库超过 1 亿条记录，DB 压力就很大。</li><li>单库超过每秒 2000 个并发时，而一个健康的单库最好保持在每秒 1000 个并发左右，不要太大。</li></ul><p>在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。</p><h4 id="水平分片"><a class="markdownIt-Anchor" href="#水平分片"></a> 水平分片</h4><blockquote><p><strong>水平拆分</strong> 又称为 <strong>Sharding</strong>，它是将同一个表中的记录拆分到多个结构相同的表中。当 <strong>单表数据量太大</strong> 时，会极大影响 <strong>SQL 执行的性能</strong> 。分表是将原来一张表的数据分布到数据库集群的不同节点上，从而缓解单点的压力。</p></blockquote><p>相对于垂直分片，水平分片不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。 例如：根据主键分片，偶数主键的记录放入 0 库（或表），奇数主键的记录放入 1 库（或表）。</p><p>水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。</p><p><img src="http://dunwu.test.upcdn.net/snap/image-20200114211203589.png" alt="image-20200114211203589" /></p><p>一般来说，<strong>单表有 200 万条数据</strong> 的时候，性能就会相对差一些了，需要考虑分表了。但是，这也要视具体情况而定，可能是 100 万条，也可能是 500 万条，SQL 越复杂，就最好让单表行数越少。</p><p>读写分离的数据节点中的数据内容是一致的，而水平分片的每个数据节点的数据内容却并不相同。将水平分片和读写分离联合使用，能够更加有效的提升系统性能。</p><h4 id="分库分表策略"><a class="markdownIt-Anchor" href="#分库分表策略"></a> 分库分表策略</h4><p><img src="http://dunwu.test.upcdn.net/snap/20200608091832.png" alt="img" /></p><p>分库分表策略主要有两种：</p><ul><li>根据数值范围划分</li><li>根据 Hash 划分</li></ul><h5 id="数值范围路由"><a class="markdownIt-Anchor" href="#数值范围路由"></a> 数值范围路由</h5><p>数值范围路由，就是根据 ID、时间范围 这类具有排序性的字段来进行划分。例如：用户 Id 为 1-9999 的记录分到第一个库，10000-20000 的分到第二个库，以此类推。</p><p>按这种策略划分出来的数据，具有数据连续性。</p><p>优点：数据迁移很简单。</p><p>缺点：容易产生热点问题，大量的流量都打在最新的数据上了。</p><h5 id="hash-路由"><a class="markdownIt-Anchor" href="#hash-路由"></a> Hash 路由</h5><p><img src="C:%5CUsers%5Czp%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200608092034118.png" alt="image-20200608092034118" /></p><p>典型的 Hash 路由，如根据数值取模，当需要扩容时，一般以 2 的幂次方进行扩容（这样，扩容时迁移的数据量会小一些）。例如：用户 Id mod n，余数为 0 的记录放到第一个库，余数为 1 的放到第二个库，以此类推。</p><p>一般采用 <strong>预分区</strong> 的方式，提前根据 <strong>数据量</strong> 规划好 <strong>分区数</strong>，比如划分为 <code>512</code> 或 <code>1024</code> 张表，保证可支撑未来一段时间的 <strong>数据容量</strong>，再根据 <strong>负载情况</strong> 将 <strong>表</strong> 迁移到其他 <strong>数据库</strong> 中。扩容时通常采用 <strong>翻倍扩容</strong>，避免 <strong>数据映射</strong> 全部被 <strong>打乱</strong>，导致 <strong>全量迁移</strong> 的情况。</p><p>优点：数据离散分布，不存在热点问题。</p><p>缺点：数据迁移、扩容麻烦（之前的数据需要重新计算 hash 值重新分配到不同的库或表）。当 <strong>节点数量</strong> 变化时，如 <strong>扩容</strong> 或 <strong>收缩</strong> 节点，数据节点 <strong>映射关系</strong> 需要重新计算，会导致数据的 <strong>重新迁移</strong>。</p><h5 id="路由表"><a class="markdownIt-Anchor" href="#路由表"></a> 路由表</h5><p>这种策略，就是用一张独立的表记录路由信息。</p><p>优点：简单、灵活，尤其是在扩容、迁移时，只需要迁移指定的数据，然后修改路由表即可。</p><p>缺点：每次查询，必须先查路由表，增加了 IO 开销。并且，如果路由表本身太大，也会面临性能瓶颈，如果想对路由表再做分库分表，将出现死循环式的路由算法选择问题。</p><h3 id="迁移和扩容"><a class="markdownIt-Anchor" href="#迁移和扩容"></a> 迁移和扩容</h3><h4 id="停机迁移扩容不推荐"><a class="markdownIt-Anchor" href="#停机迁移扩容不推荐"></a> 停机迁移/扩容（不推荐）</h4><p>停机迁移/扩容是最暴力、最简单的迁移、扩容方案。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200601114836.png" alt="img" /></p><h5 id="停机迁移扩容流程"><a class="markdownIt-Anchor" href="#停机迁移扩容流程"></a> 停机迁移/扩容流程</h5><p>（0）预估停服时间，发布停服公告。</p><p>（1）停服，不允许数据访问。</p><p>（2）编写临时的数据导入程序，从老数据库中读取数据。</p><p>（3）将数据写入中间件。</p><p>（4）中间件根据分片规则，将数据分发到分库（分表）中。</p><p>（5）应用程序修改配置，重启。</p><h5 id="停机迁移扩容方案分析"><a class="markdownIt-Anchor" href="#停机迁移扩容方案分析"></a> 停机迁移/扩容方案分析</h5><p>优点：简单、没有数据一致性问题。</p><p>缺点：如果老的数据库数据量很大，则停机处理时间可能很久。比如老的数据库是已经分库分表的数据库群，数据量可能达到亿级，导入数据可能就要花费几小时。如果中间过程中出现问题，就容易引发重大事故。</p><p>点评：综上，这种方案代价太高，不可取。</p><h4 id="双写迁移"><a class="markdownIt-Anchor" href="#双写迁移"></a> 双写迁移</h4><p><img src="http://dunwu.test.upcdn.net/snap/20200601135751.png" alt="img" /></p><h5 id="双写迁移流程"><a class="markdownIt-Anchor" href="#双写迁移流程"></a> 双写迁移流程</h5><p>（1）修改应用程序配置，将数据同时写入老数据库和中间件。这就是所谓的<strong>双写</strong>，同时写俩库，老库和新库。</p><p>（2）编写临时程序，读取老数据库。</p><p>（3）将数据写入中间件。如果数据不存在，直接写入；如果数据存在，比较时间戳，只允许新数据覆盖老数据。</p><p>（4）导入数据后，有可能数据还是存在不一致，那么就对数据进行校验，比对新老库的每条数据。如果存在差异，针对差异数据，执行（3）。循环（3）、（4）步骤，直至数据完全一致。</p><p>（5）修改应用程序配置，将数据只写入中间件。</p><p>（6）中间件根据分片规则，将数据分发到分库（分表）中。</p><h4 id="主从升级"><a class="markdownIt-Anchor" href="#主从升级"></a> 主从升级</h4><p>生产环境的数据库，为了保证高可用，一般会采用主备架构。主库支持读写操作，从库支持读操作。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200601121215.png" alt="img" /></p><p>由于主备节点数据一致，所以将从库升级为主节点，并修改分片配置，将从节点作为分库之一，就实现了扩容。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200601121400.png" alt="img" /></p><h5 id="升级从库的流程"><a class="markdownIt-Anchor" href="#升级从库的流程"></a> 升级从库的流程</h5><p>（1）解除主从关系，从库升级为主库。</p><p>（2）应用程序，修改配置，读写通过中间件。</p><p>（3）分库分表中间，修改分片配置。将数据按照新的规则分发。</p><p>（4）编写临时程序，清理冗余数据。比如：原来是一个单库，数据量为 400 万。从节点升级为分库之一后，每个分库都有 400 万数据，其中 200 万是冗余数据。清理完后，进行数据校验。</p><p>（5）为每个分库添加新的从库，保证高可用。</p><h5 id="升级从库方案分析"><a class="markdownIt-Anchor" href="#升级从库方案分析"></a> 升级从库方案分析</h5><p>优点：不需要停机，无需数据迁移。</p><p>缺点：</p><h3 id="分库分表的问题"><a class="markdownIt-Anchor" href="#分库分表的问题"></a> 分库分表的问题</h3><h4 id="分布式-id-问题"><a class="markdownIt-Anchor" href="#分布式-id-问题"></a> 分布式 ID 问题</h4><p>一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的 ID 无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得 ID，以便进行 SQL 路由。</p><blockquote><p>分布式 ID 的解决方案详见：<a href="https://github.com/dunwu/blog/blob/master/source/_posts/theory/distributed-id.md" target="_blank" rel="noopener">分布式 ID</a></p></blockquote><h4 id="分布式事务问题"><a class="markdownIt-Anchor" href="#分布式事务问题"></a> 分布式事务问题</h4><p>跨库事务也是分布式的数据库集群要面对的棘手事情。 合理采用分表，可以在降低单表数据量的情况下，尽量使用本地事务，善于使用同库不同表可有效避免分布式事务带来的麻烦。在不能避免跨库事务的场景，有些业务仍然需要保持事务的一致性。 而基于 XA 的分布式事务由于在并发度高的场景中性能无法满足需要，并未被互联网巨头大规模使用，他们大多采用最终一致性的柔性事务代替强一致事务。</p><blockquote><p>分布式事务的解决方案详见：<a href="https://github.com/dunwu/blog/blob/master/source/_posts/theory/distributed-transaction.md" target="_blank" rel="noopener">分布式事务</a></p></blockquote><h4 id="跨节点-join-和聚合"><a class="markdownIt-Anchor" href="#跨节点-join-和聚合"></a> 跨节点 Join 和聚合</h4><p>分库分表后，无法直接跨节点 <code>join</code> 、<code>count</code>、<code>order by</code>、<code>group by</code> 以及聚合。</p><p>针对这类问题，普遍做法是<strong>二次查询</strong>。</p><p>在第一次查询时，获取各个节点上的结果。</p><p>在程序中将这些结果进行合并、筛选。</p><h4 id="跨分片的排序分页"><a class="markdownIt-Anchor" href="#跨分片的排序分页"></a> 跨分片的排序分页</h4><p>一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/3710706-925381b9a478c8df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img" /></p><p>上面图中所描述的只是最简单的一种情况（取第一页数据），看起来对性能的影响并不大。但是，如果想取出第 10 页数据，情况又将变得复杂很多，如下图所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/3710706-9a7cfbdb95bb9b70.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img" /></p><p>有些读者可能并不太理解，为什么不能像获取第一页数据那样简单处理（排序取出前 10 条再合并、排序）。其实并不难理解，因为各分片节点中的数据可能是随机的，为了排序的准确性，必须把所有分片节点的前 N 页数据都排序好后做合并，最后再进行整体的排序。很显然，这样的操作是比较消耗资源的，用户越往后翻页，系统性能将会越差。</p><p>那如何解决分库情况下的分页问题呢？有以下几种办法：</p><p>如果是在前台应用提供分页，则限定用户只能看前面 n 页，这个限制在业务上也是合理的，一般看后面的分页意义不大（如果一定要看，可以要求用户缩小范围重新查询）。</p><p>如果是后台批处理任务要求分批获取数据，则可以加大 page size，比如每次获取 5000 条记录，有效减少分页数（当然离线访问一般走备库，避免冲击主库）。</p><p>分库设计时，一般还有配套大数据平台汇总所有分库的记录，有些分页查询可以考虑走大数据平台。</p><h2 id="三-中间件"><a class="markdownIt-Anchor" href="#三-中间件"></a> 三、中间件</h2><p>国内常见分库分表中间件：</p><ul><li><a href="https://github.com/alibaba/cobar" target="_blank" rel="noopener">Cobar</a> - 阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 cobar 集群，cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。</li><li><a href="https://github.com/alibaba/tb_tddl" target="_blank" rel="noopener">TDDL</a> - 淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。</li><li><a href="https://github.com/Qihoo360/Atlas" target="_blank" rel="noopener">Atlas</a> - 360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。</li><li><a href="https://github.com/dangdangdotcom/sharding-jdbc" target="_blank" rel="noopener">sharding-jdbc</a> - 当当开源的，属于 client 层方案。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且目前推出到了 2.0 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也<strong>可以选择的方案</strong>。</li><li><a href="http://www.mycat.org.cn/" target="_blank" rel="noopener">Mycat</a> - 基于 cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 sharding jdbc 来说，年轻一些，经历的锤炼少一些。</li></ul><p>技术选型建议：</p><p>建议使用的是 sharding-jdbc 和 mycat。</p><ul><li><a href="https://github.com/dangdangdotcom/sharding-jdbc" target="_blank" rel="noopener">sharding-jdbc</a> 这种 client 层方案的<strong>优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高</strong>，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要<strong>耦合</strong> sharding-jdbc 的依赖。其本质上通过配置多数据源，然后根据设定的分库分表策略，计算路由，将请求发送到计算得到的节点上。</li><li><a href="http://www.mycat.org.cn/" target="_blank" rel="noopener">Mycat</a> 这种 proxy 层方案的<strong>缺点在于需要部署</strong>，自己运维一套中间件，运维成本高，但是<strong>好处在于对于各个项目是透明的</strong>，如果遇到升级之类的都是自己中间件那里搞就行了。</li></ul><p>通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 mycat，然后大量项目直接透明使用即可。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://shardingsphere.apache.org/document/current/cn/overview/" target="_blank" rel="noopener">ShardingSphere 官方文档</a></li><li><a href="https://juejin.im/post/5bf778ef5188251b8a26ed8b" target="_blank" rel="noopener">“分库分表&quot; ？选型和流程要慎重，否则会失控</a></li><li><a href="https://www.jianshu.com/p/32b3e91aa22c" target="_blank" rel="noopener">分库分表需要考虑的问题及方案</a></li><li><a href="https://juejin.im/post/5d4b6dc1f265da03c1288332" target="_blank" rel="noopener">一次难得的分库分表实践</a></li><li><a href="https://www.cnblogs.com/barrywxx/p/11532122.html" target="_blank" rel="noopener">分库分表平滑扩容</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分布式存储基本原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#分布式存储基本原理&quot;&gt;&lt;/a&gt; 分布式存储基本原理&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;分片（Sharding）的基本思想就要把一个数据库切分成多个部分，存储在不同
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分片" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>分布式 ID 基本原理</title>
    <link href="https://dunwu.github.io/blog/theory/distributed-id/"/>
    <id>https://dunwu.github.io/blog/theory/distributed-id/</id>
    <published>2019-07-24T03:55:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式-id-基本原理"><a class="markdownIt-Anchor" href="#分布式-id-基本原理"></a> 分布式 ID 基本原理</h1><blockquote><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p><p>传统数据库软件开发中，主键自动生成技术是基本需求。而各个数据库对于该需求也提供了相应的支持，比如 MySQL 的自增键，Oracle 的自增序列等。</p><p>数据分片后，不同数据节点生成全局唯一主键是非常棘手的问题。同一个逻辑表内的不同实际表之间的自增键由于无法互相感知而产生重复主键。 虽然可通过约束自增主键初始值和步长的方式避免碰撞，但需引入额外的运维规则，使解决方案缺乏完整性和可扩展性。</p><p>为此，需要使用分布式 ID 来解决此问题。本文总结业界常用的分布式 ID 解决方案。</p></blockquote><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E5%88%86%E5%B8%83%E5%BC%8F-id-%E7%AE%80%E4%BB%8B">一、分布式 ID 简介</a></li><li><a href="#%E4%BA%8Cuuid">二、UUID</a><ul><li><a href="#uuid-%E7%9A%84%E4%BC%98%E7%82%B9">UUID 的优点</a></li><li><a href="#uuid-%E7%9A%84%E7%BC%BA%E7%82%B9">UUID 的缺点</a></li><li><a href="#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF">适用场景</a></li></ul></li><li><a href="#%E4%B8%89%E5%88%A9%E7%94%A8%E7%AC%AC%E4%B8%89%E6%96%B9%E5%AD%98%E5%82%A8%E7%94%9F%E6%88%90%E9%94%AE">三、利用第三方存储生成键</a><ul><li><a href="#%E4%BC%98%E7%82%B9">优点</a></li><li><a href="#%E7%BC%BA%E7%82%B9">缺点</a></li></ul></li><li><a href="#%E5%9B%9B%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95snowflake">四、雪花算法（Snowflake）</a><ul><li><a href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86">基本原理</a></li><li><a href="#%E4%BC%98%E7%82%B9-1">优点</a></li><li><a href="#%E7%BC%BA%E7%82%B9-1">缺点</a></li><li><a href="#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF-1">适用场景</a></li><li><a href="#%E9%98%B2%E6%AD%A2%E6%97%B6%E9%92%9F%E5%9B%9E%E6%8B%A8">防止时钟回拨</a></li></ul></li><li><a href="#%E4%BA%94leaf">五、Leaf</a><ul><li><a href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86-1">基本原理</a></li><li><a href="#%E4%BC%98%E7%82%B9-2">优点</a></li><li><a href="#%E7%BC%BA%E7%82%B9-2">缺点</a></li><li><a href="#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF-2">适用场景</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-分布式-id-简介"><a class="markdownIt-Anchor" href="#一-分布式-id-简介"></a> 一、分布式 ID 简介</h2><p>首先，分布式 ID 应该具备哪些特性呢？</p><ol><li><strong>全局唯一性</strong> - 不能出现重复的 ID 号，既然是唯一标识，这是最基本的要求。</li><li><strong>趋势递增</strong> - 在 MySQL InnoDB 引擎中使用的是聚集索引，由于多数 RDBMS 使用 B-tree 的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。</li><li><strong>单调递增</strong> - 保证下一个 ID 一定大于上一个 ID，例如事务版本号、IM 增量消息、排序等特殊需求。</li><li><strong>信息安全</strong> - 如果 ID 是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定 URL 即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要 ID 无规则、不规则。</li></ol><h2 id="二-uuid"><a class="markdownIt-Anchor" href="#二-uuid"></a> 二、UUID</h2><p>UUID 是最简单的分布式 ID 方案。</p><p>UUID 是通用唯一识别码（Universally Unique Identifier)的缩写，开放软件基金会(OSF)规范定义了包括网卡 MAC 地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素。利用这些元素来生成 UUID。</p><p>UUID 是由 128 位二进制组成，一般转换成十六进制，然后用 String 表示。在 java 中有个 UUID 类,在他的注释中我们看见这里有 4 种不同的 UUID 的生成策略:</p><ul><li>random - 基于随机数生成 UUID，由于 Java 中的随机数是伪随机数，其重复的概率是可以被计算出来的。这个一般我们用下面的代码获取基于随机数的 UUID:</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String id = UUID.randomUUID().toString();</span><br></pre></td></tr></table></figure><ul><li>time-based - 基于时间的 UUID,这个一般是通过当前时间，随机数，和本地 Mac 地址来计算出来，自带的 JDK 包并没有这个算法的我们在一些 UUIDUtil 中，比如我们的 log4j.core.util，会重新定义 UUID 的高位和低位。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> UUID <span class="title">getTimeBasedUuid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> time = System.currentTimeMillis() * <span class="number">10000L</span> + <span class="number">122192928000000000L</span> + (<span class="keyword">long</span>)(COUNT.incrementAndGet() % <span class="number">10000</span>);</span><br><span class="line">    <span class="keyword">long</span> timeLow = (time &amp; <span class="number">4294967295L</span>) &lt;&lt; <span class="number">32</span>;</span><br><span class="line">    <span class="keyword">long</span> timeMid = (time &amp; <span class="number">281470681743360L</span>) &gt;&gt; <span class="number">16</span>;</span><br><span class="line">    <span class="keyword">long</span> timeHi = (time &amp; <span class="number">1152640029630136320L</span>) &gt;&gt; <span class="number">48</span>;</span><br><span class="line">    <span class="keyword">long</span> most = timeLow | timeMid | <span class="number">4096L</span> | timeHi;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> UUID(most, LEAST);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>DCE security - DCE 安全的 UUID。</p></li><li><p>name-based - 基于名字的 UUID，通过计算名字和名字空间的 MD5 来计算 UUID。</p></li></ul><h3 id="uuid-的优点"><a class="markdownIt-Anchor" href="#uuid-的优点"></a> UUID 的优点</h3><ul><li>通过本地生成，没有经过网络 I/O，性能较快。</li></ul><h3 id="uuid-的缺点"><a class="markdownIt-Anchor" href="#uuid-的缺点"></a> UUID 的缺点</h3><ul><li><strong>长度过长</strong> - UUID 太长，16 字节 128 位，通常以 36 长度的字符串表示，很多场景不适用。例如：Mysql 官方明确建议主键越短越好，36 个字符长度的 UUID 不符合要求。</li><li><strong>信息不安全</strong> - 基于 MAC 地址生成 UUID 的算法可能会造成 MAC 地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。</li><li><strong>无序性</strong> - 不能生成递增有序的数字。这对于一些特定场景不利。例如：如果作为数据库主键，在 InnoDB 引擎下，UUID 的无序性可能会引起数据位置频繁变动，严重影响性能。</li></ul><h3 id="适用场景"><a class="markdownIt-Anchor" href="#适用场景"></a> 适用场景</h3><p>UUID 的适用场景可以为不需要担心过多的空间占用，以及不需要生成有递增趋势的数字。在 Log4j 里 <code>UuidPatternConverter</code> 中加入了 UUID 来标识每一条日志。</p><h2 id="三-利用第三方存储生成键"><a class="markdownIt-Anchor" href="#三-利用第三方存储生成键"></a> 三、利用第三方存储生成键</h2><p>提到自增键，最先想到的肯定是直接使用数据库自增键。<em>各数据库对于该需求也提供了相应的支持，比如 MySQL 的自增键，Oracle 的自增序列等</em>。</p><p>当然，也可以考虑是用 Redis 这样的 Nosql，甚至 ZooKeeper 去生成键</p><h3 id="优点"><a class="markdownIt-Anchor" href="#优点"></a> 优点</h3><ul><li>非常简单，利用现有的功能实现，成本小</li><li>有序递增</li><li>方便排序和分页</li></ul><h3 id="缺点"><a class="markdownIt-Anchor" href="#缺点"></a> 缺点</h3><ul><li>强依赖第三方存储，如果第三方存储非高可用系统，若出现丢失数据的情况，就可能出现重复生成 ID 的问题。</li><li>生成 ID 性能瓶颈依赖于第三方存储的性能。</li><li>增加了对第三方存储运维的成本。</li></ul><h2 id="四-雪花算法snowflake"><a class="markdownIt-Anchor" href="#四-雪花算法snowflake"></a> 四、雪花算法（Snowflake）</h2><p>雪花算法（Snowflake）是由 Twitter 公布的分布式主键生成算法，<strong>它会生成一个 <code>64 bit</code> 的整数</strong>，可以保证不同进程主键的不重复性，以及相同进程主键的有序性。</p><p>在同一个进程中，它首先是通过时间位保证不重复，如果时间相同则是通过序列位保证。 同时由于时间位是单调递增的，且各个服务器如果大体做了时间同步，那么生成的主键在分布式环境可以认为是总体有序的，这就保证了对索引字段的插入的高效性。</p><h3 id="基本原理"><a class="markdownIt-Anchor" href="#基本原理"></a> 基本原理</h3><h4 id="键的组成"><a class="markdownIt-Anchor" href="#键的组成"></a> 键的组成</h4><p>使用<strong>雪花算法生成的主键，二进制表示形式包含 4 部分</strong>，从高位到低位分表为：1bit 符号位、41bit 时间戳位、10bit 工作进程位以及 12bit 序列号位。</p><ul><li><strong>符号位(1bit)</strong></li></ul><p>预留的符号位，恒为零。</p><ul><li><strong>时间戳位(41bit)</strong></li></ul><p>41 位的时间戳可以容纳的毫秒数是 2 的 41 次幂，一年所使用的毫秒数是：<code>365 * 24 * 60 * 60 * 1000</code>。通过计算可知：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.pow(<span class="number">2</span>, <span class="number">41</span>) / (<span class="number">365</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span> * <span class="number">1000L</span>);</span><br></pre></td></tr></table></figure><p>结果约等于 69.73 年。ShardingSphere 的雪花算法的时间纪元从 2016 年 11 月 1 日零点开始，可以使用到 2086 年，相信能满足绝大部分系统的要求。</p><ul><li><strong>工作进程位(10bit)</strong></li></ul><p>该标志在 Java 进程内是唯一的，如果是分布式应用部署应保证每个工作进程的 id 是不同的。该值默认为 0，可通过属性设置。</p><ul><li><strong>序列号位(12bit)</strong></li></ul><p>该序列是用来在同一个毫秒内生成不同的 ID。如果在这个毫秒内生成的数量超过 4096(2 的 12 次幂)，那么生成器会等待到下个毫秒继续生成。</p><p>雪花算法主键的详细结构见下图：</p><p><img src="https://shardingsphere.apache.org/document/current/img/sharding/snowflake_cn_v2.png" alt="雪花算法" /></p><h4 id="时钟回拨"><a class="markdownIt-Anchor" href="#时钟回拨"></a> 时钟回拨</h4><p>服务器时钟回拨会导致产生重复序列，因此默认分布式主键生成器提供了一个最大容忍的时钟回拨毫秒数。 如果时钟回拨的时间超过最大容忍的毫秒数阈值，则程序报错；如果在可容忍的范围内，默认分布式主键生成器会等待时钟同步到最后一次主键生成的时间后再继续工作。 最大容忍的时钟回拨毫秒数的默认值为 0，可通过属性设置。</p><h4 id="灵活定制"><a class="markdownIt-Anchor" href="#灵活定制"></a> 灵活定制</h4><p>上面只是一个将 <code>64bit</code> 划分的标准，当然也不一定这么做，可以根据不同业务的具体场景来划分，比如下面给出一个业务场景：</p><ul><li>服务目前 QPS10 万，预计几年之内会发展到百万。</li><li>当前机器三地部署，上海，北京，深圳都有。</li><li>当前机器 10 台左右，预计未来会增加至百台。</li></ul><p>这个时候我们根据上面的场景可以再次合理的划分 62bit，QPS 几年之内会发展到百万，那么每毫秒就是千级的请求，目前 10 台机器那么每台机器承担百级的请求，为了保证扩展，后面的循环位可以限制到 1024，也就是 2^10，那么循环位 10 位就足够了。</p><p>机器三地部署我们可以用 3bit 总共 8 来表示机房位置，当前的机器 10 台，为了保证扩展到百台那么可以用 7bit 128 来表示，时间位依然是 41bit，那么还剩下 64-10-3-7-41-1 = 2bit，还剩下 2bit 可以用来进行扩展。</p><p><img src="https://user-gold-cdn.xitu.io/2018/9/29/16624909d2007c22?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" /></p><h3 id="优点-2"><a class="markdownIt-Anchor" href="#优点-2"></a> 优点</h3><ul><li>生成的 ID 都是趋势递增的。</li><li>不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成 ID 的性能也是非常高的。</li><li>可以根据自身业务特性分配 bit 位，非常灵活。</li></ul><h3 id="缺点-2"><a class="markdownIt-Anchor" href="#缺点-2"></a> 缺点</h3><ul><li>强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。</li></ul><h3 id="适用场景-2"><a class="markdownIt-Anchor" href="#适用场景-2"></a> 适用场景</h3><p>当我们需要无序不能被猜测的 ID，并且需要一定高性能，且需要 long 型，那么就可以使用我们雪花算法。比如常见的订单 ID，用雪花算法别人就无法猜测你每天的订单量是多少。</p><h3 id="防止时钟回拨"><a class="markdownIt-Anchor" href="#防止时钟回拨"></a> 防止时钟回拨</h3><p>雪花算法是强依赖于时间的，而如果机器时间发生回拨，有可能会生成重复的 ID。</p><p>我们可以针对算法做一些优化，来防止时钟回拨生成重复 ID。</p><p>用当前时间和上一次的时间进行判断，如果当前时间小于上一次的时间那么肯定是发生了回拨。普通的算法会直接抛出异常，这里我们可以对其进行优化，一般分为两个情况:</p><ul><li>如果时间回拨时间较短，比如配置 <code>5ms</code> 以内，那么可以直接等待一定的时间，让机器的时间追上来。</li><li>如果时间的回拨时间较长，我们不能接受这么长的阻塞等待，那么又有两个策略:<ul><li>直接拒绝，抛出异常。打日志，通知 RD 时钟回滚。</li><li>利用扩展位。上面我们讨论过，不同业务场景位数可能用不到那么多比特位，那么我们可以把扩展位数利用起来。比如：当这个时间回拨比较长的时候，我们可以不需要等待，直接在扩展位加 1。两位的扩展位允许我们有三次大的时钟回拨，一般来说就够了，如果其超过三次我们还是选择抛出异常，打日志。</li></ul></li></ul><h2 id="五-leaf"><a class="markdownIt-Anchor" href="#五-leaf"></a> 五、Leaf</h2><blockquote><p>美团提供了一种分布式 ID 解决方案 Leaf，其本质可以视为数据库分段+服务缓存 ID。</p><p>详情可以参考 <a href="https://tech.meituan.com/2017/04/21/mt-leaf.html" target="_blank" rel="noopener">Leaf——美团点评分布式 ID 生成系统</a></p></blockquote><h3 id="基本原理-2"><a class="markdownIt-Anchor" href="#基本原理-2"></a> 基本原理</h3><p>使用数据库生成 ID，但是做了如下改进：</p><p>原方案每次获取 ID 都得读写一次数据库，造成数据库压力大。改为利用 proxy server 批量获取，每次获取一个 segment(step 决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。 - 各个业务不同的发号需求用 biz_tag 字段来区分，每个 biz-tag 的 ID 获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对 biz_tag 分库分表就行。</p><p>数据库表设计如下：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">+<span class="comment">-------------+--------------+------+-----+-------------------+-----------------------------+</span></span><br><span class="line">| Field       | Type         | Null | Key | Default           | Extra                       |</span><br><span class="line">+<span class="comment">-------------+--------------+------+-----+-------------------+-----------------------------+</span></span><br><span class="line">| biz_tag     | varchar(128) | NO   | PRI |                   |                             |</span><br><span class="line">| max_id      | bigint(20)   | NO   |     | 1                 |                             |</span><br><span class="line">| step        | int(11)      | NO   |     | NULL              |                             |</span><br><span class="line">| desc        | varchar(256) | YES  |     | NULL              |                             |</span><br><span class="line">| update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on <span class="keyword">update</span> <span class="keyword">CURRENT_TIMESTAMP</span> |</span><br><span class="line">+<span class="comment">-------------+--------------+------+-----+-------------------+-----------------------------+</span></span><br></pre></td></tr></table></figure><p>重要字段说明：</p><ul><li><code>biz_tag</code> 用来区分业务</li><li><code>max_id</code> 表示该 <code>biz_tag</code> 目前所被分配的 ID 号段的最大值</li><li><code>step</code> 表示每次分配的号段长度。原来获取 ID 每次都需要写数据库，现在只需要把 <code>step</code> 设置得足够大，比如 1000。那么只有当 1000 个号被消耗完了之后才会去重新读写一次数据库。读写数据库的频率从 1 减小到了 1/step。</li></ul><p>大致架构如下图所示：</p><p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2017/5e4ff128.png" alt="image" /></p><p>test_tag 在第一台 Leaf 机器上是 <code>1~1000</code> 的号段，当这个号段用完时，会去加载另一个长度为 step=1000 的号段，假设另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是 <code>3001~4000</code>。同时数据库对应的 biz_tag 这条数据的 max_id 会从 3000 被更新成 4000，更新号段的 SQL 语句如下：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Begin</span></span><br><span class="line"><span class="keyword">UPDATE</span> <span class="keyword">table</span> <span class="keyword">SET</span> max_id=max_id+step <span class="keyword">WHERE</span> biz_tag=xxx</span><br><span class="line"><span class="keyword">SELECT</span> tag, max_id, step <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> biz_tag=xxx</span><br><span class="line"><span class="keyword">Commit</span></span><br></pre></td></tr></table></figure><h3 id="优点-3"><a class="markdownIt-Anchor" href="#优点-3"></a> 优点</h3><ul><li>比数据库自增键性能高</li><li>能保证键趋势递增。</li><li>如果数据库宕机，由于 proxServer 有缓存，依然可以坚持一段时间。</li></ul><h3 id="缺点-3"><a class="markdownIt-Anchor" href="#缺点-3"></a> 缺点</h3><ul><li>和主键递增一样，容易被人猜测。</li><li>数据库宕机后，虽然能支撑一段时间，但是仍然会造成系统不可用。</li></ul><h3 id="适用场景-3"><a class="markdownIt-Anchor" href="#适用场景-3"></a> 适用场景</h3><p>需要趋势递增，并且 ID 大小可控制的，可以使用这套方案。</p><p>当然这个方案也可以通过一些手段避免被人猜测，把 ID 变成是无序的，比如把我们生成的数据是一个递增的 long 型，把这个 Long 分成几个部分，比如可以分成几组三位数，几组四位数，然后在建立一个映射表，将我们的数据变成无序。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md" target="_blank" rel="noopener">百度分布式 ID</a></li><li><a href="https://juejin.im/post/5bb0217ef265da0ac2567b42" target="_blank" rel="noopener">如果再有人问你分布式 ID，这篇文章丢给他</a></li><li><a href="https://segmentfault.com/a/1190000011282426" target="_blank" rel="noopener">理解分布式 id 生成算法 SnowFlake</a></li><li><a href="https://tech.meituan.com/2017/04/21/mt-leaf.html" target="_blank" rel="noopener">Leaf——美团点评分布式 ID 生成系统</a></li><li><a href="https://www.ietf.org/rfc/rfc4122.txt" target="_blank" rel="noopener">UUID 规范</a></li><li><a href="https://shardingsphere.apache.org/document/current/cn/features/sharding/other-features/key-generator/" target="_blank" rel="noopener">ShardingSphere 分布式主键</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分布式-id-基本原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#分布式-id-基本原理&quot;&gt;&lt;/a&gt; 分布式 ID 基本原理&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;📦 本文已归档到：「&lt;a href=&quot;https://gith
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式 ID" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F-ID/"/>
    
  </entry>
  
  <entry>
    <title>消息队列基本原理</title>
    <link href="https://dunwu.github.io/blog/theory/mq/"/>
    <id>https://dunwu.github.io/blog/theory/mq/</id>
    <published>2019-07-05T07:11:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="消息队列基本原理"><a class="markdownIt-Anchor" href="#消息队列基本原理"></a> 消息队列基本原理</h1><blockquote><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p><p>消息队列（Message Queue，简称 MQ）技术是分布式应用间交换信息的一种技术。</p><p>消息队列主要解决应用耦合，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。</p><p>注意：<em>为了简便，下文中除了文章标题，一律使用 MQ 简称</em>。</p></blockquote><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E4%B8%BA%E4%BD%95%E7%94%A8-mq">一、为何用 MQ</a><ul><li><a href="#%E8%A7%A3%E8%80%A6">解耦</a></li><li><a href="#%E5%BC%82%E6%AD%A5">异步</a></li><li><a href="#%E5%89%8A%E5%B3%B0">削峰</a></li></ul></li><li><a href="#%E4%BA%8Cmq-%E7%9A%84%E9%97%AE%E9%A2%98">二、MQ 的问题</a><ul><li><a href="#%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9">重复消费</a></li><li><a href="#%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1">消息丢失</a></li><li><a href="#%E6%B6%88%E6%81%AF%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7">消息的顺序性</a></li><li><a href="#%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B">消息积压</a></li></ul></li><li><a href="#%E4%B8%89mq-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8">三、MQ 的高可用</a><ul><li><a href="#kafka-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8">Kafka 的高可用</a></li></ul></li><li><a href="#mq-%E7%9A%84%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%BC%8F">MQ 的通信模式</a></li><li><a href="#%E5%B8%B8%E7%94%A8-mq-%E5%AF%B9%E6%AF%94">常用 MQ 对比</a></li><li><a href="#jms">JMS</a><ul><li><a href="#%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B">消息模型</a></li><li><a href="#%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9">消息消费</a></li><li><a href="#jms-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B">JMS 编程模型</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-为何用-mq"><a class="markdownIt-Anchor" href="#一-为何用-mq"></a> 一、为何用 MQ</h2><p>MQ 比较核心的优点有 3 个：<strong>解耦</strong>、<strong>异步</strong>、<strong>削峰</strong>。</p><h3 id="解耦"><a class="markdownIt-Anchor" href="#解耦"></a> 解耦</h3><p>不同系统如果要建立通信，传统的做法是：调用接口。</p><p>如果需要和新的系统建立通信或删除已建立的通信，都需要修改代码，这种方案显然耦合度很高。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/theory/mq/mq_1.png" alt="img" /></p><p>如果使用 MQ，系统间的通信只需要通过发布/订阅（Pub/Sub）模型即可，彼此没有直接联系，也就不需要相互感知，从而达到 <strong>解耦</strong>。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/theory/mq/mq_2.png" alt="img" /></p><h3 id="异步"><a class="markdownIt-Anchor" href="#异步"></a> 异步</h3><p>假设这样一个场景，用户向系统 A 发起请求，系统 A 处理计算只需要 10 ms，然后通知系统 BCD 写库，系统 BCD 写库耗时分别为：100ms、200ms、300ms。最终总耗时为： 10+100ms+200ms+300ms=610ms。此外，加上请求和响应的网络传输时间，从用户角度看，可能要等待将近 1s 才能得到结果。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/theory/mq/mq_3.png" alt="img" /></p><p>如果使用 MQ，系统 A 接到请求后，耗时 10ms 处理计算，然后向系统 BCD 连续发送消息，假设耗时 5ms。那么 这一过程的总耗时为 3ms + 5ms = 8ms，这相比于 610 ms，大大缩短了响应时间。至于系统 BCD 的写库操作，只要自行消费 MQ 后处理即可，用户无需关注。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/theory/mq/mq_4.png" alt="img" /></p><h3 id="削峰"><a class="markdownIt-Anchor" href="#削峰"></a> 削峰</h3><p>假设某个系统读写数据库的稳定性能为每秒处理 1000 条数据。平常情况下，远远达不到这么大的处理量。假设，因为因为做活动，系统的瞬时请求量剧增，达到每秒 10000 个并发请求，数据库根本承受不了，可能直接就把数据库给整崩溃了，这样系统服务就不可用了。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/theory/mq/mq_5.png" alt="img" /></p><p>如果使用 MQ，每秒写入 10000 条请求，但是系统 A 每秒只从 MQ 中消费 1000 条请求，然后写入数据库。这样，就不会超过数据库的承受能力，而是把请求积压在 MQ 中。只要高峰期一过，系统 A 就会很快把积压的消息给处理掉。</p><p><img src="http://dunwu.test.upcdn.net/cs/design/theory/mq/mq_6.png" alt="img" /></p><h2 id="二-mq-的问题"><a class="markdownIt-Anchor" href="#二-mq-的问题"></a> 二、MQ 的问题</h2><p>凡事有利有弊，使用 MQ 给系统带来很多好处，也会付出一定的代价。</p><p>它引入了以下问题：</p><ul><li><strong>系统可用性降低</strong> - 引入了 MQ 后，通信需要基于 MQ 完成，如果 MQ 宕机，则服务不可用。因此，MQ 要保证是高可用的，详情参考：<a href="#MQ-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8">MQ 的高可用</a></li><li><strong>系统复杂度提高</strong> - 使用 MQ，需要关注一些新的问题：<ul><li>如何保证消息没有重复消费？</li><li>如何处理消息丢失的问题？</li><li>如何保证消息传递的顺序性？</li><li>如何处理大量消息积压的问题？</li></ul></li><li><strong>一致性问题</strong> - 假设系统 A 处理完直接返回成功的结果给用户，用户认为请求成功。但如果此时，系统 BCD 中只要有任意一个写库失败，那么数据就不一致了。这种情况如何处理？</li></ul><h3 id="重复消费"><a class="markdownIt-Anchor" href="#重复消费"></a> 重复消费</h3><p><strong>如何保证消息不被重复消费</strong> 和 <strong>如何保证消息消费的幂等性</strong> 是同一个问题。</p><p>必须先明确产生重复消费的原因，才能对症下药。</p><h4 id="重复消费问题原因"><a class="markdownIt-Anchor" href="#重复消费问题原因"></a> 重复消费问题原因</h4><p>重复消费问题通常不是 MQ 来处理，而是由开发来处理的。</p><p>以 Kafka 举例：Kafka 每个 Partition 都是一个有序的、不可变的记录序列，不断追加到结构化的提交日志中。Partition 中为每条记录分配一个连续的 id 号，称为偏移量（Offset），用于唯一标识 Partition 内的记录。</p><p><img src="http://kafka.apachecn.org/10/images/log_consumer.png" alt="img" /></p><p>Kafka 的客户端和 Broker 都会保存 Offset。客户端消费消息后，每隔一段时间，就把已消费的 Offset 提交给 Kafka Broker，表示已消费。</p><p>在这个过程中，如果客户端应用消费消息后，因为宕机、重启等情况而没有提交已消费的 Offset 。当系统恢复后，会继续消费消息，由于 Offset 未提交，就会出现重复消费的问题。</p><p><img src="http://upload-images.jianshu.io/upload_images/3101171-75abe308f9cf21f8.png" alt="img" /></p><h4 id="重复消费解决方案"><a class="markdownIt-Anchor" href="#重复消费解决方案"></a> 重复消费解决方案</h4><p>应对重复消费问题，就要通过幂等性来解决。</p><p>这个问题可以从业务层面来解决。</p><p>MQ 重复消费不可怕，可怕的是没有应对机制，可以借鉴的思路有：</p><ul><li>如果是写数据库，可以先根据主键查询，判断数据是否已存在，存在则更新，不存在则插入；</li><li>如果是写 Redis，set 操作，由于天然具有幂等性，大可放心；</li><li>如果是根据消息做较复杂的逻辑处理，可以在消息中加入全局唯一 ID，例如：订单 ID 等。在客户端存储中（Mysql、Redis 等）保存已消费消息的 ID。一旦接受到新消息，先判断消息中的 ID 是否在已消费消息 ID 表中存在，存在则不再处理，不存在则处理。</li></ul><h3 id="消息丢失"><a class="markdownIt-Anchor" href="#消息丢失"></a> 消息丢失</h3><p><strong>如何处理消息丢失的问题</strong> 和 <strong>如何保证消息不被重复消费</strong> 是同一个问题。关注点有：</p><ul><li>Kafka Server 丢失数据</li><li>消费方丢失数据</li><li>生产方丢失数据</li></ul><h4 id="消费方丢失数据"><a class="markdownIt-Anchor" href="#消费方丢失数据"></a> 消费方丢失数据</h4><p>唯一可能导致消费方丢失数据的情况，就是：消费方设置了<strong>自动提交 Offset</strong>。设置了自动提交 Offset，接受到消息后就会自动提交 Offset 给 Kafka ，Kafka 就认为消息已被消费。如果此时，消费方尚未来得及处理消息就挂了，那么消息就丢了。</p><p>解决方法就是：消费方关闭自动提交 Offset，处理完消息后<strong>手动提交 Offset</strong>。但这种情况下可能会出现重复消费的情形，需要自行保证幂等性。</p><h4 id="kafka-丢失数据"><a class="markdownIt-Anchor" href="#kafka-丢失数据"></a> Kafka 丢失数据</h4><p>当 Kafka 某个 Broker 宕机，需要重新选举 Partition 的 Leader。若此时其他的 Follower 尚未同步 Leader 的数据，那么新选某个 Follower 为 Leader 后，就丢失了部分数据。</p><p>为此，一般要求至少设置 4 个参数：</p><ul><li>给 Topic 设置 <code>replication.factor</code> 参数 - 这个值必须大于 1，要求每个 Partition 必须有至少 2 个副本。</li><li>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数 - 这个值必须大于 1，这是要求一个 Leader 需要和至少一个 Follower 保持通信，这样才能确保 Leader 挂了还有替补。</li><li>在 Producer 端设置 <code>acks=all</code> - 这意味着：要求每条数据，必须是<strong>写入所有 replica 之后，才能认为写入成功了</strong>。</li><li>在 Producer 端设置 <code>retries=MAX</code>（很大很大很大的一个值，无限次重试的意思） - 这意味着<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</li></ul><h4 id="生产方丢失数据"><a class="markdownIt-Anchor" href="#生产方丢失数据"></a> 生产方丢失数据</h4><p>如果按照上述的思路设置了 <code>acks=all</code>，生产方一定不会丢数据。</p><p>要求是，你的 Leader 接收到消息，所有的 Follower 都同步到了消息之后，才认为本生产消息成功了。如果未满足这个条件，生产者会自动不断的重试，重试无限次。</p><h3 id="消息的顺序性"><a class="markdownIt-Anchor" href="#消息的顺序性"></a> 消息的顺序性</h3><blockquote><p>以 Kafka 为例</p></blockquote><p>要保证 MQ 的顺序性，势必要付出一定的代价，所以实施方案前，要先明确业务场景是不是有必要保证消息的顺序性。只有那些明确对消息处理顺序有要求的业务场景才值得去保证消息顺序性。</p><p>方案一</p><p>一个 Topic，一个 Partition，一个 Consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。</p><p>方案二</p><ul><li>写入数据到 Partition 时指定一个全局唯一的 ID，例如订单 ID。发送方保证相同 ID 的消息有序的发送到同一个 Partition。</li><li>基于上一点，消费方从 Kafka Partition 中消费消息时，此刻一定是顺序的。但如果消费方式以并发方式消费消息，顺序就可能会被打乱。为此，还有做到以下几点：<ul><li>消费方维护 N 个缓存队列，具有相同 ID 的数据都写入同一个队列中；</li><li>创建 N 个线程，每个线程只负责从指定的一个队列中取数据。</li></ul></li></ul><p><img src="http://dunwu.test.upcdn.net/cs/design/theory/mq/mq_7.png" alt="img" /></p><h3 id="消息积压"><a class="markdownIt-Anchor" href="#消息积压"></a> 消息积压</h3><p>假设一个 MQ 消费者可以一秒处理 1000 条消息，三个 MQ 消费者可以一秒处理 3000 条消息，那么一分钟的处理量是 18 万条。如果 MQ 中积压了几百万到上千万的数据，即使消费者恢复了，也需要大概很长的时间才能恢复过来。</p><p>对于产线环境来说，漫长的等待是不可接受的，所以面临这种窘境时，只能临时紧急扩容以应对了，具体操作步骤和思路如下：</p><ul><li>先修复 Consumer 的问题，确保其恢复消费速度，然后将现有 Consumer 都停掉。</li><li>新建一个 Topic，Partition 是原来的 10 倍，临时建立好原先 10 倍的 Queue 数量。</li><li>然后写一个临时的分发数据的 Consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 Queue。</li><li>接着临时征用 10 倍的机器来部署 Consumer ，每一批 Consumer 消费一个临时 Queue 的数据。这种做法相当于是临时将 Queue 资源和 Consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。</li><li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息。</li></ul><h2 id="三-mq-的高可用"><a class="markdownIt-Anchor" href="#三-mq-的高可用"></a> 三、MQ 的高可用</h2><p>不同 MQ 实现高可用的原理各不相同。因为 Kafka 比较具有代表性，所以这里以 Kafka 为例。</p><h3 id="kafka-的高可用"><a class="markdownIt-Anchor" href="#kafka-的高可用"></a> Kafka 的高可用</h3><h4 id="kafka-的核心概念"><a class="markdownIt-Anchor" href="#kafka-的核心概念"></a> Kafka 的核心概念</h4><p>了解 Kafka，必须先了解 Kafka 的核心概念：</p><ul><li><p><strong>Broker</strong> - Kafka 集群包含一个或多个节点，这种节点被称为 Broker。</p></li><li><p><strong>Topic</strong> - 每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（不同 Topic 的消息是物理隔离的；同一个 Topic 的消息保存在一个或多个 Broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）。对于每一个 Topic， Kafka 集群都会维持一个分区日志。</p></li><li><p><strong>Partition</strong> - 了提高 Kafka 的吞吐率，每个 Topic 包含一个或多个 Partition，每个 Partition 在物理上对应一个文件夹，该文件夹下存储这个 Partition 的所有消息和索引文件。</p><ul><li>Kafka 日志的分区（Partition）分布在 Kafka 集群的节点上。每个节点在处理数据和请求时，共享这些分区。每一个分区都会在已配置的节点上进行备份，确保容错性。</li></ul></li></ul><p><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/distributed/mq/kafka/kafka-cluster-roles.png" alt="img" /></p><h4 id="kafka-的副本机制"><a class="markdownIt-Anchor" href="#kafka-的副本机制"></a> Kafka 的副本机制</h4><p>Kafka 是如何实现高可用的呢？</p><p>Kafka 在 0.8 以前的版本中，如果一个 Broker 宕机了，其上面的 Partition 都不能用了，这自然不是高可用的。</p><p>为了实现高可用，Kafka 引入了复制功能。</p><p>简单来说，就是副本机制（ Replicate ）。</p><p><strong>每个 Partition 都有一个 Leader，零个或多个 Follower</strong>。Leader 和 Follower 都是 Broker，每个 Broker 都会成为某些分区的 Leader 和某些分区的 Follower，因此集群的负载是平衡的。</p><ul><li><strong>Leader 处理一切对 Partition （分区）的读写请求</strong>；</li><li><strong>而 Follower 只需被动的同步 Leader 上的数据</strong>。</li></ul><p><strong>同一个 Topic 的不同 Partition 会分布在多个 Broker 上，而且一个 Partition 还会在其他的 Broker 上面进行备份</strong>，Producer 在发布消息到某个 Partition 时，先找到该 Partition 的 Leader，然后向这个 Leader 推送消息；每个 Follower 都从 Leader 拉取消息，拉取消息成功之后，向 Leader 发送一个 ACK 确认。</p><p><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/distributed/mq/kafka/kafka-replication.png" alt="img" /></p><blockquote><p>FAQ</p><p>问：为什么让 Leader 处理一切对对 Partition （分区）的读写请求？</p><p>答：因为如果允许所有 Broker 都可以处理读写请求，就可能产生数据一致性问题。</p></blockquote><h4 id="kafka-选举-leader"><a class="markdownIt-Anchor" href="#kafka-选举-leader"></a> Kafka 选举 Leader</h4><p>由上文可知，Partition 在多个 Broker 上存在副本。</p><p>如果某个 Follower 宕机，啥事儿没有，正常工作。</p><p>如果 Leader 宕机了，会从 Follower 中<strong>重新选举</strong>一个新的 Leader。</p><h2 id="mq-的通信模式"><a class="markdownIt-Anchor" href="#mq-的通信模式"></a> MQ 的通信模式</h2><p>MQ 可驻留在内存或磁盘上，队列存储消息直到它们被应用程序读取。通过 MQ，应用程序可独立地执行，它们不需要知道彼此的位置，不需要等待接收程序接收此消息。在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。为了管理需要共享的信息，对应用提供公共的信息交换机制是重要的。</p><ul><li><strong>点对点</strong> - 点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。</li><li><strong>多点广播</strong> - MQ 适用于不同类型的应用。其中重要的，也是正在发展中的是&quot;多点广播&quot;应用，即能够将消息发送到多个目标站点 (Destination List)。可以使用一条 MQ 指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ 不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ 将消息的一个复制版本和该系统上接收者的名单发送到目标 MQ 系统。目标 MQ 系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。</li><li><strong>发布/订阅 (Publish/Subscribe)</strong> - 发布/订阅模式使消息的分发可以突破目的队列地理位置的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅模式使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。</li><li><strong>集群 (Cluster)</strong> - 为了简化点对点通讯模式中的系统配置，MQ 提供 Cluster(集群) 的解决方案。集群类似于一个域 (Domain)，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用集群 (Cluster) 通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性。</li></ul><h2 id="常用-mq-对比"><a class="markdownIt-Anchor" href="#常用-mq-对比"></a> 常用 MQ 对比</h2><table><thead><tr><th>特性</th><th>ActiveMQ</th><th>RabbitMQ</th><th>RocketMQ</th><th>Kafka</th></tr></thead><tbody><tr><td>单机吞吐量</td><td>万级，比 RocketMQ、Kafka 低一个数量级</td><td>同 ActiveMQ</td><td>10 万级，支撑高吞吐</td><td>10 万级，高吞吐，一般配合大数据类的系统来进行流式计算、日志采集等场景</td></tr><tr><td>topic 数量对吞吐量的影响</td><td></td><td></td><td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td><td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td></tr><tr><td>时效性</td><td>ms 级</td><td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td><td>ms 级</td><td>延迟在 ms 级以内</td></tr><tr><td>可用性</td><td>高，基于主从架构实现高可用</td><td>同 ActiveMQ</td><td>非常高，分布式架构</td><td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td></tr><tr><td>消息可靠性</td><td>有较低的概率丢失数据</td><td>基本不丢</td><td>经过参数优化配置，可以做到 0 丢失</td><td>同 RocketMQ</td></tr><tr><td>功能支持</td><td>MQ 领域的功能极其完备</td><td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td><td>MQ 功能较为完善，还是分布式的，扩展性好</td><td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td></tr></tbody></table><p>综上，各种对比之后，有如下建议：</p><ul><li>一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；</li><li>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；</li><li>不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 <a href="https://github.com/apache/rocketmq" target="_blank" rel="noopener">Apache</a>，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。</li><li>所以<strong>中小型公司</strong>，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；<strong>大型公司</strong>，基础架构研发实力较强，用 RocketMQ 是很好的选择。</li><li>如果是<strong>大数据领域</strong>的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</li></ul><h2 id="jms"><a class="markdownIt-Anchor" href="#jms"></a> JMS</h2><p>谈 MQ 就不得不提一下 JMS 。</p><p><strong>JMS（JAVA Message Service，java 消息服务）API 是一个消息服务的标准/规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息</strong>。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。</p><p>在 EJB 架构中，有消息 bean 可以无缝的与 JM 消息服务集成。在 J2EE 架构模式中，有消息服务者模式，用于实现消息与应用直接的解耦。</p><h3 id="消息模型"><a class="markdownIt-Anchor" href="#消息模型"></a> 消息模型</h3><p>在 JMS 标准中，有两种消息模型：</p><ul><li>P2P(Point to Point)</li><li>Pub/Sub(Publish/Subscribe)</li></ul><h4 id="p2p-模式"><a class="markdownIt-Anchor" href="#p2p-模式"></a> P2P 模式</h4><div align="center"><img src="http://upload-images.jianshu.io/upload_images/3101171-2adc66e2367cd2c2.png"/></div>P2P 模式包含三个角色：MQ（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。<p>P2P 的特点</p><ul><li>每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在 MQ 中)</li><li>发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列</li><li>接收者在成功接收消息之后需向队列应答成功</li></ul><p>如果希望发送的每个消息都会被成功处理的话，那么需要 P2P 模式。</p><h4 id="pubsub-模式"><a class="markdownIt-Anchor" href="#pubsub-模式"></a> Pub/sub 模式</h4><div align="center"><img src="http://upload-images.jianshu.io/upload_images/3101171-12afe9581da889ea.png"/></div>包含三个角色主题（Topic），发布者（Publisher），订阅者（Subscriber） 。多个发布者将消息发送到 Topic,系统将这些消息传递给多个订阅者。<p>Pub/Sub 的特点</p><ul><li>每个消息可以有多个消费者</li><li>发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。</li><li>为了消费消息，订阅者必须保持运行的状态。</li></ul><p>为了缓和这样严格的时间相关性，JMS 允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。</p><p>如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用 Pub/Sub 模型。</p><h3 id="消息消费"><a class="markdownIt-Anchor" href="#消息消费"></a> 消息消费</h3><p>在 JMS 中，消息的产生和消费都是异步的。对于消费来说，JMS 的消息者可以通过两种方式来消费消息。</p><ul><li><strong>同步</strong> - 订阅者或接收者通过 <code>receive</code> 方法来接收消息，<code>receive</code> 方法在接收到消息之前（或超时之前）将一直阻塞；</li><li><strong>异步</strong> - 订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的 <code>onMessage</code> 方法。</li></ul><p><code>JNDI</code> - Java 命名和目录接口,是一种标准的 Java 命名系统接口。可以在网络上查找和访问服务。通过指定一个资源名称，该名称对应于数据库或命名服务中的一个记录，同时返回资源连接建立所必须的信息。</p><p>JNDI 在 JMS 中起到查找和访问发送目标或消息来源的作用。</p><h3 id="jms-编程模型"><a class="markdownIt-Anchor" href="#jms-编程模型"></a> JMS 编程模型</h3><h4 id="connectionfactory"><a class="markdownIt-Anchor" href="#connectionfactory"></a> ConnectionFactory</h4><p>创建 Connection 对象的工厂，针对两种不同的 jms 消息模型，分别有 QueueConnectionFactory 和 TopicConnectionFactory 两种。可以通过 JNDI 来查找 ConnectionFactory 对象。</p><h4 id="destination"><a class="markdownIt-Anchor" href="#destination"></a> Destination</h4><p>Destination 的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的 Destination 是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的 Destination 也是某个队列或主题（即消息来源）。</p><p>所以，Destination 实际上就是两种类型的对象：Queue、Topic。可以通过 JNDI 来查找 Destination。</p><h4 id="3-connection"><a class="markdownIt-Anchor" href="#3-connection"></a> (3) Connection</h4><p>Connection 表示在客户端和 JMS 系统之间建立的链接（对 TCP/IP socket 的包装）。Connection 可以产生一个或多个 Session。跟 ConnectionFactory 一样，Connection 也有两种类型：QueueConnection 和 TopicConnection。</p><h4 id="4-session"><a class="markdownIt-Anchor" href="#4-session"></a> (4) Session</h4><p>Session 是操作消息的接口。可以通过 session 创建生产者、消费者、消息等。Session 提供了事务的功能。当需要使用 session 发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分 QueueSession 和 TopicSession。</p><h4 id="消息的生产者"><a class="markdownIt-Anchor" href="#消息的生产者"></a> 消息的生产者</h4><p>消息生产者由 Session 创建，并用于将消息发送到 Destination。同样，消息生产者分两种类型：QueueSender 和 TopicPublisher。可以调用消息生产者的方法（send 或 publish 方法）发送消息。</p><h4 id="消息消费者"><a class="markdownIt-Anchor" href="#消息消费者"></a> 消息消费者</h4><p>消息消费者由 Session 创建，用于接收被发送到 Destination 的消息。两种类型：QueueReceiver 和 TopicSubscriber。可分别通过 session 的 createReceiver(Queue)或 createSubscriber(Topic)来创建。当然，也可以 session 的 creatDurableSubscriber 方法来创建持久化的订阅者。</p><h4 id="messagelistener"><a class="markdownIt-Anchor" href="#messagelistener"></a> MessageListener</h4><p>消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的 onMessage 方法。EJB 中的 MDB（Message-Driven Bean）就是一种 MessageListener。</p><p>深入学习 JMS 对掌握 JAVA 架构，EJB 架构有很好的帮助，消息中间件也是大型分布式系统必须的组件。本次分享主要做全局性介绍，具体的深入需要大家学习，实践，总结，领会。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://www.cnblogs.com/itfly8/p/5155983.html" target="_blank" rel="noopener">大型网站架构系列：分布式 MQ（一）</a></li><li><a href="https://www.cnblogs.com/itfly8/p/5156155.html" target="_blank" rel="noopener">大型网站架构系列：MQ（二）</a></li><li><a href="https://www.jianshu.com/p/453c6e7ff81c" target="_blank" rel="noopener">分布式开放 MQ(RocketMQ)的原理与实践</a></li><li><a href="https://juejin.im/entry/5a0abfb5f265da43062a4a91" target="_blank" rel="noopener">阿里 RocketMQ 优势对比</a></li><li><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/mq-interview.md" target="_blank" rel="noopener">advanced-java 之 MQ</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;消息队列基本原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#消息队列基本原理&quot;&gt;&lt;/a&gt; 消息队列基本原理&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;📦 本文已归档到：「&lt;a href=&quot;https://github.com/du
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="消息队列" scheme="https://dunwu.github.io/blog/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>缓存基本原理</title>
    <link href="https://dunwu.github.io/blog/theory/cache/"/>
    <id>https://dunwu.github.io/blog/theory/cache/</id>
    <published>2019-06-27T07:36:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缓存基本原理"><a class="markdownIt-Anchor" href="#缓存基本原理"></a> 缓存基本原理</h1><blockquote><p>缓存是一种利用空间换时间的设计，其目标就是<strong>更快</strong>、<strong>更近</strong>。</p><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p></blockquote><p><img src="http://dunwu.test.upcdn.net/snap/20200710163555.png" alt="img" /></p><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E7%BC%93%E5%AD%98%E7%AE%80%E4%BB%8B">一、缓存简介</a><ul><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%BC%93%E5%AD%98">什么是缓存</a></li><li><a href="#%E4%BD%95%E6%97%B6%E9%9C%80%E8%A6%81%E7%BC%93%E5%AD%98">何时需要缓存</a></li><li><a href="#%E7%BC%93%E5%AD%98%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86">缓存的基本原理</a></li><li><a href="#%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5">缓存淘汰策略</a></li><li><a href="#jsr-107">JSR 107</a></li></ul></li><li><a href="#%E4%BA%8C%E7%BC%93%E5%AD%98%E7%9A%84%E5%88%86%E7%B1%BB">二、缓存的分类</a><ul><li><a href="#http-%E7%BC%93%E5%AD%98">HTTP 缓存</a></li><li><a href="#cdn-%E7%BC%93%E5%AD%98">CDN 缓存</a></li><li><a href="#%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%BC%93%E5%AD%98">反向代理缓存</a></li></ul></li><li><a href="#%E4%B8%89%E8%BF%9B%E7%A8%8B%E5%86%85%E7%BC%93%E5%AD%98">三、进程内缓存</a><ul><li><a href="#concurrenthashmap">ConcurrentHashMap</a></li><li><a href="#lruhashmap">LRUHashMap</a></li><li><a href="#guava-cache">Guava Cache</a></li><li><a href="#caffeine">Caffeine</a></li><li><a href="#ehcache">Ehcache</a></li><li><a href="#%E8%BF%9B%E7%A8%8B%E5%86%85%E7%BC%93%E5%AD%98%E5%AF%B9%E6%AF%94">进程内缓存对比</a></li></ul></li><li><a href="#%E5%9B%9B%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98">四、分布式缓存</a><ul><li><a href="#memcached">Memcached</a></li><li><a href="#redis">Redis</a></li><li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E5%AF%B9%E6%AF%94">分布式缓存对比</a></li></ul></li><li><a href="#%E4%BA%94%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98">五、多级缓存</a><ul><li><a href="#%E6%95%B4%E4%BD%93%E7%BC%93%E5%AD%98%E6%A1%86%E6%9E%B6">整体缓存框架</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E8%BF%9B%E7%A8%8B%E5%86%85%E7%BC%93%E5%AD%98">使用进程内缓存</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98">使用分布式缓存</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98">使用多级缓存</a></li></ul></li><li><a href="#%E5%85%AD%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98">六、缓存问题</a><ul><li><a href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9">缓存雪崩</a></li><li><a href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F">缓存穿透</a></li><li><a href="#%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF">缓存击穿</a></li><li><a href="#%E5%B0%8F%E7%BB%93">小结</a></li></ul></li><li><a href="#%E4%B8%83%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5">七、缓存策略</a><ul><li><a href="#%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD">缓存预热</a></li><li><a href="#%E5%A6%82%E4%BD%95%E7%BC%93%E5%AD%98">如何缓存</a></li><li><a href="#%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0">缓存更新</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-缓存简介"><a class="markdownIt-Anchor" href="#一-缓存简介"></a> 一、缓存简介</h2><h3 id="什么是缓存"><a class="markdownIt-Anchor" href="#什么是缓存"></a> 什么是缓存</h3><p><strong>缓存就是数据交换的缓冲区</strong>。<strong>缓存的本质是一个内存 Hash</strong>。</p><p>缓存是一种利用空间换时间的设计，其目标就是<strong>更快</strong>、<strong>更近</strong>：</p><ul><li>将数据写入/读取速度<strong>更快</strong>的存储（设备）；</li><li>将数据缓存到离应用<strong>最近</strong>的位置；</li><li>将数据缓存到离<strong>用户</strong>最近的位置。</li></ul><p>缓存是用于存储数据的硬件或软件的组成部分，以使得后续更快访问相应的数据。缓存中的数据可能是提前计算好的结果、数据的副本等。典型的应用场景：有 cpu cache, 磁盘 cache 等。本文中提及到缓存主要是指互联网应用中所使用的缓存组件。</p><p><strong>缓存命中率</strong>是缓存的重要度量指标，命中率越高越好。</p><figure class="highlight fix"><table><tr><td class="code"><pre><span class="line"><span class="attr">缓存命中率 </span>=<span class="string"> 从缓存中读取次数 / 总读取次数</span></span><br></pre></td></tr></table></figure><h3 id="何时需要缓存"><a class="markdownIt-Anchor" href="#何时需要缓存"></a> 何时需要缓存</h3><p>引入缓存，会增加系统的复杂度。所以，引入缓存前，需要先权衡是否值得，考量点如下：</p><ul><li><strong>CPU 开销</strong> - 如果应用某个计算需要消耗大量 CPU，可以考虑缓存其计算结果。典型场景：复杂的、频繁调用的正则计算；分布式计算中间状态等。</li><li><strong>IO 开销</strong> - 如果数据库连接池比较繁忙，可以考虑缓存其查询结果。</li></ul><p>在数据层引入缓存，有以下几个好处：</p><ul><li>提升数据读取速度。</li><li>提升系统扩展能力，通过扩展缓存，提升系统承载能力。</li><li>降低存储成本，Cache+DB 的方式可以承担原有需要多台 DB 才能承担的请求量，节省机器成本。</li></ul><h3 id="缓存的基本原理"><a class="markdownIt-Anchor" href="#缓存的基本原理"></a> 缓存的基本原理</h3><p>根据业务场景，通常缓存有以下几种使用方式：</p><ul><li>懒汉式(读时触发)：写入 DB 后, 然后把相关的数据也写入 Cache。</li><li>饥饿式(写时触发)：先查询 DB 里的数据, 然后把相关的数据写入 Cache。</li><li>定期刷新：适合周期性的跑数据的任务，或者列表型的数据，而且不要求绝对实时性。</li></ul><h3 id="缓存淘汰策略"><a class="markdownIt-Anchor" href="#缓存淘汰策略"></a> 缓存淘汰策略</h3><p>缓存淘汰的类型：</p><ul><li><strong>基于空间</strong> - 设置缓存空间大小。</li><li><strong>基于容量</strong> - 设置缓存存储记录数。</li><li><strong>基于时间</strong><ul><li>TTL（Time To Live，即存活期）缓存数据从创建到过期的时间。</li><li>TTI（Time To Idle，即空闲期）缓存数据多久没被访问的时间。</li></ul></li></ul><p>缓存淘汰算法：</p><ul><li><strong>FIFO</strong> - <strong>先进先出</strong>。在这种淘汰算法中，先进入缓存的会先被淘汰。这种可谓是最简单的了，但是会导致我们命中率很低。试想一下我们如果有个访问频率很高的数据是所有数据第一个访问的，而那些不是很高的是后面再访问的，那这样就会把我们的首个数据但是他的访问频率很高给挤出。</li><li><strong>LRU</strong> - <strong>最近最少使用算法</strong>。在这种算法中避免了上面的问题，每次访问数据都会将其放在我们的队尾，如果需要淘汰数据，就只需要淘汰队首即可。但是这个依然有个问题，如果有个数据在 1 个小时的前 59 分钟访问了 1 万次(可见这是个热点数据),再后一分钟没有访问这个数据，但是有其他的数据访问，就导致了我们这个热点数据被淘汰。</li><li><strong>LFU</strong> - <strong>最近最少频率使用</strong>。在这种算法中又对上面进行了优化，利用额外的空间记录每个数据的使用频率，然后选出频率最低进行淘汰。这样就避免了 LRU 不能处理时间段的问题。</li></ul><p>这三种缓存淘汰算法，实现复杂度一个比一个高，同样的命中率也是一个比一个好。而我们一般来说选择的方案居中即可，即实现成本不是太高，而命中率也还行的 LRU。</p><h2 id="二-缓存的分类"><a class="markdownIt-Anchor" href="#二-缓存的分类"></a> 二、缓存的分类</h2><p>缓存从部署角度，可以分为客户端缓存和服务端缓存。</p><p><strong>客户端缓存</strong></p><ul><li><strong>HTTP 缓存</strong></li><li><strong>浏览器缓存</strong></li><li><strong>APP 缓存</strong><ul><li>Android</li><li>IOS</li></ul></li></ul><p><strong>服务端缓存</strong></p><ul><li><strong>CDN 缓存</strong> - 存放 HTML、CSS、JS 等静态资源。</li><li><strong>反向代理缓存</strong> - 动静分离，只缓存用户请求的静态资源。</li><li><strong>数据库缓存</strong> - 数据库（如 Mysql）自身一般也有缓存，但因为命中率和更新频率问题，不推荐使用。</li><li><strong>进程内缓存</strong> - 缓存应用字典等常用数据。</li><li><strong>分布式缓存</strong> - 缓存数据库中的热点数据。</li></ul><blockquote><p>其中，CDN 缓存、反向代理缓存、数据库缓存一般由专职人员维护（运维、DBA）。</p><p>后端开发一般聚焦于进程内缓存、分布式缓存。</p></blockquote><h3 id="http-缓存"><a class="markdownIt-Anchor" href="#http-缓存"></a> HTTP 缓存</h3><h3 id="cdn-缓存"><a class="markdownIt-Anchor" href="#cdn-缓存"></a> CDN 缓存</h3><blockquote><p><strong>CDN 将数据缓存到离用户物理距离最近的服务器，使得用户可以就近获取请求内容。CDN 一般缓存静态资源文件（页面，脚本，图片，视频，文件等）</strong>。</p><p>国内网络异常复杂，跨运营商的网络访问会很慢。为了解决跨运营商或各地用户访问问题，可以在重要的城市，部署 CDN 应用。使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。</p></blockquote><div align="center"><img src="http://dunwu.test.upcdn.net/snap/1559138689425.png"/></div><h4 id="cdn-原理"><a class="markdownIt-Anchor" href="#cdn-原理"></a> CDN 原理</h4><p>CDN 的基本原理是广泛采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区或网络中，在用户访问网站时，利用全局负载技术将用户的访问指向距离最近的工作正常的缓存服务器上，由缓存服务器直接响应用户请求。</p><p>（1）未部署 CDN 应用前的网络路径：</p><ul><li>请求：本机网络（局域网）=&gt; 运营商网络 =&gt; 应用服务器机房</li><li>响应：应用服务器机房 =&gt; 运营商网络 =&gt; 本机网络（局域网）</li></ul><p>在不考虑复杂网络的情况下，从请求到响应需要经过 3 个节点，6 个步骤完成一次用户访问操作。</p><p>（2）部署 CDN 应用后网络路径：</p><ul><li>请求：本机网络（局域网） =&gt; 运营商网络</li><li>响应：运营商网络 =&gt; 本机网络（局域网）</li></ul><p>在不考虑复杂网络的情况下，从请求到响应需要经过 2 个节点，2 个步骤完成一次用户访问操作。</p><p>与不部署 CDN 服务相比，减少了 1 个节点，4 个步骤的访问。极大的提高的系统的响应速度。</p><h4 id="cdn-特点"><a class="markdownIt-Anchor" href="#cdn-特点"></a> CDN 特点</h4><p><strong>优点</strong></p><ul><li><strong>本地 Cache 加速</strong> - 提升访问速度，尤其含有大量图片和静态页面站点；</li><li><strong>实现跨运营商的网络加速</strong> - 消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量；</li><li><strong>远程加速</strong> - 远程访问用户根据 DNS 负载均衡技术智能自动选择 Cache 服务器，选择最快的 Cache 服务器，加快远程访问的速度；</li><li><strong>带宽优化</strong> - 自动生成服务器的远程 Mirror（镜像）cache 服务器，远程用户访问时从 cache 服务器上读取数据，减少远程访问的带宽、分担网络流量、减轻原站点 WEB 服务器负载等功能。</li><li><strong>集群抗攻击</strong> - 广泛分布的 CDN 节点加上节点之间的智能冗余机制，可以有效地预防黑客入侵以及降低各种 D.D.o.S 攻击对网站的影响，同时保证较好的服务质量。</li></ul><p><strong>缺点</strong></p><ul><li><strong>不适宜缓存动态资源</strong><ul><li>解决方案：主要缓存静态资源，动态资源建立多级缓存或准实时同步；</li></ul></li><li><strong>存在数据的一致性问题</strong><ul><li>解决方案（主要是在性能和数据一致性二者间寻找一个平衡）</li><li>设置缓存失效时间（1 个小时，过期后同步数据）。</li><li>针对资源设置版本号。</li></ul></li></ul><h3 id="反向代理缓存"><a class="markdownIt-Anchor" href="#反向代理缓存"></a> 反向代理缓存</h3><blockquote><p><strong>反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。</strong></p></blockquote><div align="center"><img src="http://dunwu.test.upcdn.net/cs/web/nginx/reverse-proxy.png"/></div><h4 id="反向代理缓存原理"><a class="markdownIt-Anchor" href="#反向代理缓存原理"></a> 反向代理缓存原理</h4><p>反向代理位于应用服务器同一网络，处理所有对 WEB 服务器的请求。</p><p>反向代理缓存的原理：</p><ul><li>如果用户请求的页面在代理服务器上有缓存的话，代理服务器直接将缓存内容发送给用户。</li><li>如果没有缓存则先向 WEB 服务器发出请求，取回数据，本地缓存后再发送给用户。</li></ul><p>这种方式通过降低向 WEB 服务器的请求数，从而降低了 WEB 服务器的负载。</p><p><strong>反向代理缓存一般针对的是静态资源，而将动态资源请求转发到应用服务器处理</strong>。常用的缓存应用服务器有 Varnish，Ngnix，Squid。</p><h4 id="反向代理缓存比较"><a class="markdownIt-Anchor" href="#反向代理缓存比较"></a> 反向代理缓存比较</h4><p>常用的代理缓存有 Varnish，Squid，Ngnix，简单比较如下：</p><ul><li>Varnish 和 Squid 是专业的 cache 服务，Ngnix 需要第三方模块支持；</li><li>Varnish 采用内存型缓存，避免了频繁在内存、磁盘中交换文件，性能比 Squid 高；</li><li>Varnish 由于是内存 cache，所以对小文件如 css、js、小图片的支持很棒，后端的持久化缓存可以采用的是 Squid 或 ATS；</li><li>Squid 功能全而大，适合于各种静态的文件缓存，一般会在前端挂一个 HAProxy 或 Ngnix 做负载均衡跑多个实例；</li><li>Nginx 采用第三方模块 ncache 做的缓冲，性能基本达到 Varnish，一般作为反向代理使用，可以实现简单的缓存。</li></ul><h2 id="三-进程内缓存"><a class="markdownIt-Anchor" href="#三-进程内缓存"></a> 三、进程内缓存</h2><blockquote><p>进程内缓存是指应用内部的缓存，标准的分布式系统，一般有多级缓存构成。本地缓存是离应用最近的缓存，一般可以将数据缓存到硬盘或内存。</p></blockquote><ul><li><code>硬盘缓存</code> - 将数据缓存到硬盘到，读取时从硬盘读取。原理是直接读取本机文件，减少了网络传输消耗，比通过网络读取数据库速度更快。可以应用在对速度要求不是很高，但需要大量缓存存储的场景。</li><li><code>内存缓存</code> - 直接将数据存储到本机内存中，通过程序直接维护缓存对象，是访问速度最快的方式。</li></ul><p>常见的本地缓存实现方案：HashMap、Guava Cache、Caffeine、Ehcache。</p><h3 id="concurrenthashmap"><a class="markdownIt-Anchor" href="#concurrenthashmap"></a> ConcurrentHashMap</h3><p>最简单的进程内缓存可以通过 JDK 自带的 <code>HashMap</code> 或 <code>ConcurrentHashMap</code> 实现。</p><p>适用场景：<strong>不需要淘汰的缓存数据</strong>。</p><p>缺点：无法进行缓存淘汰，内存会无限制的增长。</p><h3 id="lruhashmap"><a class="markdownIt-Anchor" href="#lruhashmap"></a> LRUHashMap</h3><p>可以通过<strong>继承 <code>LinkedHashMap</code> 来实现一个简单的 <code>LRUHashMap</code></strong>。重写 <code>removeEldestEntry</code> 方法，即可完成一个简单的最近最少使用算法。</p><p>缺点：</p><ul><li>锁竞争严重，性能比较低。</li><li>不支持过期时间</li><li>不支持自动刷新</li></ul><h3 id="guava-cache"><a class="markdownIt-Anchor" href="#guava-cache"></a> Guava Cache</h3><p>解决了 <code>LRUHashMap</code> 中的几个缺点。</p><p>Guava Cache 采用了类似 <code>ConcurrentHashMap</code> 的思想，分段加锁，减少锁竞争。</p><p>Guava Cache 对于过期的 Entry 并没有马上过期(也就是并没有后台线程一直在扫)，而是通过进行读写操作的时候进行过期处理，这样做的好处是避免后台线程扫描的时候进行全局加锁。</p><p>直接通过查询，判断其是否满足刷新条件，进行刷新。</p><h3 id="caffeine"><a class="markdownIt-Anchor" href="#caffeine"></a> Caffeine</h3><p>Caffeine 实现了 W-TinyLFU(<strong>LFU</strong> + <strong>LRU</strong> 算法的变种)，其<strong>命中率和读写吞吐量大大优于 Guava Cache</strong>。</p><p>其实现原理较复杂，可以参考<a href="https://juejin.im/post/5b7593496fb9a009b62904fa#comment" target="_blank" rel="noopener">你应该知道的缓存进化史</a>。</p><h3 id="ehcache"><a class="markdownIt-Anchor" href="#ehcache"></a> Ehcache</h3><p>EhCache 是一个纯 Java 的进程内缓存框架，具有快速、精干等特点，是 Hibernate 中默认的 CacheProvider。</p><p>优点</p><ul><li>快速、简单</li><li>支持多种缓存策略：LRU、LFU、FIFO 淘汰算法</li><li>缓存数据有两级：内存和磁盘，因此无需担心容量问题</li><li>缓存数据会在虚拟机重启的过程中写入磁盘</li><li>可以通过 RMI、可插入 API 等方式进行分布式缓存</li><li>具有缓存和缓存管理器的侦听接口</li><li>支持多缓存管理器实例，以及一个实例的多个缓存区域</li><li>提供 Hibernate 的缓存实现</li></ul><p>缺点</p><ul><li><strong>使用磁盘 Cache 的时候非常占用磁盘空间</strong></li><li><strong>不保证数据的安全</strong></li><li>虽然支持分布式缓存，但效率不高（通过组播方式，在不同节点之间同步数据）。</li></ul><h3 id="进程内缓存对比"><a class="markdownIt-Anchor" href="#进程内缓存对比"></a> 进程内缓存对比</h3><p>常用进程内缓存技术对比：</p><table><thead><tr><th>比较项</th><th>ConcurrentHashMap</th><th>LRUMap</th><th>Ehcache</th><th>Guava Cache</th><th>Caffeine</th></tr></thead><tbody><tr><td>读写性能</td><td>很好，分段锁</td><td>一般，全局加锁</td><td>好</td><td>好，需要做淘汰操作</td><td>很好</td></tr><tr><td>淘汰算法</td><td>无</td><td>LRU，一般</td><td>支持多种淘汰算法,LRU,LFU,FIFO</td><td>LRU，一般</td><td>W-TinyLFU, 很好</td></tr><tr><td>功能丰富程度</td><td>功能比较简单</td><td>功能比较单一</td><td>功能很丰富</td><td>功能很丰富，支持刷新和虚引用等</td><td>功能和 Guava Cache 类似</td></tr><tr><td>工具大小</td><td>jdk 自带类，很小</td><td>基于 LinkedHashMap，较小</td><td>很大，最新版本 1.4MB</td><td>是 Guava 工具类中的一个小部分，较小</td><td>一般，最新版本 644KB</td></tr><tr><td>是否持久化</td><td>否</td><td>否</td><td>是</td><td>否</td><td>否</td></tr><tr><td>是否支持集群</td><td>否</td><td>否</td><td>是</td><td>否</td><td>否</td></tr></tbody></table><ul><li><strong><code>ConcurrentHashMap</code></strong> - 比较适合缓存比较固定不变的元素，且缓存的数量较小的。虽然从上面表格中比起来有点逊色，但是其由于是 JDK 自带的类，在各种框架中依然有大量的使用，比如我们可以用来缓存我们反射的 Method，Field 等等；也可以缓存一些链接，防止其重复建立。在 Caffeine 中也是使用的 <code>ConcurrentHashMap</code> 来存储元素。</li><li><strong><code>LRUMap</code></strong> - 如果不想引入第三方包，又想使用淘汰算法淘汰数据，可以使用这个。</li><li><strong><code>Ehcache</code></strong> - 由于其 jar 包很大，较重量级。对于需要持久化和集群的一些功能的，可以选择 Ehcache。需要注意的是，虽然 Ehcache 也支持分布式缓存，但是由于其节点间通信方式为 rmi，表现不如 Redis，所以一般不建议用它来作为分布式缓存。</li><li><strong><code>Guava Cache</code></strong> - Guava 这个 jar 包在很多 Java 应用程序中都有大量的引入，所以很多时候其实是直接用就好了，并且其本身是轻量级的而且功能较为丰富，在不了解 Caffeine 的情况下可以选择 Guava Cache。</li><li><strong><code>Caffeine</code></strong> - 其在命中率，读写性能上都比 Guava Cache 好很多，并且其 API 和 Guava cache 基本一致，甚至会多一点。在真实环境中使用 Caffeine，取得过不错的效果。</li></ul><p>总结一下：<strong>如果不需要淘汰算法则选择 <code>ConcurrentHashMap</code>，如果需要淘汰算法和一些丰富的 API，推荐选择 <code>Caffeine</code></strong>。</p><h2 id="四-分布式缓存"><a class="markdownIt-Anchor" href="#四-分布式缓存"></a> 四、分布式缓存</h2><blockquote><p><strong>分布式缓存解决了进程内缓存最大的问题：如果应用是分布式系统，节点之间无法共享彼此的进程内缓存</strong>。</p><p>分布式缓存的应用场景：</p><ul><li>缓存经过复杂计算得到的数据</li><li>缓存系统中频繁访问的热点数据，减轻数据库压力</li></ul></blockquote><p>不同分布式缓存的实现原理往往有比较大的差异。本文主要针对 Memcached 和 Redis 进行说明。</p><h3 id="memcached"><a class="markdownIt-Anchor" href="#memcached"></a> Memcached</h3><blockquote><p><a href="https://memcached.org/" target="_blank" rel="noopener">Memcached</a> 是一个高性能，分布式内存对象缓存系统，通过在内存里维护一个统一的巨大的 hash 表，它能够用来存储各种格式的数据，包括图像、视频、文件以及数据库检索的结果等。</p><p>简单的说就是：将数据缓存到内存中，然后从内存中读取，从而大大提高读取速度。</p></blockquote><h4 id="memcached-特性"><a class="markdownIt-Anchor" href="#memcached-特性"></a> Memcached 特性</h4><ul><li><strong>使用物理内存作为缓存区，可独立运行在服务器上</strong>。每个进程最大 2G，如果想缓存更多的数据，可以开辟更多的 Memcached 进程（不同端口）或者使用分布式 Memcached 进行缓存，将数据缓存到不同的物理机或者虚拟机上。</li><li><strong>使用 key-value 的方式来存储数据</strong>。这是一种单索引的结构化数据组织形式，可使数据项查询时间复杂度为 O(1)。</li><li><strong>协议简单，基于文本行的协议</strong>。直接通过 telnet 在 Memcached 服务器上可进行存取数据操作，简单，方便多种缓存参考此协议；</li><li><strong>基于 libevent 高性能通信</strong>。Libevent 是一套利用 C 开发的程序库，它将 BSD 系统的 kqueue,Linux 系统的 epoll 等事件处理功能封装成一个接口，与传统的 select 相比，提高了性能。</li><li><strong>分布式能力取决于 Memcached 客户端，服务器之间互不通信</strong>。各个 Memcached 服务器之间互不通信，各自独立存取数据，不共享任何信息。服务器并不具有分布式功能，分布式部署取决于 Memcached 客户端。</li><li><strong>采用 LRU 缓存淘汰策略</strong>。在 Memcached 内存储数据项时，可以指定它在缓存的失效时间，默认为永久。当 Memcached 服务器用完分配的内时，失效的数据被首先替换，然后也是最近未使用的数据。在 LRU 中，Memcached 使用的是一种 Lazy Expiration 策略，自己不会监控存入的 key/vlue 对是否过期，而是在获取 key 值时查看记录的时间戳，检查 key/value 对空间是否过期，这样可减轻服务器的负载。</li><li><strong>内置了一套高效的内存管理算法</strong>。这套内存管理效率很高，而且不会造成内存碎片，但是它最大的缺点就是会导致空间浪费。当内存满后，通过 LRU 算法自动删除不使用的缓存。</li><li><strong>不支持持久化</strong>。Memcached 没有考虑数据的容灾问题，重启服务，所有数据会丢失。</li></ul><h4 id="memcached-工作原理"><a class="markdownIt-Anchor" href="#memcached-工作原理"></a> Memcached 工作原理</h4><p>（1）内存管理</p><p>Memcached 利用 <strong>slab allocation</strong> 机制来分配和管理内存，它按照预先规定的大小，将分配的内存分割成特定长度的内存块，再把尺寸相同的内存块分成组，数据在存放时，根据键值 大小去匹配 slab 大小，找就近的 slab 存放，所以存在空间浪费现象。</p><p>这套内存管理效率很高，而且不会造成内存碎片，但是它最大的缺点就是会导致空间浪费。</p><p>（2）缓存淘汰策略</p><p>Memcached 的缓存淘汰策略是 <strong>LRU</strong> + 到期失效策略。</p><p>当你在 Memcached 内存储数据项时，你有可能会指定它在缓存的失效时间，默认为永久。当 Memcached 服务器用完分配的内时，失效的数据被首先替换，然后是最近未使用的数据。</p><p>在 LRU 中，Memcached 使用的是一种 Lazy Expiration 策略：<strong>Memcached 不会监控存入的 key/vlue 对是否过期</strong>，而是在获取 key 值时查看记录的时间戳，<strong>检查 key/value 对空间是否过期</strong>，这样可减轻服务器的负载。</p><p>（3）分区</p><p>Memcached 服务器之间彼此不通信，它的分布式能力是依赖客户端来实现。</p><p>具体来说，就是在客户端实现一种算法，根据 key 来计算出数据应该向哪个服务器节点读/写。</p><p>而这种选取集群节点的算法常见的有三种：</p><ul><li><strong>哈希取余算法</strong> - 使用公式：<code>hash（key）% N</code> 计算出 <strong>哈希值</strong> 来决定数据映射到哪一个节点。</li><li><strong>一致性哈希算法</strong> - 可以很好的解决 <strong>稳定性问题</strong>，可以将所有的 <strong>存储节点</strong> 排列在 <strong>首尾相接</strong> 的 <code>Hash</code> 环上，每个 <code>key</code> 在计算 <code>Hash</code> 后会 <strong>顺时针</strong> 找到 <strong>临接</strong> 的 <strong>存储节点</strong> 存放。而当有节点 <strong>加入</strong> 或 <strong>退出</strong> 时，仅影响该节点在 <code>Hash</code> 环上 <strong>顺时针相邻</strong> 的 <strong>后续节点</strong>。</li><li><strong>虚拟 Hash 槽算法</strong> - 使用 <strong>分散度良好</strong> 的 <strong>哈希函数</strong> 把所有数据 <strong>映射</strong> 到一个 <strong>固定范围</strong> 的 <strong>整数集合</strong> 中，整数定义为 <strong>槽</strong>（<code>slot</code>），这个范围一般 <strong>远远大于</strong> 节点数。<strong>槽</strong> 是集群内 <strong>数据管理</strong> 和 <strong>迁移</strong> 的 <strong>基本单位</strong>。采用 <strong>大范围槽</strong> 的主要目的是为了方便 <strong>数据拆分</strong> 和 <strong>集群扩展</strong>。每个节点会负责 <strong>一定数量的槽</strong>。</li></ul><h3 id="redis"><a class="markdownIt-Anchor" href="#redis"></a> Redis</h3><blockquote><p>Redis 是一个开源（BSD 许可）的，基于内存的，多数据结构存储系统。可以用作数据库、缓存和消息中间件。</p><p>Redis 还可以使用客户端分片来扩展写性能。内置了 复制（replication），LUA 脚本（Lua scripting），LRU 驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis 哨兵（Sentinel）和自动分区（Cluster）提供高可用性（high availability）。</p></blockquote><h4 id="redis-特性"><a class="markdownIt-Anchor" href="#redis-特性"></a> Redis 特性</h4><ul><li><p>支持多种数据类型 - string、hash、list、set、sorted set。</p></li><li><p>支持多种数据淘汰策略</p><ul><li><strong>volatile-lru</strong> - 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰</li><li><strong>volatile-ttl</strong> - 从已设置过期时间的数据集中挑选将要过期的数据淘汰</li><li><strong>volatile-random</strong> - 从已设置过期时间的数据集中任意选择数据淘汰</li><li><strong>allkeys-lru</strong> - 从所有数据集中挑选最近最少使用的数据淘汰</li><li><strong>allkeys-random</strong> - 从所有数据集中任意选择数据进行淘汰</li><li><strong>noeviction</strong> - 禁止驱逐数据</li></ul></li><li><p>提供两种持久化方式 - RDB 和 AOF</p></li><li><p>通过 Redis cluster 提供集群模式。</p></li></ul><h4 id="redis-原理"><a class="markdownIt-Anchor" href="#redis-原理"></a> Redis 原理</h4><ul><li>缓存淘汰<ul><li>Redis 有两种数据淘汰实现<ul><li>消极方式 - 访问 Redis key 时，如果发现它已经失效，则删除它</li><li>积极方式 - 周期性从设置了失效时间的 key 中，根据淘汰策略，选择一部分失效的 key 进行删除。</li></ul></li></ul></li><li>分区<ul><li>Redis Cluster 集群包含 16384 个虚拟 Hash 槽，它通过一个高效的算法来计算 key 属于哪个 Hash 槽。</li><li>Redis Cluster 支持请求分发 - 节点在接到一个命令请求时，会先检测这个命令请求要处理的键所在的槽是否由自己负责，如果不是的话，节点将向客户端返回一个 MOVED 错误，MOVED 错误携带的信息可以指引客户端将请求重定向至正在负责相关槽的节点。</li></ul></li><li>主从复制<ul><li>Redis 2.8 后支持异步复制。它有两种模式：<ul><li><code>完整重同步（full resychronization）</code> - 用于初次复制。执行步骤与 <code>SYNC</code> 命令基本一致。</li><li><code>部分重同步（partial resychronization）</code> - 用于断线后重复制。如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只需接收并执行这些写命令，即可将主从服务器的数据库状态保持一致。</li></ul></li><li>集群中每个节点都会定期向集群中的其他节点发送 PING 消息，以此来检测对方是否在线。</li><li>如果一个主节点被认为下线，则在其从节点中，根据 Raft 算法，选举出一个节点，升级为主节点。</li></ul></li><li>数据一致性<ul><li>Redis 不保证强一致性，因为这会使得集群性能大大降低。</li><li>Redis 是通过异步复制来实现最终一致性。</li></ul></li></ul><h3 id="分布式缓存对比"><a class="markdownIt-Anchor" href="#分布式缓存对比"></a> 分布式缓存对比</h3><p>不同的分布式缓存功能特性和实现原理方面有很大的差异，因此他们所适应的场景也有所不同。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200709224247.png" alt="img" /></p><p>这里选取三个比较出名的分布式缓存（MemCache，Redis，Tair）来作为比较：</p><table><thead><tr><th>比较项</th><th>MemCache</th><th>Redis</th><th>Tair</th></tr></thead><tbody><tr><td>数据结构</td><td>只支持简单的 Key-Value 结构</td><td>String,Hash, List, Set, Sorted Set</td><td>String,HashMap, List，Set</td></tr><tr><td>持久化</td><td>不支持</td><td>支持</td><td>支持</td></tr><tr><td>容量大小</td><td>数据纯内存，数据存储不宜过多</td><td>数据全内存，资源成本考量不宜超过 100GB</td><td>可以配置全内存或内存+磁盘引擎，数据容量可无限扩充</td></tr><tr><td>读写性能</td><td>很高</td><td>很高(RT0.5ms 左右)</td><td>String 类型比较高(RT1ms 左右)，复杂类型比较慢(RT5ms 左右)</td></tr><tr><td>过期策略</td><td>过期后，不删除缓存</td><td>有六种策略来处理过期数据</td><td>支持</td></tr></tbody></table><ul><li><code>MemCache</code> - 只适合基于内存的缓存框架；且不支持数据持久化和容灾。</li><li><code>Redis</code> - 支持丰富的数据结构，读写性能很高，但是数据全内存，必须要考虑资源成本，支持持久化。</li><li><code>Tair</code> - 支持丰富的数据结构，读写性能较高，部分类型比较慢，理论上容量可以无限扩充。</li></ul><p>总结：如果服务对延迟比较敏感，Map/Set 数据也比较多的话，比较适合 Redis。如果服务需要放入缓存量的数据很大，对延迟又不是特别敏感的话，那就可以选择 Memcached。</p><h2 id="五-多级缓存"><a class="markdownIt-Anchor" href="#五-多级缓存"></a> 五、多级缓存</h2><h3 id="整体缓存框架"><a class="markdownIt-Anchor" href="#整体缓存框架"></a> 整体缓存框架</h3><p>通常，一个大型软件系统的缓存采用多级缓存方案：</p><div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/缓存整体架构.png" /></div><p>请求过程：</p><ol><li>浏览器向客户端发起请求，如果 CDN 有缓存则直接返回；</li><li>如果 CDN 无缓存，则访问反向代理服务器；</li><li>如果反向代理服务器有缓存则直接返回；</li><li>如果反向代理服务器无缓存或动态请求，则访问应用服务器；</li><li>应用服务器访问进程内缓存；如果有缓存，则返回代理服务器，并缓存数据；（动态请求不缓存）</li><li>如果进程内缓存无数据，则读取分布式缓存；并返回应用服务器；应用服务器将数据缓存到本地缓存（部分）；</li><li>如果分布式缓存无数据，则应用程序读取数据库数据，并放入分布式缓存；</li></ol><h3 id="使用进程内缓存"><a class="markdownIt-Anchor" href="#使用进程内缓存"></a> 使用进程内缓存</h3><p><strong>如果应用服务是单点应用，那么进程内缓存当然是缓存的首选方案</strong>。</p><p>对于进程内缓存，其本来受限于内存的大小的限制，以及进程缓存更新后其他缓存无法得知，所以一般来说进程缓存适用于:</p><ul><li>数据量不是很大且更新频率较低的数据。</li><li>如果更新频繁的数据，也想使用进程内缓存，那么可以将其过期时间设置为较短的时间，或者设置较短的自动刷新时间。</li></ul><p>这种方案存在以下问题：</p><ul><li>如果应用服务是分布式系统，应用节点之间无法共享缓存，存在数据不一致问题。</li><li>由于进程内缓存受限于内存大小的限制，所以缓存不能无限扩展。</li></ul><h3 id="使用分布式缓存"><a class="markdownIt-Anchor" href="#使用分布式缓存"></a> 使用分布式缓存</h3><p>如果应用服务是分布式系统，那么最简单的缓存方案就是直接使用分布式缓存。</p><p>其应用场景如图所示：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200611141419.png" alt="img" /></p><p>Redis 用来存储热点数据，如果缓存不命中，则去查询数据库，并更新缓存。</p><p>这种方案存在以下问题：</p><ol><li>缓存服务如果挂了，这时应用只能访问数据库，容易造成缓存雪崩。</li><li>访问分布式缓存服务会有一定的 I/O 以及序列化反序列化的开销，虽然性能很高，但是其终究没有在内存中查询快。</li></ol><h3 id="使用多级缓存"><a class="markdownIt-Anchor" href="#使用多级缓存"></a> 使用多级缓存</h3><p>单纯使用进程内缓存和分布式缓存都存在各自的不足。如果需要更高的性能以及更好的可用性，我们可以将缓存设计为多级结构。将最热的数据使用进程内缓存存储在内存中，进一步提升访问速度。</p><p>这个设计思路在计算机系统中也存在，比如 CPU 使用 L1、L2、L3 多级缓存，用来减少对内存的直接访问，从而加快访问速度。</p><p>一般来说，多级缓存架构使用二级缓存已可以满足大部分业务需求，过多的分级会增加系统的复杂度以及维护的成本。因此，多级缓存不是分级越多越好，需要根据实际情况进行权衡。</p><p>一个典型的二级缓存架构，可以使用进程内缓存（如： Caffeine/Google Guava/Ehcache/HashMap）作为一级缓存；使用分布式缓存（如：Redis/Memcached）作为二级缓存。</p><h4 id="多级缓存查询"><a class="markdownIt-Anchor" href="#多级缓存查询"></a> 多级缓存查询</h4><div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/多级缓存2.png" width="600" /></div><p>多级缓存查询流程如下：</p><ol><li>首先，查询 L1 缓存，如果缓存命中，直接返回结果；如果没有命中，执行下一步。</li><li>接下来，查询 L2 缓存，如果缓存命中，直接返回结果并回填 L1 缓存；如果没有命中，执行下一步。</li><li>最后，查询数据库，返回结果并依次回填 L2 缓存、L1 缓存。</li></ol><h4 id="多级缓存更新"><a class="markdownIt-Anchor" href="#多级缓存更新"></a> 多级缓存更新</h4><p>对于 L1 缓存，如果有数据更新，只能删除并更新所在机器上的缓存，其他机器只能通过超时机制来刷新缓存。超时设定可以有两种策略:</p><ul><li>设置成写入后多少时间后过期</li><li>设置成写入后多少时间刷新</li></ul><p>对于 L1 缓存，如果有数据更新，其他机器立马可见。但是，也必须要设置超时时间，其时间应该比 L1 缓存的有效时间长。</p><p>为了解决进程内缓存不一致的问题，设计可以进一步优化:</p><div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/多级缓存3.png" /></div><p>通过消息队列的发布、订阅机制，可以通知其他应用节点对进程内缓存进行更新。使用这种方案，即使消息队列服务挂了或不可靠，由于先执行了数据库更新，但进程内缓存过期，刷新缓存时，也能保证数据的最终一致性。</p><h2 id="六-缓存问题"><a class="markdownIt-Anchor" href="#六-缓存问题"></a> 六、缓存问题</h2><h3 id="缓存雪崩"><a class="markdownIt-Anchor" href="#缓存雪崩"></a> 缓存雪崩</h3><p><strong>缓存雪崩是指缓存不可用或者大量缓存由于超时时间相同在同一时间段失效，大量请求直接访问数据库，数据库压力过大导致系统雪崩</strong>。</p><p>举例来说，对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。</p><p>解决缓存雪崩的主要手段如下：</p><ul><li><strong>增加缓存系统可用性</strong>（事前）。例如：部署 Redis Cluster（主从+哨兵），以实现 Redis 的高可用，避免全盘崩溃。</li><li><strong>采用多级缓存方案</strong>（事中）。例如：本地缓存（<strong>Ehcache</strong>/<strong>Caffine</strong>/<strong>Guava Cache</strong>） + 分布式缓存（<strong>Redis</strong>/ <strong>Memcached</strong>）。</li><li><strong>限流、降级、熔断方案</strong>（事中），避免被流量打死。如：使用 <strong>Hystrix</strong> 进行熔断、降级。</li><li>缓存如果支持<strong>持久化</strong>，可以在恢复工作后恢复数据（事后）。如：<strong>Redis</strong> 支持持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><p>上面的解决方案简单来说，就是多级缓存方案。系统收到一个查询请求，先查本地缓存，再查分布式缓存，最后查数据库，只要命中，立即返回。</p><p>解决缓存雪崩的辅助手段如下：</p><ul><li><strong>监控缓存，弹性扩容</strong>。</li><li><strong>缓存的过期时间可以取个随机值</strong>。这么做是为避免缓存同时失效，使得数据库 IO 骤升。比如：以前是设置 10 分钟的超时时间，那每个 Key 都可以随机 8-13 分钟过期，尽量让不同 Key 的过期时间不同。</li></ul><h3 id="缓存穿透"><a class="markdownIt-Anchor" href="#缓存穿透"></a> 缓存穿透</h3><blockquote><p><strong>缓存穿透是指：查询的数据在数据库中不存在，那么缓存中自然也不存在。所以，应用在缓存中查不到，则会去查询数据库。当这样的请求多了后，数据库的压力就会增大。</strong></p></blockquote><p>解决缓存穿透，一般有两种方法：</p><p>（一）缓存空值</p><p><strong>对于返回为 NULL 的依然缓存，对于抛出异常的返回不进行缓存</strong>。</p><div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/缓存穿透1.png" width="350px"/></div><p>采用这种手段的会增加我们缓存的维护成本，需要在插入缓存的时候删除这个空缓存，当然我们可以通过设置较短的超时时间来解决这个问题。</p><p>（二）过滤不可能存在的数据</p><div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/缓存穿透2.png" width="350px"/></div><p><strong>制定一些规则过滤一些不可能存在的数据</strong>。可以使用布隆过滤器（针对二进制操作的数据结构，所以性能高），比如你的订单 ID 明显是在一个范围 1-1000，如果不是 1-1000 之内的数据那其实可以直接给过滤掉。</p><blockquote><p>针对于一些恶意攻击，攻击带过来的大量 key 是不存在的，那么我们采用第一种方案就会缓存大量不存在 key 的数据。</p><p>此时我们采用第一种方案就不合适了，我们完全可以先对使用第二种方案进行过滤掉这些 key。</p><p>针对这种 key 异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。</p><p>而对于空数据的 key 有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。</p></blockquote><h3 id="缓存击穿"><a class="markdownIt-Anchor" href="#缓存击穿"></a> 缓存击穿</h3><p>缓存击穿是指，<strong>热点数据失效瞬间，大量请求直接访问数据库</strong>。例如，某些 key 是热点数据，访问非常频繁。如果某个 key 失效的瞬间，大量的请求过来，缓存未命中，然后去数据库访问，此时数据库访问量会急剧增加。</p><p>为了避免这个问题，我们可以采取下面的两个手段:</p><ul><li><strong>分布式锁</strong> - 锁住热点数据的 key，避免大量线程同时访问同一个 key。</li><li><strong>定时异步刷新</strong> - 可以对部分数据采取失效前自动刷新的策略，而不是到期自动淘汰。淘汰其实也是为了数据的时效性，所以采用自动刷新也可以。</li></ul><h3 id="小结"><a class="markdownIt-Anchor" href="#小结"></a> 小结</h3><p>上面逐一介绍了缓存使用中常见的问题。这里，从发生时间段的角度整体归纳一下缓存问题解决方案。</p><ul><li>事前：Redis 高可用方案（<strong>Redis Cluster</strong> + <strong>主从</strong> + <strong>哨兵</strong>），避免缓存全面崩溃。</li><li>事中：（一）采用多级缓存方案，本地缓存（<strong>Ehcache</strong>/<strong>Caffine</strong>/<strong>Guava Cache</strong>） + 分布式缓存（<strong>Redis</strong>/ <strong>Memcached</strong>）。（二）限流 + 熔断 + 降级（<strong>Hystrix</strong>），避免极端情况下，数据库被打死。</li><li>事后：<strong>Redis</strong> 持久化（<strong>RDB</strong>+<strong>AOF</strong>），一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><blockquote><p>分布式缓存 Memcached ，由于数据类型不如 Redis 丰富，并且不支持持久化、容灾。所以，一般会选择 Redis 做分布式缓存。</p></blockquote><h2 id="七-缓存策略"><a class="markdownIt-Anchor" href="#七-缓存策略"></a> 七、缓存策略</h2><h3 id="缓存预热"><a class="markdownIt-Anchor" href="#缓存预热"></a> 缓存预热</h3><p>缓存预热是指系统启动后，直接查询热点数据并缓存。这样就可以避免用户请求的时候，先查询数据库，然后再更新缓存的问题。</p><p>解决方案：</p><ul><li><strong>手动刷新缓存</strong>：直接写个缓存刷新页面，上线时手工操作下。</li><li><strong>应用启动时刷新缓存</strong>：数据量不大，可以在项目启动的时候自动进行加载。</li><li><strong>定时异步刷新缓存</strong></li></ul><h3 id="如何缓存"><a class="markdownIt-Anchor" href="#如何缓存"></a> 如何缓存</h3><h4 id="不过期缓存"><a class="markdownIt-Anchor" href="#不过期缓存"></a> 不过期缓存</h4><p>缓存更新模式：</p><ol><li>开启事务</li><li>写 SQL</li><li>提交事务</li><li>写缓存</li></ol><p><strong>不要把写缓存操作放在事务中，尤其是写分布式缓存</strong>。因为网络抖动可能导致写缓存响应时间很慢，引起数据库事务阻塞。如果对缓存数据一致性要求不是那么高，数据量也不是很大，可以考虑定期全量同步缓存。</p><p>这种模式存在这样的情况：存在事务成功，但缓存写失败的可能。但这种情况相对于上面的问题，影响较小。</p><h4 id="过期缓存"><a class="markdownIt-Anchor" href="#过期缓存"></a> 过期缓存</h4><p>采用<strong>懒加载</strong>。对于热点数据，可以设置较短的缓存时间，并定期异步加载。</p><h3 id="缓存更新"><a class="markdownIt-Anchor" href="#缓存更新"></a> 缓存更新</h3><p>一般来说，系统如果不是严格要求缓存和数据库保持一致性的话，尽量不要将<strong>读请求和写请求串行化</strong>。串行化可以保证一定不会出现数据不一致的情况，但是它会导致系统的吞吐量大幅度下降。</p><p>一般来说缓存的更新有两种情况:</p><ul><li>先删除缓存，再更新数据库。</li><li>先更新数据库，再删除缓存。</li></ul><blockquote><p><strong>为什么是删除缓存，而不是更新缓存呢？</strong></p><p>你可以想想当有多个并发的请求更新数据，你并不能保证更新数据库的顺序和更新缓存的顺序一致，那就会出现数据库中和缓存中数据不一致的情况。所以一般来说考虑删除缓存。</p></blockquote><ul><li><strong>先删除缓存，再更新数据库</strong></li></ul><p>对于一个更新操作简单来说，就是先去各级缓存进行删除，然后更新数据库。</p><p>这个操作有一个比较大的问题，在对缓存删除完之后，有一个读请求，这个时候由于缓存被删除所以直接会读库，读操作的数据是老的并且会被加载进入缓存当中，后续读请求全部访问的老数据。</p><div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/缓存更新.png" width="400px"/></div><p>对缓存的操作不论成功失败都不能阻塞我们对数据库的操作，那么很多时候删除缓存可以用异步的操作，但是先删除缓存不能很好的适用于这个场景。</p><p>先删除缓存也有一个好处是，如果对数据库操作失败了，那么由于先删除的缓存，最多只是造成 Cache Miss。</p><ul><li><strong>先更新数据库，再删除缓存</strong></li></ul><blockquote><p>注：更推荐使用这种策略</p></blockquote><p>如果我们使用更新数据库，再删除缓存就能避免上面的问题。</p><p>但是同样的引入了新的问题：假设执行更新操作时，又接收到查询请求，此时就会返回缓存中的老数据。更麻烦的是，如果数据库更新操作执行失败，则缓存中可能永远是脏数据。</p><ul><li>应该选择哪种更新策略</li></ul><p>通过上面的内容，我们知道，两种更新策略都存在并发问题。</p><p>但是建议选择先更新数据库，再删除缓存，因为其并发问题出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且同时有一个并发写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。</p><p>如果需要数据库和缓存保证强一致性，则可以通过 2PC 或 Paxos 协议来实现。但是 2PC 太慢，而 Paxos 太复杂，所以如果不是非常重要的数据，不建议使用强一致性方案。</p><blockquote><p>更详细的分析可以参考：<a href="https://www.cnblogs.com/rjzheng/p/9041659.html" target="_blank" rel="noopener">分布式之数据库和缓存双写一致性方案解析 </a></p></blockquote><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://item.jd.com/11322972.html" target="_blank" rel="noopener">《大型网站技术架构：核心原理与案例分析》</a></li><li><a href="https://link.juejin.im/?target=https%3A%2F%2Fjuejin.im%2Fpost%2F5b7593496fb9a009b62904fa">你应该知道的缓存进化史</a></li><li><a href="https://link.juejin.im/?target=https%3A%2F%2Fjuejin.im%2Fpost%2F5b849878e51d4538c77a974a">如何优雅的设计和使用缓存？</a></li><li><a href="https://www.jianshu.com/p/73ce0ef820f9" target="_blank" rel="noopener">理解分布式系统中的缓存架构(上)</a></li><li><a href="https://tech.meituan.com/2017/03/17/cache-about.html" target="_blank" rel="noopener">缓存那些事</a></li><li><a href="https://www.cnblogs.com/rjzheng/p/9041659.html" target="_blank" rel="noopener">分布式之数据库和缓存双写一致性方案解析 </a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;缓存基本原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#缓存基本原理&quot;&gt;&lt;/a&gt; 缓存基本原理&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;缓存是一种利用空间换时间的设计，其目标就是&lt;strong&gt;更快&lt;/strong&gt;、&lt;stron
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="缓存" scheme="https://dunwu.github.io/blog/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务基本原理</title>
    <link href="https://dunwu.github.io/blog/theory/distributed-transaction/"/>
    <id>https://dunwu.github.io/blog/theory/distributed-transaction/</id>
    <published>2019-06-21T03:30:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式事务基本原理"><a class="markdownIt-Anchor" href="#分布式事务基本原理"></a> 分布式事务基本原理</h1><blockquote><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p><p><strong>分布式事务指的是事务操作跨越多个节点，并且要求满足事务的 ACID 特性。</strong></p></blockquote><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%AE%80%E4%BB%8B">一、分布式事务简介</a><ul><li><a href="#%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1">本地事务</a></li><li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1">分布式事务</a></li><li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%BE%E7%82%B9">分布式事务的难点</a></li><li><a href="#cap-%E5%92%8C-base">CAP 和 BASE</a></li><li><a href="#%E6%9F%94%E6%80%A7%E4%BA%8B%E5%8A%A1">柔性事务</a></li></ul></li><li><a href="#%E4%BA%8C%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A42pc">二、两阶段提交（2PC）</a><ul><li><a href="#%E6%96%B9%E6%A1%88%E7%AE%80%E4%BB%8B">方案简介</a></li><li><a href="#%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B">处理流程</a></li><li><a href="#%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93">方案总结</a></li></ul></li><li><a href="#%E4%B8%89%E4%B8%89%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A43pc">三、三阶段提交（3PC）</a><ul><li><a href="#%E6%96%B9%E6%A1%88%E7%AE%80%E4%BB%8B-1">方案简介</a></li><li><a href="#%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-1">处理流程</a></li><li><a href="#%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93-1">方案总结</a></li></ul></li><li><a href="#%E5%9B%9B%E8%A1%A5%E5%81%BF%E4%BA%8B%E5%8A%A1tcc">四、补偿事务（TCC）</a><ul><li><a href="#%E6%96%B9%E6%A1%88%E7%AE%80%E4%BB%8B-2">方案简介</a></li><li><a href="#%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-2">处理流程</a></li><li><a href="#%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93-2">方案总结</a></li></ul></li><li><a href="#%E4%BA%94%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8">五、本地消息表</a><ul><li><a href="#%E6%96%B9%E6%A1%88%E7%AE%80%E4%BB%8B-3">方案简介</a></li><li><a href="#%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-3">处理流程</a></li><li><a href="#%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93-3">方案总结</a></li></ul></li><li><a href="#%E5%85%ADmq-%E4%BA%8B%E5%8A%A1">六、MQ 事务</a><ul><li><a href="#%E6%96%B9%E6%A1%88%E7%AE%80%E4%BB%8B-4">方案简介</a></li><li><a href="#%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-4">处理流程</a></li><li><a href="#%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93-4">方案总结</a></li></ul></li><li><a href="#%E4%B8%83saga">七、SAGA</a><ul><li><a href="#%E6%96%B9%E6%A1%88%E7%AE%80%E4%BB%8B-5">方案简介</a></li><li><a href="#%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-5">处理流程</a></li><li><a href="#%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93-5">方案总结</a></li></ul></li><li><a href="#%E6%80%BB%E7%BB%93">总结</a><ul><li><a href="#%E5%90%84%E6%96%B9%E6%A1%88%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF">各方案使用场景</a></li><li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1">分布式事务方案设计</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-分布式事务简介"><a class="markdownIt-Anchor" href="#一-分布式事务简介"></a> 一、分布式事务简介</h2><h3 id="本地事务"><a class="markdownIt-Anchor" href="#本地事务"></a> 本地事务</h3><p>学习分布式之前，先了解一下本地事务的概念。</p><p>事务简单来说：<strong>一个会话中所进行所有的操作，要么同时成功，要么同时失败</strong>。</p><p><img src="http://dunwu.test.upcdn.net/cs/database/RDB/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1.png" alt="img" /></p><p>具体来说，事务指的是满足 ACID 特性的一组操作，可以通过 <code>Commit</code> 提交一个事务，也可以使用 <code>Rollback</code> 进行回滚。</p><ul><li>原子性（Atomicity）</li><li>一致性（Consistency）</li><li>隔离性（Isolation）</li><li>持久性（Durability）</li></ul><blockquote><p>💡 更详细的内容可以参考：<a href="https://dunwu.github.io/db-tutorial/#/sql/sql-interview?id=%e4%ba%8c%e3%80%81%e4%ba%8b%e5%8a%a1">事务</a></p></blockquote><h3 id="分布式事务"><a class="markdownIt-Anchor" href="#分布式事务"></a> 分布式事务</h3><p><strong>分布式事务指的是事务操作跨越多个节点，并且要求满足事务的 ACID 特性。</strong></p><p>随着互联网快速发展，微服务，SOA 等服务架构模式正在被大规模的使用，现在分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。</p><p>有很多用例会跨多个子系统才能完成，比较典型的是电子商务网站的下单支付流程，至少会涉及交易系统和支付系统，而且这个过程中会涉及到事务的概念，即保证交易系统和支付系统的数据一致性，此处我们称这种<strong>跨系统的事务为分布式事务</strong>，具体一点而言，分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。</p><p>举个互联网常用的交易业务为例：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200205112615.png" alt="img" /></p><p>上图中包含了库存和订单两个独立的微服务，每个微服务维护了自己的数据库。在交易系统的业务逻辑中，一个商品在下单之前需要先调用库存服务，进行扣除库存，再调用订单服务，创建订单记录。</p><p><img src="http://dunwu.test.upcdn.net/snap/20200205112518.png" alt="img" /></p><p>可以看到，如果多个数据库之间的数据更新没有保证事务，将会导致出现子系统数据不一致，业务出现问题。</p><h3 id="分布式事务的难点"><a class="markdownIt-Anchor" href="#分布式事务的难点"></a> 分布式事务的难点</h3><ul><li><strong>事务的原子性</strong> 事务操作跨不同节点，当多个节点某一节点操作失败时，需要保证多节点操作的**都做或都不做（All or Nothing）**的原子性。</li><li><strong>事务的一致性</strong> 当发生网络传输故障或者节点故障，节点间数据复制通道中断，在进行事务操作时需要保证数据一致性，保证事务的任何操作都不会使得数据违反数据库定义的约束、触发器等规则。</li><li><strong>事务的隔离性</strong> 事务隔离性的本质就是如何正确多个并发事务的处理的读写冲突和写写冲突，因为在分布式事务控制中，可能会出现提交不同步的现象，这个时候就有可能出现“部分已经提交”的事务。此时并发应用访问数据如果没有加以控制，有可能出现“脏读”问题。</li></ul><h3 id="cap-和-base"><a class="markdownIt-Anchor" href="#cap-和-base"></a> CAP 和 BASE</h3><p>CAP 定理又称为 CAP 原则，指的是：<strong>在一个分布式系统中， <code>一致性（C：Consistency）</code>、<code>可用性（A：Availability）</code> 和 <code>分区容忍性（P：Partition Tolerance）</code>，最多只能同时满足其中两项</strong>。</p><p>BASE 是 <strong><code>基本可用（Basically Available）</code></strong>、<strong><code>软状态（Soft State）</code></strong> 和 <strong><code>最终一致性（Eventually Consistent）</code></strong> 三个短语的缩写。BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。</p><blockquote><p>💡 更详细的内容可以参考：<a href="#distributed-base-theory.md">分布式基础理论</a></p></blockquote><h3 id="柔性事务"><a class="markdownIt-Anchor" href="#柔性事务"></a> 柔性事务</h3><h4 id="柔性事务的概念"><a class="markdownIt-Anchor" href="#柔性事务的概念"></a> 柔性事务的概念</h4><p>在电商等互联网场景下，传统的事务在数据库性能和处理能力上都暴露出了瓶颈。在分布式领域基于 CAP 理论以及 BASE 理论，有人就提出了<strong>柔性事务</strong>的概念。</p><p>基于 BASE 理论的设计思想，柔性事务下，在不影响系统整体可用性的情况下(Basically Available 基本可用)，允许系统存在数据不一致的中间状态(Soft State 软状态)，在经过数据同步的延时之后，最终数据能够达到一致。<strong>并不是完全放弃了 ACID，而是通过放宽一致性要求，借助本地事务来实现最终分布式事务一致性的同时也保证系统的吞吐</strong>。</p><h4 id="柔性事务的特性"><a class="markdownIt-Anchor" href="#柔性事务的特性"></a> 柔性事务的特性</h4><p>下面介绍的是实现柔性事务的一些常见特性，这些特性在具体的方案中不一定都要满足，因为不同的方案要求不一样。</p><p><strong>可见性(对外可查询)</strong> 在分布式事务执行过程中，如果某一个步骤执行出错，就需要明确的知道其他几个操作的处理情况，这就需要其他的服务都能够提供查询接口，保证可以通过查询来判断操作的处理情况。</p><p>为了保证操作的可查询，需要对于每一个服务的每一次调用都有一个全局唯一的标识，可以是业务单据号（如订单号）、也可以是系统分配的操作流水号（如支付记录流水号）。除此之外，操作的时间信息也要有完整的记录。</p><p><strong>操作幂等性</strong> 幂等性，其实是一个数学概念。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。也就是说，同一个方法，使用同样的参数，调用多次产生的业务结果与调用一次产生的业务结果相同。</p><p>之所以需要操作幂等性，是因为为了保证数据的最终一致性，很多事务协议都会有很多重试的操作，如果一个方法不保证幂等，那么将无法被重试。幂等操作的实现方式有多种，如在系统中缓存所有的请求与处理结果、检测到重复操作后，直接返回上一次的处理结果等。</p><h2 id="二-两阶段提交2pc"><a class="markdownIt-Anchor" href="#二-两阶段提交2pc"></a> 二、两阶段提交（2PC）</h2><h3 id="方案简介"><a class="markdownIt-Anchor" href="#方案简介"></a> 方案简介</h3><p>二阶段提交协议（Two-phase Commit，即 2PC）是常用的分布式事务解决方案，即<strong>将事务的提交过程分为两个阶段来进行处理：准备阶段和提交阶段</strong>。事务的发起者称协调者，事务的执行者称参与者。</p><p>在分布式系统里，每个节点都可以知晓自己操作的成功或者失败，却无法知道其他节点操作的成功或失败。当一个事务跨多个节点时，为了保持事务的原子性与一致性，而引入一个协调者来统一掌控所有参与者的操作结果，并指示它们是否要把操作结果进行真正的提交或者回滚（rollback）。</p><p>二阶段提交的思路可以概括为：<strong>参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作</strong>。</p><p>核心思想就是对每一个事务都采用先尝试后提交的处理方式，处理后所有的读操作都要能获得最新的数据，因此也可以将二阶段提交看作是一个强一致性算法。</p><h3 id="处理流程"><a class="markdownIt-Anchor" href="#处理流程"></a> 处理流程</h3><p>简单一点理解，可以把协调者节点比喻为带头大哥，参与者理解比喻为跟班小弟，带头大哥统一协调跟班小弟的任务执行。</p><h4 id="阶段-1准备阶段"><a class="markdownIt-Anchor" href="#阶段-1准备阶段"></a> 阶段 1：准备阶段</h4><ol><li>协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待所有参与者答复。</li><li>各参与者执行事务操作，将 undo 和 redo 信息记入事务日志中（但不提交事务）。</li><li>如参与者执行成功，给协调者反馈 yes，即可以提交；如执行失败，给协调者反馈 no，即不可提交。</li></ol><h4 id="阶段-2提交阶段"><a class="markdownIt-Anchor" href="#阶段-2提交阶段"></a> 阶段 2：提交阶段</h4><p>如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(rollback)消息；否则，发送提交(commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源) 接下来分两种情况分别讨论提交阶段的过程。</p><p><strong>情况 1，当所有参与者均反馈 yes，提交事务</strong>：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200205153529.png" alt="img" /></p><blockquote><ol><li>协调者向所有参与者发出正式提交事务的请求（即 commit 请求）。</li><li>参与者执行 commit 请求，并释放整个事务期间占用的资源。</li><li>各参与者向协调者反馈 ack(应答)完成的消息。</li><li>协调者收到所有参与者反馈的 ack 消息后，即完成事务提交。</li></ol></blockquote><p><strong>情况 2，当任何阶段 1 一个参与者反馈 no，中断事务</strong>：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200205154145.png" alt="img" /></p><blockquote><ol><li>协调者向所有参与者发出回滚请求（即 rollback 请求）。</li><li>参与者使用阶段 1 中的 undo 信息执行回滚操作，并释放整个事务期间占用的资源。</li><li>各参与者向协调者反馈 ack 完成的消息。</li><li>协调者收到所有参与者反馈的 ack 消息后，即完成事务中断。</li></ol></blockquote><h3 id="方案总结"><a class="markdownIt-Anchor" href="#方案总结"></a> 方案总结</h3><p>2PC 方案实现起来简单，实际项目中使用比较少，主要因为以下问题：</p><ul><li><strong>性能问题</strong> - 所有参与者在事务提交阶段处于同步阻塞状态，占用系统资源，容易导致性能瓶颈。</li><li><strong>可靠性问题</strong> - 如果协调者存在单点故障问题，如果协调者出现故障，参与者将一直处于锁定状态。</li><li><strong>数据一致性问题</strong> - 在阶段 2 中，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。</li></ul><h2 id="三-三阶段提交3pc"><a class="markdownIt-Anchor" href="#三-三阶段提交3pc"></a> 三、三阶段提交（3PC）</h2><h3 id="方案简介-2"><a class="markdownIt-Anchor" href="#方案简介-2"></a> 方案简介</h3><p>三阶段提交协议（Three-phase Commit，3PC），是二阶段提交协议的改进版本，与二阶段提交不同的是，引入超时机制。同时在协调者和参与者中都引入超时机制。</p><p>三阶段提交将二阶段的准备阶段拆分为 2 个阶段，插入了一个 preCommit 阶段，使得原先在二阶段提交中，参与者在准备之后，由于协调者发生崩溃或错误，而导致参与者处于无法知晓是否提交或者中止的“不确定状态”所产生的可能相当长的延时的问题得以解决。</p><h3 id="处理流程-2"><a class="markdownIt-Anchor" href="#处理流程-2"></a> 处理流程</h3><h4 id="阶段-1cancommit"><a class="markdownIt-Anchor" href="#阶段-1cancommit"></a> 阶段 1：canCommit</h4><p>协调者向参与者发送 commit 请求，参与者如果可以提交就返回 yes 响应(参与者不执行事务操作)，否则返回 no 响应：</p><ol><li>协调者向所有参与者发出包含事务内容的 canCommit 请求，询问是否可以提交事务，并等待所有参与者答复。</li><li>参与者收到 canCommit 请求后，如果认为可以执行事务操作，则反馈 yes 并进入预备状态，否则反馈 no。</li></ol><h4 id="阶段-2precommit"><a class="markdownIt-Anchor" href="#阶段-2precommit"></a> 阶段 2：preCommit</h4><p>协调者根据阶段 1 canCommit 参与者的反应情况来决定是否可以基于事务的 preCommit 操作。根据响应情况，有以下两种可能。</p><p><strong>情况 1：阶段 1 所有参与者均反馈 yes，参与者预执行事务：</strong></p><p><img src="http://dunwu.test.upcdn.net/snap/20200205180242.png" alt="img" /></p><blockquote><ol><li>协调者向所有参与者发出 preCommit 请求，进入准备阶段。</li><li>参与者收到 preCommit 请求后，执行事务操作，将 undo 和 redo 信息记入事务日志中（但不提交事务）。</li><li>各参与者向协调者反馈 ack 响应或 no 响应，并等待最终指令。</li></ol></blockquote><p><strong>情况 2：阶段 1 任何一个参与者反馈 no，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务:</strong></p><p><img src="http://dunwu.test.upcdn.net/snap/20200205205117.png" alt="img" /></p><blockquote><ol><li>协调者向所有参与者发出 abort 请求。</li><li>无论收到协调者发出的 abort 请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。</li></ol></blockquote><h4 id="阶段-3docommit"><a class="markdownIt-Anchor" href="#阶段-3docommit"></a> 阶段 3：doCommit</h4><p>该阶段进行真正的事务提交，也可以分为以下两种情况：</p><p><strong>情况 1：阶段 2 所有参与者均反馈 ack 响应，执行真正的事务提交：</strong></p><p><img src="http://dunwu.test.upcdn.net/snap/20200205180425.png" alt="img" /></p><blockquote><ol><li>如果协调者处于工作状态，则向所有参与者发出 do Commit 请求。</li><li>参与者收到 do Commit 请求后，会正式执行事务提交，并释放整个事务期间占用的资源。</li><li>各参与者向协调者反馈 ack 完成的消息。</li><li>协调者收到所有参与者反馈的 ack 消息后，即完成事务提交。</li></ol></blockquote><p><strong>阶段 2 任何一个参与者反馈 no，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务：</strong></p><p><img src="http://dunwu.test.upcdn.net/snap/20200205180515.png" alt="img" /></p><blockquote><ol><li>如果协调者处于工作状态，向所有参与者发出 abort 请求。</li><li>参与者使用阶段 1 中的 undo 信息执行回滚操作，并释放整个事务期间占用的资源。</li><li>各参与者向协调者反馈 ack 完成的消息。</li><li>协调者收到所有参与者反馈的 ack 消息后，即完成事务中断。</li></ol></blockquote><p>注意：进入阶段 3 后，无论协调者出现问题，或者协调者与参与者网络出现问题，都会导致参与者无法接收到协调者发出的 do Commit 请求或 abort 请求。此时，参与者都会在等待超时之后，继续执行事务提交。</p><h3 id="方案总结-2"><a class="markdownIt-Anchor" href="#方案总结-2"></a> 方案总结</h3><p>优点：</p><ul><li>相比二阶段提交，三阶段降低了阻塞范围，在等待超时后协调者或参与者会中断事务。避免了协调者单点问题，阶段 3 中协调者出现问题时，参与者会继续提交事务。</li></ul><p>缺点：</p><ul><li>数据不一致问题依然存在，当在参与者收到 preCommit 请求后等待 do commite 指令时，此时如果协调者请求中断事务，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。</li></ul><h2 id="四-补偿事务tcc"><a class="markdownIt-Anchor" href="#四-补偿事务tcc"></a> 四、补偿事务（TCC）</h2><h3 id="方案简介-3"><a class="markdownIt-Anchor" href="#方案简介-3"></a> 方案简介</h3><p>TCC（Try-Confirm-Cancel）的概念，最早是由 Pat Helland 于 2007 年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。</p><p>TCC 是服务化的二阶段编程模型，其 Try、Confirm、Cancel 3 个方法均由业务编码实现；</p><ul><li><strong>Try</strong> - 操作作为一阶段，负责资源的检查和预留。</li><li><strong>Confirm</strong> - 操作作为二阶段提交操作，执行真正的业务。</li><li><strong>Cancel</strong> - 是预留资源的取消。</li></ul><p>TCC 事务的 Try、Confirm、Cancel 可以理解为 SQL 事务中的 Lock、Commit、Rollback。</p><h3 id="处理流程-3"><a class="markdownIt-Anchor" href="#处理流程-3"></a> 处理流程</h3><p>为了方便理解，下面以电商下单为例进行方案解析，这里把整个过程简单分为扣减库存，订单创建 2 个步骤，库存服务和订单服务分别在不同的服务器节点上。</p><h4 id="try-阶段"><a class="markdownIt-Anchor" href="#try-阶段"></a> Try 阶段</h4><p>从执行阶段来看，与传统事务机制中业务逻辑相同。但从业务角度来看，却不一样。TCC 机制中的 Try 仅是一个初步操作，它和后续的确认一起才能真正构成一个完整的业务逻辑，这个阶段主要完成：</p><ul><li>完成所有业务检查( 一致性 )</li><li>预留必须业务资源( 准隔离性 )</li><li>Try 尝试执行业务 TCC 事务机制以初步操作（Try）为中心的，确认操作（Confirm）和取消操作（Cancel）都是围绕初步操作（Try）而展开。因此，Try 阶段中的操作，其保障性是最好的，即使失败，仍然有取消操作（Cancel）可以将其执行结果撤销。</li></ul><p>假设商品库存为 100，购买数量为 2，这里检查和更新库存的同时，冻结用户购买数量的库存，同时创建订单，订单状态为待确认。</p><h4 id="confirm-cancel-阶段"><a class="markdownIt-Anchor" href="#confirm-cancel-阶段"></a> Confirm / Cancel 阶段</h4><p>根据 Try 阶段服务是否全部正常执行，继续执行确认操作（Confirm）或取消操作（Cancel）。 Confirm 和 Cancel 操作满足幂等性，如果 Confirm 或 Cancel 操作执行失败，将会不断重试直到执行完成。</p><p><strong>Confirm：当 Try 阶段服务全部正常执行， 执行确认业务逻辑操作</strong></p><p><img src="http://dunwu.test.upcdn.net/snap/20200205205200.png" alt="img" /></p><p>这里使用的资源一定是 Try 阶段预留的业务资源。在 TCC 事务机制中认为，如果在 Try 阶段能正常的预留资源，那 Confirm 一定能完整正确的提交。Confirm 阶段也可以看成是对 Try 阶段的一个补充，Try+Confirm 一起组成了一个完整的业务逻辑。</p><p><strong>Cancel：当 Try 阶段存在服务执行失败， 进入 Cancel 阶段</strong></p><p><img src="http://dunwu.test.upcdn.net/snap/20200205205221.png" alt="img" /></p><p>Cancel 取消执行，释放 Try 阶段预留的业务资源，上面的例子中，Cancel 操作会把冻结的库存释放，并更新订单状态为取消。</p><h3 id="方案总结-3"><a class="markdownIt-Anchor" href="#方案总结-3"></a> 方案总结</h3><p>TCC 事务机制相对于传统事务机制（X/Open XA），TCC 事务机制相比于上面介绍的 XA 事务机制，有以下优点:</p><ul><li><strong>性能提升</strong> - 具体业务来实现控制资源锁的粒度变小，不会锁定整个资源。</li><li><strong>数据最终一致性</strong> - 基于 Confirm 和 Cancel 的幂等性，保证事务最终完成确认或者取消，保证数据的一致性。</li><li><strong>可靠性</strong> - 解决了 XA 协议的协调者单点故障问题，由主业务方发起并控制整个业务活动，业务活动管理器也变成多点，引入集群。</li></ul><p>缺点： TCC 的 Try、Confirm 和 Cancel 操作功能要按具体业务来实现，业务耦合度较高，提高了开发成本。</p><h2 id="五-本地消息表"><a class="markdownIt-Anchor" href="#五-本地消息表"></a> 五、本地消息表</h2><h3 id="方案简介-4"><a class="markdownIt-Anchor" href="#方案简介-4"></a> 方案简介</h3><p>本地消息表的方案最初是由 ebay 提出，核心思路是将分布式事务拆分成本地事务进行处理。</p><p>方案通过在事务主动发起方额外新建事务消息表，事务发起方处理业务和记录事务消息在本地事务中完成，轮询事务消息表的数据发送事务消息，事务被动方基于消息中间件消费事务消息表中的事务。</p><p>这样设计可以避免”<strong>业务处理成功 + 事务消息发送失败</strong>&quot;，或&quot;<strong>业务处理失败 + 事务消息发送成功</strong>&quot;的棘手情况出现，保证 2 个系统事务的数据一致性。</p><h3 id="处理流程-4"><a class="markdownIt-Anchor" href="#处理流程-4"></a> 处理流程</h3><p>下面把分布式事务最先开始处理的事务方成为事务主动方，在事务主动方之后处理的业务内的其他事务成为事务被动方。</p><p>为了方便理解，下面继续以电商下单为例进行方案解析，这里把整个过程简单分为扣减库存，订单创建 2 个步骤，库存服务和订单服务分别在不同的服务器节点上，其中库存服务是事务主动方，订单服务是事务被动方。</p><p>事务的主动方需要额外新建事务消息表，用于记录分布式事务的消息的发生、处理状态。</p><p>整个业务处理流程如下：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200205220246.png" alt="img" /></p><blockquote><ol><li><strong>步骤 1 事务主动方处理本地事务。</strong> 事务主动发在本地事务中处理业务更新操作和写消息表操作。 上面例子中库存服务阶段再本地事务中完成扣减库存和写消息表(图中 1、2)。</li><li><strong>步骤 2 事务主动方通过 MQ 通知事务被动方处理事务</strong>。 消息中间件可以基于 Kafka、RocketMQ 消息队列，事务主动方法主动写消息到消息队列，事务消费方消费并处理消息队列中的消息。 上面例子中，库存服务把事务待处理消息写到消息中间件，订单服务消费消息中间件的消息，完成新增订单（图中 3 - 5）。</li><li><strong>步骤 3 事务被动方通过 MQ 反会处理结果。</strong> 上面例子中，订单服务把事务已处理消息写到消息中间件，库存服务消费中间件的消息，并将事务消息的状态更新为已完成(图中 6 - 8)</li></ol></blockquote><p>为了数据的一致性，当处理错误需要重试，事务发送方和事务接收方相关业务处理需要支持幂等。具体保存一致性的容错处理如下：</p><blockquote><ul><li>当步骤 1 处理出错，事务回滚，相当于什么都没发生。</li><li>当步骤 2、步骤 3 处理出错，由于未处理的事务消息还是保存在事务发送方，事务发送方可以定时轮询为超时消息数据，再次发送的消息中间件进行处理。事务被动方消费事务消息重试处理。</li><li>如果是业务上的失败，事务被动方可以发消息给事务主动方进行回滚。</li><li>如果多个事务被动方已经消费消息，事务主动方需要回滚事务时需要通知事务被动方回滚。</li></ul></blockquote><h3 id="方案总结-4"><a class="markdownIt-Anchor" href="#方案总结-4"></a> 方案总结</h3><p>方案的优点如下：</p><ul><li>从应用设计开发的角度实现了消息数据的可靠性，消息数据的可靠性不依赖于消息中间件，弱化了对 MQ 中间件特性的依赖。</li><li>方案轻量，容易实现。</li></ul><p>缺点如下：</p><ul><li>与具体的业务场景绑定，耦合性强，不可复用。</li><li>消息数据与业务数据同库，占用业务系统资源。</li><li>业务系统在使用关系型数据库的情况下，消息服务性能会受到关系型数据库并发性能的局限。</li></ul><h2 id="六-mq-事务"><a class="markdownIt-Anchor" href="#六-mq-事务"></a> 六、MQ 事务</h2><h3 id="方案简介-5"><a class="markdownIt-Anchor" href="#方案简介-5"></a> 方案简介</h3><p>基于 MQ 的分布式事务方案其实是对本地消息表的封装，将本地消息表基于 MQ 内部，其他方面的协议基本与本地消息表一致。</p><h3 id="处理流程-5"><a class="markdownIt-Anchor" href="#处理流程-5"></a> 处理流程</h3><p>下面主要基于 RocketMQ4.3 之后的版本介绍 MQ 的分布式事务方案。</p><p>在本地消息表方案中，保证事务主动方发写业务表数据和写消息表数据的一致性是基于数据库事务，RocketMQ 的事务消息相对于普通 MQ，相对于提供了 2PC 的提交接口，方案如下：</p><p><strong>正常情况——事务主动方发消息</strong> 这种情况下，事务主动方服务正常，没有发生故障，发消息流程如下：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200205230320.png" alt="img" /></p><blockquote><ol><li>发送方向 MQ 服务端(MQ Server)发送 half 消息。</li><li>MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功。</li><li>发送方开始执行本地事务逻辑。</li><li>发送方根据本地事务执行结果向 MQ Server 提交二次确认（commit 或是 rollback）。</li><li>MQ Server 收到 commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 rollback 状态则删除半消息，订阅方将不会接受该消息。</li></ol></blockquote><p><strong>异常情况——事务主动方消息恢复</strong> 在断网或者应用重启等异常情况下，图中 4 提交的二次确认超时未到达 MQ Server，此时处理逻辑如下：</p><p><img src="http://dunwu.test.upcdn.net/snap/20200205230412.png" alt="img" /></p><blockquote><ol start="5"><li>MQ Server 对该消息发起消息回查。</li><li>发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li><li>发送方根据检查得到的本地事务的最终状态再次提交二次确认</li><li>MQ Server 基于 commit / rollback 对消息进行投递或者删除</li></ol></blockquote><h3 id="方案总结-5"><a class="markdownIt-Anchor" href="#方案总结-5"></a> 方案总结</h3><p>相比本地消息表方案，MQ 事务方案优点是：</p><ul><li>消息数据独立存储 ，降低业务系统与消息系统之间的耦合。</li><li>吞吐量优于使用本地消息表方案。</li></ul><p>缺点是：</p><ul><li>一次消息发送需要两次网络请求(half 消息 + commit/rollback 消息)</li><li>业务处理服务需要实现消息状态回查接口</li></ul><h2 id="七-saga"><a class="markdownIt-Anchor" href="#七-saga"></a> 七、SAGA</h2><h3 id="方案简介-6"><a class="markdownIt-Anchor" href="#方案简介-6"></a> 方案简介</h3><p>Saga 事务源于 1987 年普林斯顿大学的 Hecto 和 Kenneth 发表的如何处理 long lived transaction（长活事务）论文，Saga 事务核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。</p><h3 id="处理流程-6"><a class="markdownIt-Anchor" href="#处理流程-6"></a> 处理流程</h3><p><strong>Saga 事务基本协议如下</strong>：</p><ul><li>每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。</li><li>每个 Ti 都有对应的幂等补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果。</li></ul><p>可以看到，和 TCC 相比，Saga 没有“预留”动作，它的 Ti 就是直接提交到库。</p><p>下面以下单流程为例，整个操作包括：创建订单、扣减库存、支付、增加积分 Saga 的执行顺序有两种：</p><p><img src="https://user-gold-cdn.xitu.io/2018/12/10/1679817d8ce9b4b7?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="Saga事务执行顺序" /></p><ul><li>事务正常执行完成 T1, T2, T3, …, Tn，例如：扣减库存(T1)，创建订单(T2)，支付(T3)，依次有序完成整个事务。</li><li>事务回滚 T1, T2, …, Tj, Cj,…, C2, C1，其中 0 &lt; j &lt; n，例如：扣减库存(T1)，创建订单(T2)，支付(T3，支付失败)，支付回滚(C3)，订单回滚(C2)，恢复库存(C1)。</li></ul><h4 id="恢复策略"><a class="markdownIt-Anchor" href="#恢复策略"></a> 恢复策略</h4><p>Saga 定义了两种恢复策略：</p><ul><li>向前恢复(forward recovery)</li></ul><p><img src="https://user-gold-cdn.xitu.io/2018/12/10/1679817da631d59c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="Saga事务向前恢复" /></p><p>对应于上面第一种执行顺序，适用于必须要成功的场景，发生失败进行重试，执行顺序是类似于这样的：T1, T2, …, Tj(失败), Tj(重试),…, Tn，其中 j 是发生错误的子事务(sub-transaction)。该情况下不需要 Ci。</p><ul><li>向后恢复(backward recovery)</li></ul><p><img src="https://user-gold-cdn.xitu.io/2018/12/10/1679817da706b3c2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="Saga事务向后恢复" /></p><p>对应于上面提到的第二种执行顺序，其中 j 是发生错误的子事务(sub-transaction)，这种做法的效果是撤销掉之前所有成功的子事务，使得整个 Saga 的执行结果撤销。</p><p>Saga 事务常见的有两种不同的实现方式：命令协调和事件编排。</p><h4 id="命令协调"><a class="markdownIt-Anchor" href="#命令协调"></a> 命令协调</h4><ul><li><strong>命令协调(Order Orchestrator)：中央协调器负责集中处理事件的决策和业务逻辑排序。</strong></li></ul><p>中央协调器（Orchestrator，简称 OSO）以命令/回复的方式与每项服务进行通信，全权负责告诉每个参与者该做什么以及什么时候该做什么。</p><p><img src="https://user-gold-cdn.xitu.io/2018/12/10/1679817daa1798dd?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="命令协调模式" /></p><p>以电商订单的例子为例：</p><blockquote><ol><li>事务发起方的主业务逻辑请求 OSO 服务开启订单事务。</li><li>OSO 向库存服务请求扣减库存，库存服务回复处理结果。</li><li>OSO 向订单服务请求创建订单，订单服务回复创建结果。</li><li>OSO 向支付服务请求支付，支付服务回复处理结果。</li><li>主业务逻辑接收并处理 OSO 事务处理结果回复。</li></ol></blockquote><p>中央协调器必须事先知道执行整个订单事务所需的流程(例如通过读取配置)。如果有任何失败，它还负责通过向每个参与者发送命令来撤销之前的操作来协调分布式的回滚。基于中央协调器协调一切时，回滚要容易得多，因为协调器默认是执行正向流程，回滚时只要执行反向流程即可。</p><h4 id="事件编排"><a class="markdownIt-Anchor" href="#事件编排"></a> 事件编排</h4><ul><li><strong>事件编排 (Event Choreography0：没有中央协调器（没有单点风险）时，每个服务产生并观察其他服务的事件，并决定是否应采取行动</strong>。</li></ul><p>在事件编排方法中，第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。</p><p>当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何 Saga 参与者听到都意味着事务结束。</p><p>以电商订单的例子为例：</p><p><img src="https://user-gold-cdn.xitu.io/2018/12/10/1679817dba9b2b61?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="事件编排模式" /></p><blockquote><ol><li>事务发起方的主业务逻辑发布开始订单事件</li><li>库存服务监听开始订单事件，扣减库存，并发布库存已扣减事件</li><li>订单服务监听库存已扣减事件，创建订单，并发布订单已创建事件</li><li>支付服务监听订单已创建事件，进行支付，并发布订单已支付事件</li><li>主业务逻辑监听订单已支付事件并处理。</li></ol></blockquote><p>事件/编排是实现 Saga 模式的自然方式，它很简单，容易理解，不需要太多的代码来构建。如果事务涉及 2 至 4 个步骤，则可能是非常合适的。</p><h3 id="方案总结-6"><a class="markdownIt-Anchor" href="#方案总结-6"></a> 方案总结</h3><p><strong>命令协调设计的优点和缺点：</strong></p><p>优点如下：</p><ul><li>服务之间关系简单，避免服务之间的循环依赖关系，因为 Saga 协调器会调用 Saga 参与者，但参与者不会调用协调器</li><li>程序开发简单，只需要执行命令/回复(其实回复消息也是一种事件消息)，降低参与者的复杂性。</li><li>易维护扩展，在添加新步骤时，事务复杂性保持线性，回滚更容易管理，更容易实施和测试</li></ul><p>缺点如下：</p><ul><li>中央协调器容易处理逻辑容易过于复杂，导致难以维护。</li><li>存在协调器单点故障风险。</li></ul><p><strong>事件/编排设计的优点和缺点</strong></p><p>优点如下：</p><ul><li>避免中央协调器单点故障风险。</li><li>当涉及的步骤较少服务开发简单，容易实现。</li></ul><p>缺点如下：</p><ul><li>服务之间存在循环依赖的风险。</li><li>当涉及的步骤较多，服务间关系混乱，难以追踪调测。</li></ul><p>值得补充的是，由于 Saga 模型中没有 Prepare 阶段，因此事务间不能保证隔离性，当多个 Saga 事务操作同一资源时，就会产生更新丢失、脏数据读取等问题，这时需要在业务层控制并发，例如：在应用层面加锁，或者应用层面预先冻结资源。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><h3 id="各方案使用场景"><a class="markdownIt-Anchor" href="#各方案使用场景"></a> 各方案使用场景</h3><p>介绍完分布式事务相关理论和常见解决方案后，最终的目的在实际项目中运用，因此，总结一下各个方案的常见的使用场景。</p><p><img src="https://user-gold-cdn.xitu.io/2018/12/10/1679817dc68ae74d?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="方案比较" /></p><ul><li>2PC/3PC 依赖于数据库，能够很好的提供强一致性和强事务性，但相对来说延迟比较高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况，不适合高并发和高性能要求的场景。</li><li>TCC 适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。</li><li>本地消息表/MQ 事务 都适用于事务中参与方支持操作幂等，对一致性要求不高，业务上能容忍数据不一致到一个人工检查周期，事务涉及的参与方、参与环节较少，业务上有对账/校验系统兜底。</li><li>Saga 事务 由于 Saga 事务不能保证隔离性，需要在业务层控制并发，适合于业务场景事务并发操作同一资源较少的情况。 Saga 相比缺少预提交动作，导致补偿动作的实现比较麻烦，例如业务是发送短信，补偿动作则得再发送一次短信说明撤销，用户体验比较差。Saga 事务较适用于补偿动作容易处理的场景。</li></ul><h3 id="分布式事务方案设计"><a class="markdownIt-Anchor" href="#分布式事务方案设计"></a> 分布式事务方案设计</h3><p>本文介绍的偏向于原理，业界已经有不少开源的或者收费的解决方案，篇幅所限，就不再展开介绍。</p><p>实际运用理论时进行架构设计时，许多人容易犯“手里有了锤子，看什么都觉得像钉子”的错误，设计方案时考虑的问题场景过多，各种重试，各种补偿机制引入系统，导致设计出来的系统过于复杂，落地遥遥无期。</p><blockquote><p>世界上解决一个计算机问题最简单的方法：“恰好”不需要解决它！—— 阿里中间件技术专家沈询</p></blockquote><p>有些问题，看起来很重要，但实际上我们可以通过<strong>合理的设计</strong>或者将<strong>问题分解</strong>来规避。设计分布式事务系统也不是需要考虑所有异常情况，不必过度设计各种回滚，补偿机制。如果硬要把时间花在解决问题本身，实际上不仅效率低下，而且也是一种浪费。</p><p>如果系统要实现回滚流程的话，有可能系统复杂度将大大提升，且很容易出现 Bug，估计出现 Bug 的概率会比需要事务回滚的概率大很多。在设计系统时，我们需要衡量是否值得花这么大的代价来解决这样一个出现概率非常小的问题，可以考虑当出现这个概率很小的问题，能否采用<strong>人工解决</strong>的方式，这也是大家在解决疑难问题时需要多多思考的地方。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html" target="_blank" rel="noopener">聊聊分布式事务，再说说解决方案</a></li><li><a href="https://juejin.im/post/5c0e5bf8e51d45063322fe50" target="_blank" rel="noopener">理解分布式事务</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分布式事务基本原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#分布式事务基本原理&quot;&gt;&lt;/a&gt; 分布式事务基本原理&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;📦 本文已归档到：「&lt;a href=&quot;https://github.com
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="事务" scheme="https://dunwu.github.io/blog/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>分布式锁基本原理</title>
    <link href="https://dunwu.github.io/blog/theory/distributed-lock/"/>
    <id>https://dunwu.github.io/blog/theory/distributed-lock/</id>
    <published>2019-06-04T15:42:00.000Z</published>
    <updated>2020-07-25T07:46:26.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁基本原理"><a class="markdownIt-Anchor" href="#分布式锁基本原理"></a> 分布式锁基本原理</h1><blockquote><p>在并发场景下，为了保证并发安全，我们常常要通过互斥（加锁）手段来保证数据同步安全。</p><p>JDK 虽然提供了大量锁工具，但是只能作用于单一 Java 进程，无法应用于分布式系统。为了解决这个问题，需要使用分布式锁。</p><p>分布式锁的解决方案大致有以下几种：</p><ul><li>基于数据库实现</li><li>基于缓存（redis，memcached 等）实现</li><li>基于 Zookeeper 实现 ✅</li></ul><p>注：推荐基于 ZooKeeper 实现分布式锁，具体原因看完本文即可明了。</p><p>📦 本文已归档到：「<a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">blog</a>」</p></blockquote><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#%E4%B8%80%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%80%9D%E8%B7%AF">一、分布式锁思路</a></li><li><a href="#%E4%BA%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">二、数据库分布式锁</a><ul><li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8E%9F%E7%90%86">数据库分布式锁原理</a></li><li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E9%97%AE%E9%A2%98">数据库分布式锁问题</a></li><li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%B0%8F%E7%BB%93">数据库分布式锁小结</a></li></ul></li><li><a href="#%E4%B8%89redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">三、Redis 分布式锁</a><ul><li><a href="#redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8E%9F%E7%90%86">Redis 分布式锁原理</a></li><li><a href="#redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0">Redis 分布式锁实现</a></li><li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%B0%8F%E7%BB%93-1">数据库分布式锁小结</a></li><li><a href="#redlock-%E7%AE%97%E6%B3%95">RedLock 算法</a></li></ul></li><li><a href="#%E5%9B%9Bzookeeper-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">四、ZooKeeper 分布式锁</a><ul><li><a href="#zookeeper-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8E%9F%E7%90%86">ZooKeeper 分布式锁原理</a></li><li><a href="#zookeeper-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0">ZooKeeper 分布式锁实现</a></li><li><a href="#zookeeper-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%B0%8F%E7%BB%93">ZooKeeper 分布式锁小结</a></li></ul></li><li><a href="#%E4%BA%94-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94">五、 分布式锁方案对比</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul><!-- /TOC --><h2 id="一-分布式锁思路"><a class="markdownIt-Anchor" href="#一-分布式锁思路"></a> 一、分布式锁思路</h2><p>分布式锁的总体思路大同小异，仅在实现细节上有所不同。</p><p>分布式锁的主要思路如下：</p><ul><li><strong>互斥、可重入</strong> - 创建锁必须是唯一的，表现形式为向数据存储服务器或容器插入一个唯一的 key，一旦有一个线程插入这个 key，其他线程就不能再插入了。<ul><li>保证 key 唯一性的最简单的方式是使用 UUID。</li><li>存储锁的重入次数，以及分布式环境下唯一的线程标识。举例来说，可以使用 json 存储结构化数据，为了保证唯一，可以考虑将 mac 地址（IP 地址、机器 ID）、Jvm 进程 ID（应用 ID、服务 ID）、线程 ID 拼接起来作为唯一标识。<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">"count"</span>:<span class="number">1</span>,<span class="attr">"expireAt"</span>:<span class="number">147506817232</span>,<span class="attr">"jvmPid"</span>:<span class="number">22224</span>,<span class="attr">"mac"</span>:<span class="string">"28-D2-44-0E-0D-9A"</span>,<span class="attr">"threadId"</span>:<span class="number">14</span>&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><strong>避免死锁</strong> - 数据库分布式锁和缓存分布式锁（Redis）的思路都是引入超时机制，即成功申请锁后，超过一定时间，锁失效（删除 key），原因在于它们无法感知申请锁的客户端节点状态。而 ZooKeeper 由于其 znode 以目录、文件形式组织，天然就存在物理空间隔离，只要 znode 存在，即表示客户端节点还在工作，所以不存在这种问题。</li><li><strong>容错</strong> - 只要大部分 Redis 节点可用，客户端就能正常加锁。</li><li><strong>自旋重试</strong> - 获取不到锁时，不要直接返回失败，而是支持一定的周期自旋重试，设置一个总的超时时间，当过了超时时间以后还没有获取到锁则返回失败。</li></ul><h2 id="二-数据库分布式锁"><a class="markdownIt-Anchor" href="#二-数据库分布式锁"></a> 二、数据库分布式锁</h2><h3 id="数据库分布式锁原理"><a class="markdownIt-Anchor" href="#数据库分布式锁原理"></a> 数据库分布式锁原理</h3><p>（1）创建表</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`methodLock`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT <span class="keyword">COMMENT</span> <span class="string">'主键'</span>,</span><br><span class="line">  <span class="string">`method_name`</span> <span class="built_in">varchar</span>(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">''</span> <span class="keyword">COMMENT</span> <span class="string">'锁定的方法名'</span>,</span><br><span class="line">  <span class="string">`desc`</span> <span class="built_in">varchar</span>(<span class="number">1024</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">'备注信息'</span>,</span><br><span class="line">  <span class="string">`update_time`</span> <span class="built_in">timestamp</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">COMMENT</span> <span class="string">'保存数据时间，自动生成'</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>),</span><br><span class="line">  <span class="keyword">UNIQUE</span> <span class="keyword">KEY</span> <span class="string">`uidx_method_name`</span> (<span class="string">`method_name `</span>) <span class="keyword">USING</span> BTREE</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8 <span class="keyword">COMMENT</span>=<span class="string">'锁定中的方法'</span>;</span><br></pre></td></tr></table></figure><p>（2）获取锁</p><p>想要锁住某个方法时，执行以下 SQL：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> methodLock(method_name,<span class="keyword">desc</span>) <span class="keyword">values</span> (‘method_name’,‘<span class="keyword">desc</span>’)</span><br></pre></td></tr></table></figure><p>因为我们对 <code>method_name</code> 做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。</p><p>成功插入则获取锁。</p><p>（3）释放锁</p><p>当方法执行完毕之后，想要释放锁的话，需要执行以下 Sql:</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> methodLock <span class="keyword">where</span> method_name =<span class="string">'method_name'</span></span><br></pre></td></tr></table></figure><h3 id="数据库分布式锁问题"><a class="markdownIt-Anchor" href="#数据库分布式锁问题"></a> 数据库分布式锁问题</h3><ul><li>这把锁强依赖数据库的可用性。如果数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</li><li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li><li>这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li><li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li></ul><p>解决办法：</p><ul><li>单点问题可以用多数据库实例，同时塞 N 个表，N/2+1 个成功就任务锁定成功</li><li>写一个定时任务，隔一段时间清除一次过期的数据。</li><li>写一个 while 循环，不断的重试插入，直到成功。</li><li>在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li></ul><h3 id="数据库分布式锁小结"><a class="markdownIt-Anchor" href="#数据库分布式锁小结"></a> 数据库分布式锁小结</h3><ul><li>优点: 直接借助数据库，容易理解。</li><li>缺点: 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。操作数据库需要一定的开销，性能问题需要考虑。</li></ul><h2 id="三-redis-分布式锁"><a class="markdownIt-Anchor" href="#三-redis-分布式锁"></a> 三、Redis 分布式锁</h2><p>相比于用数据库来实现分布式锁，基于缓存实现的分布式锁的性能会更好一些。目前有很多成熟的分布式产品，包括 Redis、memcache、Tair 等。这里以 Redis 举例。</p><h3 id="redis-分布式锁原理"><a class="markdownIt-Anchor" href="#redis-分布式锁原理"></a> Redis 分布式锁原理</h3><p>这个分布式锁有 3 个重要的考量点：</p><ol><li>互斥（只能有一个客户端获取锁）</li><li>不能死锁</li><li>容错（只要大部分 redis 节点创建了这把锁就可以）</li></ol><p>对应的 Redis 指令如下：</p><ul><li><code>setnx</code> - <code>setnx key val</code>：当且仅当 key 不存在时，set 一个 key 为 val 的字符串，返回 1；若 key 存在，则什么都不做，返回 0。</li><li><code>expire</code> - <code>expire key timeout</code>：为 key 设置一个超时时间，单位为 second，超过这个时间锁会自动释放，避免死锁。</li><li><code>delete</code> - <code>delete key</code>：删除 key</li></ul><blockquote><p>注意：</p><p>不要将 setnx 和 expire 作为两个命令组合实现加锁，这样就<strong>无法保证原子性</strong>。如果客户端在 setnx 之后崩溃，那么将导致锁无法释放。正确的做法应是在 setnx 命令中指定 expire 时间。</p></blockquote><h3 id="redis-分布式锁实现"><a class="markdownIt-Anchor" href="#redis-分布式锁实现"></a> Redis 分布式锁实现</h3><p>（1）申请锁</p><figure class="highlight gams"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> resource_name <span class="comment">my_random_value NX PX 30000</span></span><br></pre></td></tr></table></figure><p>执行这个命令就 ok。</p><ul><li><code>NX</code>：表示只有 <code>key</code> 不存在的时候才会设置成功。（如果此时 redis 中存在这个 key，那么设置失败，返回 <code>nil</code>）</li><li><code>PX 30000</code>：意思是 30s 后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。</li></ul><p>（2）释放锁</p><p>释放锁就是删除 key ，但是一般可以用 <code>lua</code> 脚本删除，判断 value 一样才删除：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">-- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。</span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">"get"</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] then</span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">"del"</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure><h3 id="数据库分布式锁小结-2"><a class="markdownIt-Anchor" href="#数据库分布式锁小结-2"></a> 数据库分布式锁小结</h3><p>为啥要用 <code>random_value</code> 随机值呢？因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，所以得用随机值加上面的 <code>lua</code> 脚本来释放锁。</p><p>但是这样是肯定不行的。因为如果是普通的 redis 单实例，那就是单点故障。或者是 redis 普通主从，那 redis 主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。</p><h3 id="redlock-算法"><a class="markdownIt-Anchor" href="#redlock-算法"></a> RedLock 算法</h3><p>这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把锁：</p><ol><li>获取当前时间戳，单位是毫秒；</li><li>跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；</li><li>尝试在<strong>大多数节点</strong>上建立一个锁，比如 5 个节点就要求是 3 个节点 <code>n / 2 + 1</code>；</li><li>客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；</li><li>要是锁建立失败了，那么就依次之前建立过的锁删除；</li><li>只要别人建立了一把分布式锁，你就得<strong>不断轮询去尝试获取锁</strong>。</li></ol><p><a href="https://redis.io/" target="_blank" rel="noopener">Redis 官方</a>给出了以上两种基于 Redis 实现分布式锁的方法，详细说明可以查看：<a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">https://redis.io/topics/distlock</a> 。</p><h2 id="四-zookeeper-分布式锁"><a class="markdownIt-Anchor" href="#四-zookeeper-分布式锁"></a> 四、ZooKeeper 分布式锁</h2><h3 id="zookeeper-分布式锁原理"><a class="markdownIt-Anchor" href="#zookeeper-分布式锁原理"></a> ZooKeeper 分布式锁原理</h3><p>这也是 ZooKeeper 客户端 curator 的分布式锁实现。</p><ol><li>创建一个目录 mylock；</li><li>线程 A 想获取锁就在 mylock 目录下创建临时顺序节点；</li><li>获取 mylock 目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；</li><li>线程 B 获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；</li><li>线程 A 处理完，删除自己的节点，线程 B 监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。</li></ol><h3 id="zookeeper-分布式锁实现"><a class="markdownIt-Anchor" href="#zookeeper-分布式锁实现"></a> ZooKeeper 分布式锁实现</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ZooKeeperSession</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> bingo</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2018/11/29</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZooKeeperSession</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> CountDownLatch connectedSemaphore = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ZooKeeper zookeeper;</span><br><span class="line">    <span class="keyword">private</span> CountDownLatch latch;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ZooKeeperSession</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.zookeeper = <span class="keyword">new</span> ZooKeeper(<span class="string">"192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181"</span>, <span class="number">50000</span>, <span class="keyword">new</span> ZooKeeperWatcher());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                connectedSemaphore.await();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">"ZooKeeper session established......"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取分布式锁</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> productId</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">acquireDistributedLock</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        String path = <span class="string">"/product-lock-"</span> + productId;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zookeeper.create(path, <span class="string">""</span>.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 相当于是给node注册一个监听器，去看看这个监听器是否存在</span></span><br><span class="line">                    Stat stat = zk.exists(path, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (stat != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        <span class="keyword">this</span>.latch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line">                        <span class="keyword">this</span>.latch.await(waitTime, TimeUnit.MILLISECONDS);</span><br><span class="line">                        <span class="keyword">this</span>.latch = <span class="keyword">null</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    zookeeper.create(path, <span class="string">""</span>.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception ee) &#123;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 释放掉一个分布式锁</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> productId</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">releaseDistributedLock</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        String path = <span class="string">"/product-lock-"</span> + productId;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zookeeper.delete(path, -<span class="number">1</span>);</span><br><span class="line">            System.out.println(<span class="string">"release the lock for product[id="</span> + productId + <span class="string">"]......"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 建立zk session的watcher</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@author</span> bingo</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@since</span> 2018/11/29</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">ZooKeeperWatcher</span> <span class="keyword">implements</span> <span class="title">Watcher</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">"Receive watched event: "</span> + event.getState());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (KeeperState.SyncConnected == event.getState()) &#123;</span><br><span class="line">                connectedSemaphore.countDown();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.latch != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">this</span>.latch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 封装单例的静态内部类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@author</span> bingo</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@since</span> 2018/11/29</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> ZooKeeperSession instance;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">static</span> &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> ZooKeeperSession();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ZooKeeperSession <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> instance;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取单例</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ZooKeeperSession <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Singleton.getInstance();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化单例的便捷方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        getInstance();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以采用另一种方式，创建临时顺序节点：</p><p>如果有一把锁，被多个人给竞争，此时多个人会排队，第一个拿到锁的人会执行，然后释放锁；后面的每个人都会去监听<strong>排在自己前面</strong>的那个人创建的 node 上，一旦某个人释放了锁，排在自己后面的人就会被 zookeeper 给通知，一旦被通知了之后，就 ok 了，自己就获取到了锁，就可以执行代码了。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZooKeeperDistributedLock</span> <span class="keyword">implements</span> <span class="title">Watcher</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ZooKeeper zk;</span><br><span class="line">    <span class="keyword">private</span> String locksRoot = <span class="string">"/locks"</span>;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> String waitNode;</span><br><span class="line">    <span class="keyword">private</span> String lockNode;</span><br><span class="line">    <span class="keyword">private</span> CountDownLatch latch;</span><br><span class="line">    <span class="keyword">private</span> CountDownLatch connectedLatch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> sessionTimeout = <span class="number">30000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ZooKeeperDistributedLock</span><span class="params">(String productId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.productId = productId;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String address = <span class="string">"192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181"</span>;</span><br><span class="line">            zk = <span class="keyword">new</span> ZooKeeper(address, sessionTimeout, <span class="keyword">this</span>);</span><br><span class="line">            connectedLatch.await();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> LockException(e);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> LockException(e);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> LockException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (event.getState() == KeeperState.SyncConnected) &#123;</span><br><span class="line">            connectedLatch.countDown();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.latch != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.latch.countDown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">acquireDistributedLock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.tryLock()) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                waitForLock(waitNode, sessionTimeout);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> LockException(e);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> LockException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">     <span class="comment">// 传入进去的locksRoot + “/” + productId</span></span><br><span class="line">    <span class="comment">// 假设productId代表了一个商品id，比如说1</span></span><br><span class="line">    <span class="comment">// locksRoot = locks</span></span><br><span class="line">    <span class="comment">// /locks/10000000000，/locks/10000000001，/locks/10000000002</span></span><br><span class="line">            lockNode = zk.create(locksRoot + <span class="string">"/"</span> + productId, <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 看看刚创建的节点是不是最小的节点</span></span><br><span class="line">     <span class="comment">// locks：10000000000，10000000001，10000000002</span></span><br><span class="line">            List&lt;String&gt; locks = zk.getChildren(locksRoot, <span class="keyword">false</span>);</span><br><span class="line">            Collections.sort(locks);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>(lockNode.equals(locksRoot+<span class="string">"/"</span>+ locks.get(<span class="number">0</span>)))&#123;</span><br><span class="line">                <span class="comment">//如果是最小的节点,则表示取得锁</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//如果不是最小的节点，找到比自己小1的节点</span></span><br><span class="line">  <span class="keyword">int</span> previousLockIndex = -<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; locks.size(); i++) &#123;</span><br><span class="line"><span class="keyword">if</span>(lockNode.equals(locksRoot + “/” + locks.get(i))) &#123;</span><br><span class="line">             previousLockIndex = i - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">this</span>.waitNode = locks.get(previousLockIndex);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> LockException(e);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> LockException(e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">waitForLock</span><span class="params">(String waitNode, <span class="keyword">long</span> waitTime)</span> <span class="keyword">throws</span> InterruptedException, KeeperException </span>&#123;</span><br><span class="line">        Stat stat = zk.exists(locksRoot + <span class="string">"/"</span> + waitNode, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">if</span> (stat != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.latch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">this</span>.latch.await(waitTime, TimeUnit.MILLISECONDS);</span><br><span class="line">            <span class="keyword">this</span>.latch = <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 删除/locks/10000000000节点</span></span><br><span class="line">            <span class="comment">// 删除/locks/10000000001节点</span></span><br><span class="line">            System.out.println(<span class="string">"unlock "</span> + lockNode);</span><br><span class="line">            zk.delete(lockNode, -<span class="number">1</span>);</span><br><span class="line">            lockNode = <span class="keyword">null</span>;</span><br><span class="line">            zk.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LockException</span> <span class="keyword">extends</span> <span class="title">RuntimeException</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">LockException</span><span class="params">(String e)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">super</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">LockException</span><span class="params">(Exception e)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">super</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="zookeeper-分布式锁小结"><a class="markdownIt-Anchor" href="#zookeeper-分布式锁小结"></a> ZooKeeper 分布式锁小结</h3><p>ZooKeeper 版本的分布式锁问题相对比较来说少。</p><ul><li>锁的占用时间限制：redis 就有占用时间限制，而 ZooKeeper 则没有，最主要的原因是 redis 目前没有办法知道已经获取锁的客户端的状态，是已经挂了呢还是正在执行耗时较长的业务逻辑。而 ZooKeeper 通过临时节点就能清晰知道，如果临时节点存在说明还在执行业务逻辑，如果临时节点不存在说明已经执行完毕释放锁或者是挂了。由此看来 redis 如果能像 ZooKeeper 一样添加一些与客户端绑定的临时键，也是一大好事。</li><li>是否单点故障：redis 本身有很多中玩法，如客户端一致性 hash，服务器端 sentinel 方案或者 cluster 方案，很难做到一种分布式锁方式能应对所有这些方案。而 ZooKeeper 只有一种玩法，多台机器的节点数据是一致的，没有 redis 的那么多的麻烦因素要考虑。</li></ul><p>总体上来说 ZooKeeper 实现分布式锁更加的简单，可靠性更高。但 ZooKeeper 因为需要频繁的创建和删除节点，性能上不如 Redis 方式。</p><h2 id="五-分布式锁方案对比"><a class="markdownIt-Anchor" href="#五-分布式锁方案对比"></a> 五、 分布式锁方案对比</h2><p>数据库分布式锁，问题比较多，解决起来比较麻烦，不推荐。</p><p>性能：</p><ul><li>Redis 分布式锁，其实<strong>需要自己不断自旋去尝试获取锁</strong>，比较消耗性能。</li><li>ZooKeeper 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。</li></ul><p>可靠性：</p><ul><li>如果是 redis 获取锁的那个客户端出现 bug 挂了，那么只能等待超时时间之后才能释放锁；</li><li>而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。</li></ul><p>综上分析，<strong>ZooKeeper 实现分布式锁更加的简单，可靠性更高</strong>。✅</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://juejin.im/post/5a20cd8bf265da43163cdd9a" target="_blank" rel="noopener">分布式锁实现汇总</a></li><li><a href="https://www.jianshu.com/p/1c5c1a592088" target="_blank" rel="noopener">Redis 实现分布式锁，以及可重入锁思路</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分布式锁基本原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#分布式锁基本原理&quot;&gt;&lt;/a&gt; 分布式锁基本原理&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;在并发场景下，为了保证并发安全，我们常常要通过互斥（加锁）手段来保证数据同步安全。
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式锁" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    
  </entry>
  
</feed>
